
<!DOCTYPE html>

<html class="no-js" lang="zh-Hant">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="ie=edge" http-equiv="x-ua-compatible"/>
<meta content="10程式中" name="author"/>
<meta content="複製" name="lang:clipboard.copy"/>
<meta content="已複製" name="lang:clipboard.copied"/>
<meta content="ja" name="lang:search.language"/>
<meta content="True" name="lang:search.pipeline.stopwords"/>
<meta content="True" name="lang:search.pipeline.trimmer"/>
<meta content="沒有符合的項目" name="lang:search.result.none"/>
<meta content="找到 1 個符合的項目" name="lang:search.result.one"/>
<meta content="找到 # 個符合的項目" name="lang:search.result.other"/>
<meta content="[\uff0c\u3002]+" name="lang:search.tokenizer"/>
<link href="../assets/images/favicon.png" rel="shortcut icon"/>
<meta content="mkdocs-1.0.4, mkdocs-material-4.4.0" name="generator"/>
<title>[Day 13] LIME實作：實戰演練LIME解釋方法 - 全民瘋AI系列 [探索可解釋人工智慧]</title>
<link href="../assets/stylesheets/application.0284f74d.css" rel="stylesheet"/>
<link href="../assets/stylesheets/application-palette.01803549.css" rel="stylesheet"/>
<meta content="#7e57c2" name="theme-color"/>
<script src="../assets/javascripts/modernizr.74668098.js"></script>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&amp;display=fallback" rel="stylesheet"/>
<style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
<link href="../assets/fonts/material-icons.css" rel="stylesheet"/>
<link href="../stylesheets/extra.css" rel="stylesheet"/>
</head>
<body data-md-color-accent="deep-purple" data-md-color-primary="deep-purple" dir="ltr">
<svg class="md-svg">
<defs>
<svg height="448" id="__github" viewbox="0 0 416 448" width="416" xmlns="http://www.w3.org/2000/svg"><path d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z" fill="currentColor"></path></svg>
</defs>
</svg>
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
<a class="md-skip" href="#day-13-limelime" tabindex="1">
        跳轉到
      </a>
<header class="md-header" data-md-component="header">
<nav class="md-header-nav md-grid">
<div class="md-flex">
<div class="md-flex__cell md-flex__cell--shrink">
<a class="md-header-nav__button md-logo" href=".." title="全民瘋AI系列 [探索可解釋人工智慧]">
<i class="md-icon"></i>
</a>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
</div>
<div class="md-flex__cell md-flex__cell--stretch">
<div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
<span class="md-header-nav__topic">
              全民瘋AI系列 [探索可解釋人工智慧]
            </span>
<span class="md-header-nav__topic">
              
                [Day 13] LIME實作：實戰演練LIME解釋方法
              
            </span>
</div>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="query" data-md-state="active" name="query" placeholder="搜尋" spellcheck="false" type="text"/>
<label class="md-icon md-search__icon" for="__search"></label>
<button class="md-icon md-search__icon" data-md-component="reset" tabindex="-1" type="reset">
        
      </button>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="result">
<div class="md-search-result__meta">
            打字進行搜尋
          </div>
<ol class="md-search-result__list"></ol>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<div class="md-header-nav__source">
<a class="md-source" data-md-source="github" href="https://github.com/andy6804tw/2023-15th-ironman" title="前往倉庫">
<div class="md-source__icon">
<svg height="24" viewbox="0 0 24 24" width="24">
<use height="24" width="24" xlink:href="#__github"></use>
</svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
</div>
</div>
</nav>
</header>
<div class="md-container">
<main class="md-main">
<div class="md-main__inner md-grid" data-md-component="container">
<div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav class="md-nav md-nav--primary" data-md-level="0">
<label class="md-nav__title md-nav__title--site" for="__drawer">
<a class="md-nav__button md-logo" href=".." title="全民瘋AI系列 [探索可解釋人工智慧]">
<i class="md-icon"></i>
</a>
    全民瘋AI系列 [探索可解釋人工智慧]
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-source="github" href="https://github.com/andy6804tw/2023-15th-ironman" title="前往倉庫">
<div class="md-source__icon">
<svg height="24" viewbox="0 0 24 24" width="24">
<use height="24" width="24" xlink:href="#__github"></use>
</svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" id="nav-1" type="checkbox"/>
<label class="md-nav__link" for="nav-1">
      1.XAI基礎與概念介紹
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-1">
        1.XAI基礎與概念介紹
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../1.揭開模型的神秘面紗:為何XAI對機器學習如此重要/" title="[Day 1] 揭開模型的神秘面紗：為何XAI對機器學習如此重要？">
      [Day 1] 揭開模型的神秘面紗：為何XAI對機器學習如此重要？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2.從黑盒到透明化:XAI技術的發展之路/" title="[Day 2] 從黑盒到透明化：XAI技術的發展之路">
      [Day 2] 從黑盒到透明化：XAI技術的發展之路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../3.機器學習中的可解釋性指標/" title="[Day 3] 機器學習中的可解釋性指標">
      [Day 3] 機器學習中的可解釋性指標
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../4.LIME vs SHAP:哪種XAI解釋方法更適合你/" title="[Day 4] LIME vs. SHAP：哪種XAI解釋方法更適合你？">
      [Day 4] LIME vs. SHAP：哪種XAI解釋方法更適合你？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../5.淺談XAI與傳統機器學習的區別/" title="[Day 5] 淺談XAI與傳統機器學習的區別">
      [Day 5] 淺談XAI與傳統機器學習的區別
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" id="nav-2" type="checkbox"/>
<label class="md-nav__link" for="nav-2">
      2.XAI在傳統機器學習中的應用
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-2">
        2.XAI在傳統機器學習中的應用
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../6.非監督學習也能做到可解釋性-探索XAI在非監督學習中的應用/" title="[Day 6] 非監督學習也能做到可解釋性？探索XAI在非監督學習中的應用">
      [Day 6] 非監督學習也能做到可解釋性？探索XAI在非監督學習中的應用
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../7.KNN與XAI:從鄰居中找出模型的決策邏輯/" title="[Day 7] KNN與XAI：從鄰居中找出模型的決策邏輯">
      [Day 7] KNN與XAI：從鄰居中找出模型的決策邏輯
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../8.解釋線性模型:探索線性迴歸和邏輯迴歸的可解釋性/" title="[Day 8] 解釋線性模型：探索線性迴歸和邏輯迴歸的可解釋性">
      [Day 8] 解釋線性模型：探索線性迴歸和邏輯迴歸的可解釋性
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../9.基於樹狀結構的XAI方法:決策樹的可解釋性/" title="[Day 9] 基於樹狀結構的XAI方法：決策樹的可解釋性">
      [Day 9] 基於樹狀結構的XAI方法：決策樹的可解釋性
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../10.Permutation Importance:從特徵重要性角度解釋整個模型行為/" title="[Day 10] Permutation Importance：從特徵重要性角度解釋整個模型行為">
      [Day 10] Permutation Importance：從特徵重要性角度解釋整個模型行為
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../11.Partial Dependence Plot:探索特徵對預測值的影響/" title="[Day 11] Partial Dependence Plot：探索特徵對預測值的影響">
      [Day 11] Partial Dependence Plot：探索特徵對預測值的影響
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-toggle md-nav__toggle" data-md-toggle="nav-3" id="nav-3" type="checkbox"/>
<label class="md-nav__link" for="nav-3">
      3.XAI常用工具介紹
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-3">
        3.XAI常用工具介紹
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../12.LIME理論:如何用局部線性近似解釋黑箱模型/" title="[Day 12] LIME理論：如何用局部線性近似解釋黑箱模型">
      [Day 12] LIME理論：如何用局部線性近似解釋黑箱模型
    </a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-toggle md-nav__toggle" data-md-toggle="toc" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
        [Day 13] LIME實作：實戰演練LIME解釋方法
      </label>
<a class="md-nav__link md-nav__link--active" href="./" title="[Day 13] LIME實作：實戰演練LIME解釋方法">
      [Day 13] LIME實作：實戰演練LIME解釋方法
    </a>
<nav class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">本頁目錄</label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#lime" title="LIME 的優缺點">
    LIME 的優缺點
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#lime_1" title="[實作] LIME 解釋分類模型">
    [實作] LIME 解釋分類模型
  </a>
<nav class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_1" title="載入資料集">
    載入資料集
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_2" title="切割資料集">
    切割資料集
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#xgboost" title="訓練模型 (XGBoost 分類器)">
    訓練模型 (XGBoost 分類器)
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#lime_2" title="LIME 解釋模型">
    LIME 解釋模型
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sp-lime" title="SP-LIME 總體貢獻">
    SP-LIME 總體貢獻
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_3" title="小結">
    小結
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#reference" title="Reference">
    Reference
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../14.SHAP理論:解析SHAP解釋方法的核心/" title="[Day 14] SHAP理論：解析SHAP解釋方法的核心">
      [Day 14] SHAP理論：解析SHAP解釋方法的核心
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../15.SHAP實作:實戰演練SHAP解釋方法/" title="[Day 15] SHAP實作：實戰演練SHAP解釋方法">
      [Day 15] SHAP實作：實戰演練SHAP解釋方法
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" id="nav-4" type="checkbox"/>
<label class="md-nav__link" for="nav-4">
      4.XAI在深度學習中的可解釋性
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-4">
        4.XAI在深度學習中的可解釋性
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../16.神經網路的可解釋性:如何理解深度學習中的黑箱模型/" title="[Day 16] 神經網路的可解釋性：如何理解深度學習中的黑箱模型？">
      [Day 16] 神經網路的可解釋性：如何理解深度學習中的黑箱模型？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../17.解析深度神經網路:使用Deep SHAP進行模型解釋/" title="[Day 17] 解析深度神經網路：使用Deep SHAP進行模型解釋">
      [Day 17] 解析深度神經網路：使用Deep SHAP進行模型解釋
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="18.CNN:卷積深度神經網路的解釋方法/" title="[Day 18] CNN：卷積深度神經網路的解釋方法">
      [Day 18] CNN：卷積深度神經網路的解釋方法
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="19.Perturbation-Based:如何用擾動方法解釋神經網路/" title="[Day 19] Perturbation-Based：如何用擾動方法解釋神經網路">
      [Day 19] Perturbation-Based：如何用擾動方法解釋神經網路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="20.Gradient-Based:利用梯度訊息解釋神經網路/" title="[Day 20] Gradient-Based：利用梯度訊息解釋神經網路">
      [Day 20] Gradient-Based：利用梯度訊息解釋神經網路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="21.Propagation-Based:探索反向傳播法的可解釋性/" title="[Day 21] Propagation-Based：探索反向傳播法的可解釋性">
      [Day 21] Propagation-Based：探索反向傳播法的可解釋性
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="22.CAM-Based:如何解釋卷積神經網路/" title="[Day 22] CAM-Based：如何解釋卷積神經網路">
      [Day 22] CAM-Based：如何解釋卷積神經網路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="23.Attention-Based:使用注意力機制解釋CNN模型/" title="[Day 23] Attention-Based：使用注意力機制解釋CNN模型">
      [Day 23] Attention-Based：使用注意力機制解釋CNN模型
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" id="nav-5" type="checkbox"/>
<label class="md-nav__link" for="nav-5">
      5.XAI在現實生活中的應用案例
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-5">
        5.XAI在現實生活中的應用案例
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../24.LSTM的可解釋性:解析步態分類中的時序資料/" title="[Day 24] LSTM的可解釋性：從時序資料解析人體姿態預測">
      [Day 24] LSTM的可解釋性：從時序資料解析人體姿態預測
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../25.XAI在影像處理中的瑕疵檢測:解釋卷積神經網路的運作/" title="[Day 25] XAI在影像處理中的瑕疵檢測：解釋卷積神經網路的運作">
      [Day 25] XAI在影像處理中的瑕疵檢測：解釋卷積神經網路的運作
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../26.智慧工廠製程中的鋼材缺陷檢測:運用XAI解析數值型感測器數據/" title="[Day 26] XAI在表格型資料的應用：解析智慧工廠中的鋼材缺陷">
      [Day 26] XAI在表格型資料的應用：解析智慧工廠中的鋼材缺陷
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../27.XAI在NLP中的應用:以情感分析解釋語言模型/" title="[Day 27] XAI在NLP中的應用：以情感分析解釋語言模型">
      [Day 27] XAI在NLP中的應用：以情感分析解釋語言模型
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" id="nav-6" type="checkbox"/>
<label class="md-nav__link" for="nav-6">
      6.XAI的挑戰與未來
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-6">
        6.XAI的挑戰與未來
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../28.誤差分析和對抗樣本:如何利用XAI檢測模型的弱點/" title="[Day 28] 對抗樣本的挑戰：如何利用XAI檢測模型的弱點？">
      [Day 28] 對抗樣本的挑戰：如何利用XAI檢測模型的弱點？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../29.XAI如何影響人類對技術的信任和接受程度/" title="[Day 29] XAI如何影響人類對技術的信任和接受程度？">
      [Day 29] XAI如何影響人類對技術的信任和接受程度？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../30.XAI未來發展方向:向更可靠的機器學習模型邁進/" title="[Day30] XAI未來發展方向：向更可靠的機器學習模型邁進">
      [Day30] XAI未來發展方向：向更可靠的機器學習模型邁進
    </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">本頁目錄</label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#lime" title="LIME 的優缺點">
    LIME 的優缺點
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#lime_1" title="[實作] LIME 解釋分類模型">
    [實作] LIME 解釋分類模型
  </a>
<nav class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_1" title="載入資料集">
    載入資料集
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_2" title="切割資料集">
    切割資料集
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#xgboost" title="訓練模型 (XGBoost 分類器)">
    訓練模型 (XGBoost 分類器)
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#lime_2" title="LIME 解釋模型">
    LIME 解釋模型
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sp-lime" title="SP-LIME 總體貢獻">
    SP-LIME 總體貢獻
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_3" title="小結">
    小結
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#reference" title="Reference">
    Reference
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content">
<article class="md-content__inner md-typeset"><a class="md-content__icon pdf-download-btn" download href="../pdf/全民瘋AI系列_探索可解釋人工智慧_v1.1.pdf" title="Download"><i class="fa fas fa-download"></i><small> PDF</small></a>
<h1 id="day-13-limelime">[Day 13] LIME實作：實戰演練LIME解釋方法</h1>
<p>今天我們將深入探討 LIME 的實作細節，包括如何選擇解釋性模型和解釋特徵，以及如何選擇鄰域大小來生成解釋數據。</p>
<p>若想了解 LIME 的核心原理可以參考前一篇文章：<a href="https://ithelp.ithome.com.tw/articles/10327698">[Day 12] LIME理論：如何用局部線性近似解釋黑箱模型</a></p>
<h2 id="lime">LIME 的優缺點</h2>
<p>LIME 是一種機器學習可解釋的技術，它的基本原理是在解釋模型時，透過建立一個局部解釋性模型，來近似黑盒模型的預測結果。這讓我們能夠針對特定的輸入樣本，解釋模型是如何進行判斷和預測的。以下為各位統整 LIME 的優缺點：</p>
<ul>
<li>
<p>LIME 的優點：</p>
<ul>
<li>可以解釋任何複雜模型。</li>
<li>能夠針對某一筆資料進行解釋。</li>
<li>提供簡單容易理解的解釋方法(線性模型ex: Ridge Linear Regression)。</li>
</ul>
</li>
<li>
<p>LIME 的缺點：</p>
<ul>
<li>對於鄰域的定義仍然是一個未解決的問題（最好的方法是嘗試不同的核函數設置，並測試哪一個效果最好）。</li>
<li>資料的抽樣方法與數量無一定的標準，因此容易影響解釋結果。</li>
<li>簡單模型採用線性易忽略特徵之間的相關性，有時可能產生不合理的解釋結果。</li>
</ul>
</li>
<li>輸入的資料若存在嚴重共線性問題，則會使迴歸估計不准確。</li>
</ul>
<h2 id="lime_1">[實作] LIME 解釋分類模型</h2>
<p>這裡我們會以一個糖尿病預測資料集訓練一個 XGBoost 分類器。接這透過 LIME LimeTabularExplainer 訓練一個簡單模型並對一筆資料進行解釋。首先我們先載入今天範例的資料集，該資料集可以從 Kaggle 資料科學平台<a href="https://www.kaggle.com/datasets/mathchi/diabetes-data-set">取得</a>。</p>
<h3 id="_1">載入資料集</h3>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># 讀取資料集</span>
<span class="n">df_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'./diabetes.csv'</span><span class="p">)</span>
</pre></div>
<p>讓我們來瞧瞧 df_train 裡面的內容。我們可以發現該資料集有總共有 768 筆數據，每一筆資料有八個欄位資訊，其中包含模型的輸入與輸出。</p>
<p><img alt="" src="../image/img13-1.png"/></p>
<p>這個資料集來自美國國家糖尿病和消化和腎臟疾病研究所。其目標是根據診斷測量來預測病人是否患有糖尿病。資料集的變數如下：</p>
<ul>
<li>Glucose：口服葡萄糖耐量測試中2小時的血漿葡萄糖濃度，用於測試糖尿病的診斷。</li>
<li>BloodPressure：舒張壓(mm Hg)，血壓中的一個參數，用於衡量心臟在收縮時的壓力。</li>
<li>SkinThickness：三頭肌皮膚褶皺厚度(mm)，用於衡量皮膚的脂肪層厚度。</li>
<li>Insulin：2小時血清胰島素(mu U/ml)，用於評估胰島素水平，對糖尿病的診斷非常重要。</li>
<li>BMI：身體質量指數，表示體重和身高的比例，用於評估體重狀況。</li>
<li>DiabetesPedigreeFunction：糖尿病家族遺傳函數，用於衡量患有糖尿病的家族遺傳風險。</li>
<li>Age：病人的年齡。</li>
<li>Outcome：病人是否患有糖尿病(作為模型輸出)，值為0表示沒有糖尿病，值為1表示患有糖尿病。</li>
</ul>
<h3 id="_2">切割資料集</h3>
<p>接下來從剛剛讀取進來的 df_train 資料集中，將所有的輸入特徵資料提取出來，作為模型的輸入 X。同時，我們從 df_train 中取得 <code>Outcome</code> 欄位的資料，作為模型的輸出 y，用來表示病人是否患有糖尿病。除此之外，我們也將所有輸入特徵的欄位名稱儲存到 <code>x_feature_names</code> 變數中，<code>y_label_names</code> 則是儲存輸出的標籤名稱，這兩個個變數將在後續 LIME 模型解釋的過程中使用。最後透過 <code>train_test_split</code> 方法切割訓練集與測試集。</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">x_feature_names</span> <span class="o">=</span> <span class="n">df_train</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">'Outcome'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">columns</span>
<span class="n">y_label_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'No'</span><span class="p">,</span> <span class="s1">'Yes'</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_train</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">'Outcome'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span> <span class="c1"># 移除y並取得剩下欄位資料</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="s1">'Outcome'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="c1"># 取得病人糖尿病結果作為y</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</pre></div>
<h3 id="xgboost">訓練模型 (XGBoost 分類器)</h3>
<p>以下使用 XGBoost 分類器（XGBClassifier）來建立一個模型，並使用訓練資料（X_train, y_train）來訓練這個模型。</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>

<span class="c1"># 建立 XGBClassifier 模型</span>
<span class="n">xgboostModel</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">()</span>
<span class="c1"># 使用訓練資料訓練模型</span>
<span class="n">xgboostModel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
<h3 id="lime_2">LIME 解釋模型</h3>
<p>再來是本文的重頭戲。首先大家可以在終端機輸入以下指令安裝 LIME 套件：</p>
<div class="codehilite"><pre><span></span>pip install lime
</pre></div>
<p>LimeTabularExplainer 用於解釋表格數據中的模型預測，根據訓練數據和模型預測結果生成解釋模型，並提供局部解釋結果。透過設置不同的參數，可以自定義解釋器的行為，以滿足不同的解釋需求。以下是常用的設定參數與說明：</p>
<ul>
<li>training_data：訓練集資料 X。</li>
<li>mode：str，用於指定是分類還是迴歸模型，{"classification", "regression"}。</li>
<li>feature_names：list of names (strings)，特徵名稱，對應於訓練數據中的列。</li>
<li>categorical_features：list of indices (ints)，類別特徵的索引列表，這些特徵的值必須是整數(OrdinalEncoder前處理)。</li>
<li>categorical_names：map from int to list of names，類別特徵的名稱映射，其中 categorical_names[i][j] 表示第 i 列中第 j 個值的名稱。</li>
<li>verbose：bool，是否顯示LIME局部模型預測值。</li>
<li>class_names：list of class names，類別名稱列表，按照分類器使用的順序排列。如果未提供，類別名稱將是 '0'、'1' 等。</li>
<li>feature_selection：str，特徵選擇方法，預設值為auto，{'forward_selection', 'highest_weights', 'lasso_path', 'none', 'auto'}。詳細內容<a href="https://lime-ml.readthedocs.io/en/latest/lime.html#module-lime.lime_base">參考</a></li>
<li>random_state: 亂數種子，確保每次執行結果都一樣。</li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">lime</span> 
<span class="kn">from</span> <span class="nn">lime</span> <span class="kn">import</span> <span class="n">lime_tabular</span>

<span class="n">lime_explainer</span> <span class="o">=</span> <span class="n">lime_tabular</span><span class="o">.</span><span class="n">LimeTabularExplainer</span><span class="p">(</span>
    <span class="n">training_data</span><span class="o">=</span> <span class="n">X_train</span><span class="p">,</span>
    <span class="n">feature_names</span><span class="o">=</span> <span class="n">feature_names</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s1">'classification'</span><span class="p">,</span>
    <span class="n">class_names</span><span class="o">=</span><span class="n">y_label_names</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">feature_selection</span><span class="o">=</span><span class="s1">'lasso_path'</span><span class="p">,</span>
    <span class="n">feature_selection</span><span class="o">=</span><span class="s1">'none'</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">44</span>
<span class="p">)</span>
</pre></div>
<p>我們剛剛已經建立了一個 LimeTabularExplainer 並且初始化解釋模型的設定後，接下來就可以試著丟一筆要被解釋的資料並透過 LIME 訓練一個簡單線性模型並解釋。解釋每一筆預測數據則是呼叫 <code>explain_instance()</code> 方法。以下是常用的設定參數與說明：</p>
<ul>
<li>data_row：一維numpy，對應於要解釋的一筆資料。也就是要進行解釋的特定數據樣本。</li>
<li>predict_fn：已訓練的預測模型。對於分類器，這應該是一個函數，接受一個 numpy 數組作為輸入，並輸出預測機率。對於回歸模型，這個函數接受一個 numpy 數組並返回預測值。對於 ScikitClassifiers，這是 classifier.predict_proba()。對於 ScikitRegressors，這是 regressor.predict()。</li>
<li>top_labels：預設為None，適用於分類模型可以輸入要被解釋的前k個預測標籤的模型解釋。</li>
<li>num_features：解釋的特徵數量。這個參數限制了解釋結果中所顯示的特徵數量。預設為10。</li>
<li>num_samples：用於學習線性模型的鄰域大小。該參數控制了生成解釋所需的樣本數量。預設為5000。</li>
</ul>
<p>這裡需要注意的是，LIME 在訓練一個簡單的線性模型時，使用的是 Ridge 線性模型。在訓練過程中，會根據使用者呼叫 <code>explain_instance()</code> 方法時設定的 num_features 參數，從訓練集中挑選出合適的特徵進行訓練。而模型如何選擇特徵，則取決於建立 LimeTabularExplainer 時所設定的 forward_selection 參數。若想觀察所有特徵的解釋性，可以將該參數設置為 'none'，這樣模型就會考慮所有輸入 X 的特徵。以下程式碼從測試集中拿第六筆資料進行解釋，並且選擇要解釋的特徵設定為七個，代表 LIME 會針對所有特徵進行解釋。</p>
<div class="codehilite"><pre><span></span><span class="n">lime_exp</span> <span class="o">=</span> <span class="n">lime_explainer</span><span class="o">.</span><span class="n">explain_instance</span><span class="p">(</span>
    <span class="n">data_row</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span>
    <span class="n">predict_fn</span><span class="o">=</span><span class="n">xgboostModel</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">,</span>
    <span class="n">num_features</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
</pre></div>
<p>最後呼叫 <code>show_in_notebook()</code> 即可觀察 LIME 如何對該筆資料進行解釋。</p>
<div class="codehilite"><pre><span></span><span class="n">lime_exp</span><span class="o">.</span><span class="n">show_in_notebook</span><span class="p">(</span><span class="n">show_table</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show_all</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
<ul>
<li>
<p>Intercept 是生成的線性模型的截距項。在 LIME 中，為了解釋模型的預測結果，會使用一個線性模型來近似原始黑盒模型。Intercept 是這個線性模型中的截距項，表示在沒有任何特徵貢獻的情況下，模型預測的基本值。</p>
</li>
<li>
<p>Prediction_local 是從線性模型中預測的局部預測結果。在 LIME 中，針對特定的一筆資料樣本，會生成一個局部的線性模型，用來解釋該樣本的預測結果。Prediction_local 是這個局部線性模型對於該樣本的預測值。</p>
</li>
<li>
<p>Right 是從被解釋的分類器（XGBoost）中得到的預測值。在 LIME 中，會使用一個弱模型（分類器或迴歸器）來進行解釋，該弱模型是用來模擬原始黑盒模型的預測行為。</p>
</li>
</ul>
<p><img alt="" src="../image/img13-2.png"/></p>
<p>我們可以從上面的結果分析這筆資料的預測結果。首先，在沒有加入任何特徵時，線性模型預測患有糖尿病的機率為 0.21，這是截距項的影響。接著，我們觀察每個特徵的影響。以 BMI 為例該項特徵會造成糖尿病正面的影響是因為輸入的數值大於 36.6 這個閾值，將其輸入值 43 乘以 LIME 線性模型的 x1 係數，得到 0.15。這表示 BMI 特徵的加入會增加預測患有糖尿病的機率約 0.15。依此類推，每個特徵都加入後，最後加總起來得到這筆資料的預測結果為 0.712。在這個二元分類的範例中，這表示有相當高的機率被預測為患有糖尿病。而 XGBoost 模型預測該筆資料的機率為 0.69。</p>
<p><img alt="" src="../image/img13-3.png"/></p>
<h3 id="sp-lime">SP-LIME 總體貢獻</h3>
<p>雖然單筆預測的解釋可以部分地讓使用者了解模型的決策方式，但這並不能完整地反映模型整體的性能和可靠性。若要全面的理解整個模型可能需要看很多筆資料的解釋。但是要看幾筆資料才足夠多呢？在原始論文中提供了一個選擇資料筆數的演算法稱作 Submodular pick (SP)。</p>
<h2 id="_3">小結</h2>
<p>LIME 提供了一種有效的方法，能夠針對黑盒模型進行解釋，幫助我們更理解模型推論的規則。今天透過 LIME 解釋模型的特徵重要性，我們可以發現哪些特徵對於模型的預測結果影響較大，進而幫助我們優化模型，提高其性能和準確性。此外在某些應用中，模型的誤判可能導致嚴重的後果。透過 LIME 可以幫助我們找出模型預測的薄弱環節，並進行風險評估和風險管理。所以模型的解釋性至關重要，因為模型的預測可能直接影響最終決策。</p>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://taweihuang.hpd.io/2018/02/27/introtolime/">使用 LIME 解釋複雜的分類模型</a></li>
<li><a href="https://towardsdatascience.com/interpretability-of-deep-learning-models-9f52e54d72ab?gi=6403abc9f660">interpretability-of-deep-learning-models</a></li>
</ul>
</article>
</div>
</div>
</main>
<footer class="md-footer">
<div class="md-footer-nav">
<nav class="md-footer-nav__inner md-grid">
<a class="md-flex md-footer-nav__link md-footer-nav__link--prev" href="../12.LIME理論:如何用局部線性近似解釋黑箱模型/" rel="prev" title="[Day 12] LIME理論：如何用局部線性近似解釋黑箱模型">
<div class="md-flex__cell md-flex__cell--shrink">
<i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
</div>
<div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
<span class="md-flex__ellipsis">
<span class="md-footer-nav__direction">
                  上一頁
                </span>
                [Day 12] LIME理論：如何用局部線性近似解釋黑箱模型
              </span>
</div>
</a>
<a class="md-flex md-footer-nav__link md-footer-nav__link--next" href="../14.SHAP理論:解析SHAP解釋方法的核心/" rel="next" title="[Day 14] SHAP理論：解析SHAP解釋方法的核心">
<div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
<span class="md-flex__ellipsis">
<span class="md-footer-nav__direction">
                  下一頁
                </span>
                [Day 14] SHAP理論：解析SHAP解釋方法的核心
              </span>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
</div>
</a>
</nav>
</div>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-footer-copyright">
<div class="md-footer-copyright__highlight">
            Copyright © 2023 - 2024 10程式中
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
</div>
</div>
</div>
</footer>
</div>
<script src="../assets/javascripts/application.245445c6.js"></script>
<script src="../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
<script src="../assets/javascripts/lunr/tinyseg.js"></script>
<script src="../assets/javascripts/lunr/lunr.ja.js"></script>
<script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
<script src="../javascripts/extra.js"></script>
</body>
</html>