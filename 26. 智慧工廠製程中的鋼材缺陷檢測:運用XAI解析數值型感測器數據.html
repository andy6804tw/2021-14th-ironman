
<!DOCTYPE html>

<html class="no-js" lang="zh-Hant">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="ie=edge" http-equiv="x-ua-compatible"/>
<meta content="10程式中" name="author"/>
<meta content="複製" name="lang:clipboard.copy"/>
<meta content="已複製" name="lang:clipboard.copied"/>
<meta content="ja" name="lang:search.language"/>
<meta content="True" name="lang:search.pipeline.stopwords"/>
<meta content="True" name="lang:search.pipeline.trimmer"/>
<meta content="沒有符合的項目" name="lang:search.result.none"/>
<meta content="找到 1 個符合的項目" name="lang:search.result.one"/>
<meta content="找到 # 個符合的項目" name="lang:search.result.other"/>
<meta content="[\uff0c\u3002]+" name="lang:search.tokenizer"/>
<link href="assets/images/favicon.png" rel="shortcut icon"/>
<meta content="mkdocs-1.0.4, mkdocs-material-4.4.0" name="generator"/>
<title>[Day 26] XAI在表格型資料的應用:解析智慧工廠中的鋼材缺陷 - 全民瘋AI系列 [探索可解釋人工智慧]</title>
<link href="assets/stylesheets/application.0284f74d.css" rel="stylesheet"/>
<link href="assets/stylesheets/application-palette.01803549.css" rel="stylesheet"/>
<meta content="#7e57c2" name="theme-color"/>
<script src="assets/javascripts/modernizr.74668098.js"></script>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&amp;display=fallback" rel="stylesheet"/>
<style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
<link href="assets/fonts/material-icons.css" rel="stylesheet"/>
<link href="stylesheets/extra.css" rel="stylesheet"/>
</head>
<body data-md-color-accent="deep-purple" data-md-color-primary="deep-purple" dir="ltr">
<svg class="md-svg">
<defs>
<svg height="448" id="__github" viewbox="0 0 416 448" width="416" xmlns="http://www.w3.org/2000/svg"><path d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z" fill="currentColor"></path></svg>
</defs>
</svg>
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
<a class="md-skip" href="#day-26-xai" tabindex="1">
        跳轉到
      </a>
<header class="md-header" data-md-component="header">
<nav class="md-header-nav md-grid">
<div class="md-flex">
<div class="md-flex__cell md-flex__cell--shrink">
<a class="md-header-nav__button md-logo" href="." title="全民瘋AI系列 [探索可解釋人工智慧]">
<i class="md-icon"></i>
</a>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
</div>
<div class="md-flex__cell md-flex__cell--stretch">
<div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
<span class="md-header-nav__topic">
              全民瘋AI系列 [探索可解釋人工智慧]
            </span>
<span class="md-header-nav__topic">
              
                [Day 26] XAI在表格型資料的應用:解析智慧工廠中的鋼材缺陷
              
            </span>
</div>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="query" data-md-state="active" name="query" placeholder="搜尋" spellcheck="false" type="text"/>
<label class="md-icon md-search__icon" for="__search"></label>
<button class="md-icon md-search__icon" data-md-component="reset" tabindex="-1" type="reset">
        
      </button>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="result">
<div class="md-search-result__meta">
            打字進行搜尋
          </div>
<ol class="md-search-result__list"></ol>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<div class="md-header-nav__source">
<a class="md-source" data-md-source="github" href="https://github.com/andy6804tw/2020-12th-ironman" title="前往倉庫">
<div class="md-source__icon">
<svg height="24" viewbox="0 0 24 24" width="24">
<use height="24" width="24" xlink:href="#__github"></use>
</svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
</div>
</div>
</nav>
</header>
<div class="md-container">
<main class="md-main">
<div class="md-main__inner md-grid" data-md-component="container">
<div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav class="md-nav md-nav--primary" data-md-level="0">
<label class="md-nav__title md-nav__title--site" for="__drawer">
<a class="md-nav__button md-logo" href="." title="全民瘋AI系列 [探索可解釋人工智慧]">
<i class="md-icon"></i>
</a>
    全民瘋AI系列 [探索可解釋人工智慧]
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-source="github" href="https://github.com/andy6804tw/2020-12th-ironman" title="前往倉庫">
<div class="md-source__icon">
<svg height="24" viewbox="0 0 24 24" width="24">
<use height="24" width="24" xlink:href="#__github"></use>
</svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" id="nav-1" type="checkbox"/>
<label class="md-nav__link" for="nav-1">
      1. XAI 基礎與概念介紹
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-1">
        1. XAI 基礎與概念介紹
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="1. 揭開模型的神秘面紗:為何XAI對機器學習如此重要.html" title="[Day 1] 揭開模型的神秘面紗:為何XAI對機器學習如此重要?">
      [Day 1] 揭開模型的神秘面紗:為何XAI對機器學習如此重要?
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="2. 從黑盒到透明化:XAI技術的發展之路.html" title="[Day 2] 從黑盒到透明化:XAI技術的發展之路">
      [Day 2] 從黑盒到透明化:XAI技術的發展之路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="3. 機器學習中的可解釋性指標.html" title="[Day 3] 機器學習中的可解釋性指標">
      [Day 3] 機器學習中的可解釋性指標
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="4. LIME vs SHAP:哪種XAI解釋方法更適合你.html" title="[Day 4] LIME vs. SHAP:哪種XAI解釋方法更適合你?">
      [Day 4] LIME vs. SHAP:哪種XAI解釋方法更適合你?
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="5. 淺談XAI與傳統機器學習的區別.html" title="[Day 5] 淺談XAI與傳統機器學習的區別">
      [Day 5] 淺談XAI與傳統機器學習的區別
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" id="nav-2" type="checkbox"/>
<label class="md-nav__link" for="nav-2">
      2. XAI 在傳統機器學習中的應用
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-2">
        2. XAI 在傳統機器學習中的應用
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="6. 非監督學習也能做到可解釋性-探索XAI在非監督學習中的應用.html" title="[Day 6] 非監督學習也能做到可解釋性?探索XAI在非監督學習中的應用">
      [Day 6] 非監督學習也能做到可解釋性?探索XAI在非監督學習中的應用
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="7. KNN與XAI:從鄰居中找出模型的決策邏輯.html" title="[Day 7] KNN與XAI:從鄰居中找出模型的決策邏輯">
      [Day 7] KNN與XAI:從鄰居中找出模型的決策邏輯
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="8. 解釋線性模型:探索線性迴歸和邏輯迴歸的可解釋性.html" title="[Day 8] 解釋線性模型:探索線性迴歸和邏輯迴歸的可解釋性">
      [Day 8] 解釋線性模型:探索線性迴歸和邏輯迴歸的可解釋性
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="9. 基於樹狀結構的XAI方法:決策樹的可解釋性.html" title="[Day 9] 基於樹狀結構的XAI方法:決策樹的可解釋性">
      [Day 9] 基於樹狀結構的XAI方法:決策樹的可解釋性
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="10. Permutation Importance:從特徵重要性角度解釋整個模型行為.html" title="[Day 10] Permutation Importance:從特徵重要性角度解釋整個模型行為">
      [Day 10] Permutation Importance:從特徵重要性角度解釋整個模型行為
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="11. Partial Dependence Plot:探索特徵對預測值的影響.html" title="[Day 11] Partial Dependence Plot:探索特徵對預測值的影響">
      [Day 11] Partial Dependence Plot:探索特徵對預測值的影響
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" id="nav-3" type="checkbox"/>
<label class="md-nav__link" for="nav-3">
      3. XAI 常用工具介紹
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-3">
        3. XAI 常用工具介紹
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="12. LIME理論:如何用局部線性近似解釋黑箱模型.html" title="[Day 12] LIME理論:如何用局部線性近似解釋黑箱模型">
      [Day 12] LIME理論:如何用局部線性近似解釋黑箱模型
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="13. LIME實作:實戰演練LIME解釋方法.html" title="[Day 13] LIME實作:實戰演練LIME解釋方法">
      [Day 13] LIME實作:實戰演練LIME解釋方法
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="14. SHAP理論:解析SHAP解釋方法的核心.html" title="[Day 14] SHAP理論:解析SHAP解釋方法的核心">
      [Day 14] SHAP理論:解析SHAP解釋方法的核心
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="15. SHAP實作:實戰演練SHAP解釋方法.html" title="[Day 15] SHAP實作:實戰演練SHAP解釋方法">
      [Day 15] SHAP實作:實戰演練SHAP解釋方法
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" id="nav-4" type="checkbox"/>
<label class="md-nav__link" for="nav-4">
      4. XAI 在深度學習中的可解釋性
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-4">
        4. XAI 在深度學習中的可解釋性
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="16. 神經網路的可解釋性:如何理解深度學習中的黑箱模型.html" title="[Day 16] 神經網路的可解釋性:如何理解深度學習中的黑箱模型?">
      [Day 16] 神經網路的可解釋性:如何理解深度學習中的黑箱模型?
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="17.  解析深度神經網路:使用Deep SHAP進行模型解釋.html" title="[Day 17] 解析深度神經網路:使用Deep SHAP進行模型解釋">
      [Day 17] 解析深度神經網路:使用Deep SHAP進行模型解釋
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="18. CNN:卷積深度神經網路的解釋方法.html" title="[Day 18] CNN:卷積深度神經網路的解釋方法">
      [Day 18] CNN:卷積深度神經網路的解釋方法
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="19. Perturbation-Based:如何用擾動方法解釋神經網路.html" title="[Day 19] Perturbation-Based:如何用擾動方法解釋神經網路">
      [Day 19] Perturbation-Based:如何用擾動方法解釋神經網路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="20. Gradient-Based:利用梯度訊息解釋神經網路.html" title="[Day 20] Gradient-Based:利用梯度訊息解釋神經網路">
      [Day 20] Gradient-Based:利用梯度訊息解釋神經網路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="21. Propagation-Based:探索反向傳播法的可解釋性.html" title="[Day 21] Propagation-Based:探索反向傳播法的可解釋性">
      [Day 21] Propagation-Based:探索反向傳播法的可解釋性
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="22. CAM-Based:如何解釋卷積神經網路.html" title="[Day 22] CAM-Based:如何解釋卷積神經網路">
      [Day 22] CAM-Based:如何解釋卷積神經網路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="23. Attention-Based:使用注意力機制解釋CNN模型.html" title="[Day 23] Attention-Based:使用注意力機制解釋CNN模型">
      [Day 23] Attention-Based:使用注意力機制解釋CNN模型
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-toggle md-nav__toggle" data-md-toggle="nav-5" id="nav-5" type="checkbox"/>
<label class="md-nav__link" for="nav-5">
      5. XAI 在現實生活中的應用案例
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-5">
        5. XAI 在現實生活中的應用案例
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="24. LSTM的可解釋性:解析步態分類中的時序資料.html" title="[Day 24] LSTM的可解釋性:從時序資料解析人體姿態預測">
      [Day 24] LSTM的可解釋性:從時序資料解析人體姿態預測
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="25. XAI在影像處理中的瑕疵檢測:解釋卷積神經網路的運作.html" title="[Day 25] XAI在影像處理中的瑕疵檢測:解釋卷積神經網路的運作">
      [Day 25] XAI在影像處理中的瑕疵檢測:解釋卷積神經網路的運作
    </a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-toggle md-nav__toggle" data-md-toggle="toc" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
        [Day 26] XAI在表格型資料的應用:解析智慧工廠中的鋼材缺陷
      </label>
<a class="md-nav__link md-nav__link--active" href="26. 智慧工廠製程中的鋼材缺陷檢測:運用XAI解析數值型感測器數據.html" title="[Day 26] XAI在表格型資料的應用:解析智慧工廠中的鋼材缺陷">
      [Day 26] XAI在表格型資料的應用:解析智慧工廠中的鋼材缺陷
    </a>
<nav class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">本頁目錄</label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#_1" title="[案例] 鋼鐵缺陷分類">
    [案例] 鋼鐵缺陷分類
  </a>
<nav class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_2" title="載入資料集">
    載入資料集
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_3" title="切割訓練集與測試集">
    切割訓練集與測試集
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#smote" title="SMOTE處理標籤不平衡問題">
    SMOTE處理標籤不平衡問題
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#lightgbm" title="建立LightGBM模型">
    建立LightGBM模型
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#kernel-shap" title="Kernel SHAP 解釋模型">
    Kernel SHAP 解釋模型
  </a>
<nav class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#shap-summary-plot" title="SHAP Summary Plot (全局解釋)">
    SHAP Summary Plot (全局解釋)
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#shap-force-plot" title="SHAP Force plot (單筆資料解釋)">
    SHAP Force plot (單筆資料解釋)
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#shap-waterfall-plot" title="SHAP waterfall plot (單筆資料解釋)">
    SHAP waterfall plot (單筆資料解釋)
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#permutation-importance" title="Permutation importance解釋全局模型">
    Permutation importance解釋全局模型
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#refernece" title="Refernece">
    Refernece
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="27. XAI在NLP中的應用:以情感分析解釋語言模型.html" title="[Day 27] XAI在NLP中的應用:以情感分析解釋語言模型">
      [Day 27] XAI在NLP中的應用:以情感分析解釋語言模型
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" id="nav-6" type="checkbox"/>
<label class="md-nav__link" for="nav-6">
      6. XAI 的挑戰與未來
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-6">
        6. XAI 的挑戰與未來
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="28. 誤差分析和對抗樣本:如何利用XAI檢測模型的弱點.html" title="[Day 28] XAI如何影響人類對技術的信任和接受程度?">
      [Day 28] XAI如何影響人類對技術的信任和接受程度?
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="29. XAI如何影響人類對技術的信任和接受程度.html" title="[Day 29] 對抗樣本的挑戰:如何利用XAI檢測模型的弱點?">
      [Day 29] 對抗樣本的挑戰:如何利用XAI檢測模型的弱點?
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="30. XAI未來發展方向:向更可靠的機器學習模型邁進.html" title="[Day 30] XAI未來發展方向:向更可靠的機器學習模型邁進">
      [Day 30] XAI未來發展方向:向更可靠的機器學習模型邁進
    </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">本頁目錄</label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#_1" title="[案例] 鋼鐵缺陷分類">
    [案例] 鋼鐵缺陷分類
  </a>
<nav class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_2" title="載入資料集">
    載入資料集
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_3" title="切割訓練集與測試集">
    切割訓練集與測試集
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#smote" title="SMOTE處理標籤不平衡問題">
    SMOTE處理標籤不平衡問題
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#lightgbm" title="建立LightGBM模型">
    建立LightGBM模型
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#kernel-shap" title="Kernel SHAP 解釋模型">
    Kernel SHAP 解釋模型
  </a>
<nav class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#shap-summary-plot" title="SHAP Summary Plot (全局解釋)">
    SHAP Summary Plot (全局解釋)
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#shap-force-plot" title="SHAP Force plot (單筆資料解釋)">
    SHAP Force plot (單筆資料解釋)
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#shap-waterfall-plot" title="SHAP waterfall plot (單筆資料解釋)">
    SHAP waterfall plot (單筆資料解釋)
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#permutation-importance" title="Permutation importance解釋全局模型">
    Permutation importance解釋全局模型
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#refernece" title="Refernece">
    Refernece
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content">
<article class="md-content__inner md-typeset"><a class="md-content__icon pdf-download-btn" download href="pdf/全民瘋AI系列_探索可解釋人工智慧_v1.1.pdf" title="Download"><i class="fa fas fa-download"></i><small> PDF</small></a>
<h1 id="day-26-xai">[Day 26] XAI在表格型資料的應用：解析智慧工廠中的鋼材缺陷</h1>
<p>在當今的工業領域中，智慧製造、碳中和以及數位雙生等議題受到廣泛關注。其中機器學習技術已經開始發揮關鍵作用，特別是在虛擬量測和異常檢測方面。在今天的內容中將帶各位深入探討工業應用實戰案例，即基於機器學習演算法的<a href="https://archive.ics.uci.edu/dataset/198/steel+plates+faults">鋼材缺陷偵測分類</a>。</p>
<h2 id="_1">[案例] 鋼鐵缺陷分類</h2>
<p>本案例使用的資料集來自 UCI（加州大學爾灣分校）的開放數據平台，這個平台致力於為機器學習研究者和實踐者提供高品質的資料集。該資料集涵蓋了鋼材製造過程中可能出現的多種缺陷情況，其中包含了7種帶鋼缺陷類型，具體分別是 Pastry、Z_Scratch、K_Scatch、Stains、Dirtiness、Bumps、Other_Faults。另外這個資料集是一個表格型的資料集，特別適用於機器學習和數據分析。它包含了27種不同的特徵，這些特徵描述了帶鋼的不同屬性和特點，如缺陷的大小、形狀、位置等等。這些數據都是在製造或生產過程中收集的，每一筆資料都有相對應的標籤，即缺陷種類。</p>
<p><img alt="" src="image/img26-1.png"/></p>
<p>表格型資料通常以逗號分隔檔(csv)呈現，每一列(row)代表一個觀測值或樣本，而每一行(col)代表一個特徵或標籤。在這個特定的資料集中，每一列可能代表一個時間點或生產批次，而每一行代表一組製程參數以及對應的標籤種類。這份資料集比較特別的是輸出的標籤是以 one hot encoding 的方式呈現。在等等的實作中我們必須將這些資料進行前處理，並取得相對應的標籤索引。</p>
<h3 id="_2">載入資料集</h3>
<p>首先透過 pandas 載入事先準備好的資料集。將 csv 檔案中的數據讀取並存儲在名為 df_data 的 DataFrame 變數中，以便後續的數據分析和處理。</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">url</span> <span class="o">=</span> <span class="s1">'https://raw.githubusercontent.com/andy6804tw/2023-15th-ironman/main/dataset/stell-faults.csv'</span>
<span class="n">df_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</pre></div>
<p>接著我們必須從 df_data 分離輸入特徵 X 與標籤 y。首先從資料集中提取出特徵欄位的名稱，然後將這些特徵的數據提取出來，存儲在變數 X 中。接著從資料中提取了包含標籤的 one hot encoding 數據，然後使用 <code>argmax()</code> 找到每個 one hot 向量中的最大值索引，將其視為對應的標籤，最終將這些標籤存儲在變數 y_labels 中。</p>
<div class="codehilite"><pre><span></span><span class="n">x_feature_names</span> <span class="o">=</span> <span class="n">df_data</span><span class="o">.</span><span class="n">columns</span><span class="p">[:</span><span class="o">-</span><span class="mi">7</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="c1"># 取得特徵欄位名稱</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_data</span><span class="p">[</span><span class="n">x_feature_names</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="c1"># 取出訓練資料特徵</span>
<span class="n">y_label_names</span> <span class="o">=</span> <span class="n">df_data</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="o">-</span><span class="mi">7</span><span class="p">:]</span><span class="o">.</span><span class="n">values</span> <span class="c1"># 取得標籤欄位名稱</span>
<span class="n">y_one_hot_array</span> <span class="o">=</span> <span class="n">df_data</span><span class="p">[</span><span class="n">y_label_names</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="c1"># 取出標籤</span>
<span class="c1"># 使用argmax函數找到每個one hot向量中的最大值索引，並將其視為對應的標籤</span>
<span class="n">y_labels</span> <span class="o">=</span> <span class="n">y_one_hot_array</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'The shape of X: </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'The shape of y_labels: </span><span class="si">{</span><span class="n">y_labels</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<p>從上面的輸出結果可以知道資料集總共有1941筆，每筆資料總共有27個特徵。</p>
<div class="codehilite"><pre><span></span>The shape of X: (1941, 27)
The shape of y_labels: (1941,)
</pre></div>
<h3 id="_3">切割訓練集與測試集</h3>
<p>這裡使用 sklearn 套件中的 <code>train_test_split()</code> 從原始資料集中切分出訓練集和測試集。test_size 參數設置0.1即代表從資料集1941筆中切1%比例作為測試集，random_state 確保每次運行結果相同，stratify 參數根據 y_labels 的類別分佈來確保訓練集和測試集中類別的分佈比例相似。</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># 切分資料集為訓練集和測試集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_labels</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y_labels</span><span class="p">)</span>

<span class="c1"># 觀察切割後資料的維度與筆數</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'The shape of X_train: </span><span class="si">{</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\t</span><span class="s1"> y_train: </span><span class="si">{</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'The shape of X_test: </span><span class="si">{</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\t</span><span class="s1"> y_test: </span><span class="si">{</span><span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<p>輸出結果：</p>
<div class="codehilite"><pre><span></span>The shape of X_train: (1746, 27)     y_train: (1746,)
The shape of X_test: (195, 27)       y_test: (195,)
</pre></div>
<p>資料集切割後我們觀察再訓練集中每個類別缺陷的數量分佈情況，可以透過 pandas 的 <code>value_counts()</code> 方法迅速計算每個不同類別的出現次數。通常，這個函數用於統計和分析資料中的類別型變數，以便了解每個類別的分佈情況。從下圖的結果可以觀察到，每個缺陷類別的數量分佈不均勻，其中 <code>Other_Faults</code> 類別的樣本數最多，共有666筆。相較之下 <code>Stains</code> 和 <code>Dirtiness</code> 類別的樣本數都不到100筆。這顯示了這個資料集存在明顯的標籤不平衡問題。</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># 查看七種類別筆數</span>
<span class="n">label_counts</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">sort</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">label_counts</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">'bar'</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">label_counts</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">y_label_names</span><span class="p">)</span>
<span class="c1"># 在每個bar上方顯示數值</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">label_counts</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">value</span><span class="p">),</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'bottom'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
<p><img alt="" src="image/img26-2.png"/></p>
<h3 id="smote">SMOTE處理標籤不平衡問題</h3>
<p>SMOTE（Synthetic Minority Over-sampling Technique）是一種用於處理標籤不平衡問題的技術，它的主要目標是合成新的少數類樣本，以平衡不同類別之間的數量差距。首先要安裝 <code>imbalanced-learn</code> 套件，如果尚未安裝，可以使用以下指令安裝：</p>
<div class="codehilite"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>imbalanced-learn
</pre></div>
<p>SMOTE 方法採用過取樣（Oversampling）技術，以合成新的樣本，以實現不同類別之間的平衡。從下圖的採樣結果可以看出，每個類別均有666筆數據。</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">SMOTE</span>

<span class="n">smo</span> <span class="o">=</span> <span class="n">SMOTE</span><span class="p">(</span><span class="n">sampling_strategy</span><span class="o">=</span><span class="s1">'auto'</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_smo</span><span class="p">,</span> <span class="n">y_smo</span> <span class="o">=</span> <span class="n">smo</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_labels</span><span class="p">)</span>
</pre></div>
<p><img alt="" src="image/img26-3.png"/></p>
<h3 id="lightgbm">建立LightGBM模型</h3>
<p>LightGBM 是輕量化 (Light) 的梯度提升機 (GBM) 的實例。其相對 XGBoost 來說它具有訓練速度快、記憶體佔用低的特點，因此近幾年 LightGBM 在 Kaggle 上也算是熱門模型一。在本飯範例中我們採用 LightGBM 分類器，若還沒安裝的讀者可以參考以下指令進行安裝。</p>
<div class="codehilite"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">lightgbm</span>
</pre></div>
<p>安裝結束後即可載入 lightgbm 套件並選用 LGBMClassifier 分類器進行模型訓練。</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">lightgbm</span> <span class="k">as</span> <span class="nn">lgb</span>

<span class="c1"># 建立模型</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">()</span>
<span class="c1"># 訓練模型</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>
<p>訓練結束後，我們可以透過 sklearn 的 <code>classification_report()</code> 方法來查看模型在測試集上的分類報告，該報告包含了模型的精確度、召回率、F1分數等評估指標，可以用來評估模型的性能。</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>


<span class="n">pred_test</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">))</span>
</pre></div>
<p>從評估報告中我們可以看到測試集總共有195筆，其中<code>0: Pastry</code>、<code>5: Bumps</code>和<code>6: Other_Faults</code>兩個的辨識率約七成。其餘的瑕疵類別都表現得不錯。</p>
<div class="codehilite"><pre><span></span>              precision    recall  f1-score   support

           0       0.63      0.75      0.69        16
           1       1.00      0.95      0.97        19
           2       0.93      0.95      0.94        39
           3       1.00      0.86      0.92         7
           4       1.00      0.83      0.91         6
           5       0.70      0.67      0.68        39
           6       0.74      0.75      0.75        69

    accuracy                           0.80       195
   macro avg       0.86      0.82      0.84       195
weighted avg       0.80      0.80      0.80       195
</pre></div>
<p>我們進一步從混淆矩陣（confusion matrix）中分析了哪些類別容易被誤判成其他類別。我們發現 <code>Other_Faults</code> 有少數幾筆容易跟 <code>Pastry</code> 和 <code>Bumps</code> 搞混 ，同時有11筆 <code>Bumps</code> 資料被誤判為 <code>Other_Faults</code>。</p>
<p><img alt="" src="image/img26-4.png"/></p>
<blockquote>
<p>透過混淆矩陣可以解釋分類模型在哪幾種類別表現較不好。</p>
</blockquote>
<h3 id="kernel-shap">Kernel SHAP 解釋模型</h3>
<p>建立一個通用的 KernelExplainer 解釋器，並試圖解釋剛剛訓練的 LightGBM 分類器。我們從訓練集中取出前 100 筆資料，以代表整體特徵值的分佈，用於進行模型解釋。然後，我們將使用測試集中的前 10 筆資料來計算 Shapley values。此外，我們將 nsamples 設定為 100，這表示我們將進行 100 次蒙地卡羅抽樣，從 KernelExplainer 設定的資料中隨機擾動抽樣，並建立一個 SHAP 簡化可解釋模型。</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">shap</span>
<span class="n">shap</span><span class="o">.</span><span class="n">initjs</span><span class="p">()</span>

<span class="c1"># 使用 Kernel SHAP 解釋模型</span>
<span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">KernelExplainer</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">X_train</span><span class="p">[:</span><span class="mi">100</span><span class="p">],</span> <span class="n">link</span><span class="o">=</span><span class="s1">'logit'</span><span class="p">)</span>
<span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_test</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="n">nsamples</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
<h4 id="shap-summary-plot">SHAP Summary Plot (全局解釋)</h4>
<p>我們可以使用 SHAP Summary Plot 來進行模型的全局解釋，該圖表顯示了每個特徵變量對整體平均模型輸出的平均影響。每個顏色代表不同的類別，因此我們可以觀察每個特徵對於模型預測輸出的平均貢獻程度，以及在不同類別下哪個特徵佔有較大的重要性。</p>
<div class="codehilite"><pre><span></span><span class="n">shap</span><span class="o">.</span><span class="n">summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">plot_type</span><span class="o">=</span><span class="s2">"bar"</span><span class="p">,</span> <span class="n">feature_names</span> <span class="o">=</span> <span class="n">x_feature_names</span><span class="p">)</span>
</pre></div>
<p>從下圖我們可以看到前三名重要的特徵為：
1. Steel_Plate_Thickness
2. Length_of_Conveyer
3. X_Maximum</p>
<p><img alt="" src="image/img26-5.png"/></p>
<h4 id="shap-force-plot">SHAP Force plot (單筆資料解釋)</h4>
<p>我們可以使用 Force Plot 方法觀察單一筆資料在模型中的預測情況。在 SHAP 套件中，Force Plot 提供了對單一模型預測的解釋性呈現。這個圖表清楚顯示了各個特徵對於模型對特定輸入值的預測所做的貢獻。從下圖結果中，我們可以看到模型預測結果為5（Bumps），其預測機率為 0.939。因此圖中的 Force Plot 是針對解釋為什麼這筆資料輸入會得到標籤為5的 Shapley values 解釋。</p>
<div class="codehilite"><pre><span></span><span class="c1"># 觀察測試集中第一筆資料預測的重要程度</span>
<span class="n">index</span><span class="o">=</span><span class="mi">0</span>
<span class="n">pred_class</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">[[</span><span class="n">index</span><span class="p">]])[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">pred_proba</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">[[</span><span class="n">index</span><span class="p">]])[</span><span class="mi">0</span><span class="p">][</span><span class="n">pred_class</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'測試集第 </span><span class="si">{</span><span class="n">index</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1"> 筆模型預測結果: </span><span class="si">{</span><span class="n">pred_class</span><span class="si">}</span><span class="s1"> 機率值: </span><span class="si">{</span><span class="n">pred_proba</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'真實答案: </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">index</span><span class="p">])</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="n">shap</span><span class="o">.</span><span class="n">force_plot</span><span class="p">(</span><span class="n">explainer</span><span class="o">.</span><span class="n">expected_value</span><span class="p">[</span><span class="n">pred_class</span><span class="p">],</span> <span class="n">shap_values</span><span class="p">[</span><span class="n">pred_class</span><span class="p">][</span><span class="n">index</span><span class="p">],</span> <span class="n">X_test</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">x_feature_names</span><span class="p">,</span> <span class="n">link</span><span class="o">=</span><span class="s1">'logit'</span><span class="p">)</span>
</pre></div>
<p><img alt="" src="image/img26-6.png"/></p>
<h4 id="shap-waterfall-plot">SHAP waterfall plot (單筆資料解釋)</h4>
<p>我們可以更近一步地用瀑布圖視覺化排序重要的特徵，同時觀看每個特徵的相對應 Shapley values。</p>
<p><img alt="" src="image/img26-7.png"/></p>
<div class="codehilite"><pre><span></span><span class="n">shap</span><span class="o">.</span><span class="n">waterfall_plot</span><span class="p">(</span><span class="n">shap</span><span class="o">.</span><span class="n">Explanation</span><span class="p">(</span><span class="n">values</span><span class="o">=</span><span class="n">shap_values</span><span class="p">[</span><span class="n">pred_class</span><span class="p">][</span><span class="n">index</span><span class="p">],</span> 
                                    <span class="n">base_values</span><span class="o">=</span><span class="n">explainer</span><span class="o">.</span><span class="n">expected_value</span><span class="p">[</span><span class="n">pred_class</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="n">index</span><span class="p">],</span>  
                                    <span class="n">feature_names</span><span class="o">=</span><span class="n">x_feature_names</span><span class="p">),</span>
                                    <span class="n">max_display</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
</pre></div>
<blockquote>
<p>全部特徵的Shapley value總和加上基準值，最後再通過Sigmoid函數就是輸出的機率值了。</p>
</blockquote>
<h3 id="permutation-importance">Permutation importance解釋全局模型</h3>
<p>在本系列中 <a href="https://ithelp.ithome.com.tw/articles/10325613">Day 10</a> 介紹了利用特徵擾動的方法解釋整個模型，當時使用了 <code>eli5</code> 實作特徵重要程度的排序。這裡再分享另一個方法實作，那就是使用 <a href="https://scikit-learn.org/stable/modules/permutation_importance.html4">sklearn</a> 套件中的 <code>permutation_importance()</code>。</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.inspection</span> <span class="kn">import</span> <span class="n">permutation_importance</span>

<span class="c1"># 使用 permutation_importance 函數計算特徵重要性</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">permutation_importance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">'accuracy'</span><span class="p">)</span>

<span class="c1"># 印出各特徵的平均重要性排序</span>
<span class="n">sorted_idx</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">importances_mean</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sorted_idx</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">x_feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">&lt;10</span><span class="si">}</span><span class="s2"> importance: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">importances_mean</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> +/- </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">importances_std</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<p>從下圖可以觀察模型在評估每個瑕疵時所使用的重要特徵排序。另外可以將這些排序結果與 SHAP Summary Plot 的全局解釋進行比對，以檢查不同方法在模型特徵重要性排序方面是否具有一致性。由於理論方法和資料抽樣的隨機性，無法保證每種方法的解釋都完全相同，但我們可以透過尋找共通的解釋來增強可信度。</p>
<p><img alt="" src="image/img26-8.png"/></p>
<p>本系列教學內容及範例程式都可以從我的 <a href="https://github.com/andy6804tw/2023-15th-ironman">GitHub</a> 取得！</p>
<h2 id="refernece">Refernece</h2>
<ul>
<li>
<p><a href="https://archive.ics.uci.edu/dataset/198/steel+plates+faults">UCI 資料集：Steel Plates Faults</a></p>
</li>
<li>
<p><a href="https://zhuanlan.zhihu.com/p/498131022">鋼材缺陷偵測分類：LightGBM王者登頂</a></p>
</li>
</ul>
</article>
</div>
</div>
</main>
<footer class="md-footer">
<div class="md-footer-nav">
<nav class="md-footer-nav__inner md-grid">
<a class="md-flex md-footer-nav__link md-footer-nav__link--prev" href="25. XAI在影像處理中的瑕疵檢測:解釋卷積神經網路的運作.html" rel="prev" title="[Day 25] XAI在影像處理中的瑕疵檢測:解釋卷積神經網路的運作">
<div class="md-flex__cell md-flex__cell--shrink">
<i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
</div>
<div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
<span class="md-flex__ellipsis">
<span class="md-footer-nav__direction">
                  上一頁
                </span>
                [Day 25] XAI在影像處理中的瑕疵檢測:解釋卷積神經網路的運作
              </span>
</div>
</a>
<a class="md-flex md-footer-nav__link md-footer-nav__link--next" href="27. XAI在NLP中的應用:以情感分析解釋語言模型.html" rel="next" title="[Day 27] XAI在NLP中的應用:以情感分析解釋語言模型">
<div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
<span class="md-flex__ellipsis">
<span class="md-footer-nav__direction">
                  下一頁
                </span>
                [Day 27] XAI在NLP中的應用:以情感分析解釋語言模型
              </span>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
</div>
</a>
</nav>
</div>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-footer-copyright">
<div class="md-footer-copyright__highlight">
            Copyright © 2023 - 2024 10程式中
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
</div>
</div>
</div>
</footer>
</div>
<script src="assets/javascripts/application.245445c6.js"></script>
<script src="assets/javascripts/lunr/lunr.stemmer.support.js"></script>
<script src="assets/javascripts/lunr/tinyseg.js"></script>
<script src="assets/javascripts/lunr/lunr.ja.js"></script>
<script>app.initialize({version:"1.0.4",url:{base:"."}})</script>
<script src="javascripts/extra.js"></script>
</body>
</html>