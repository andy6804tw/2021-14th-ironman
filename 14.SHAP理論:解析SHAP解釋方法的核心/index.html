
<!DOCTYPE html>

<html class="no-js" lang="zh-Hant">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="ie=edge" http-equiv="x-ua-compatible"/>
<meta content="10程式中" name="author"/>
<meta content="複製" name="lang:clipboard.copy"/>
<meta content="已複製" name="lang:clipboard.copied"/>
<meta content="ja" name="lang:search.language"/>
<meta content="True" name="lang:search.pipeline.stopwords"/>
<meta content="True" name="lang:search.pipeline.trimmer"/>
<meta content="沒有符合的項目" name="lang:search.result.none"/>
<meta content="找到 1 個符合的項目" name="lang:search.result.one"/>
<meta content="找到 # 個符合的項目" name="lang:search.result.other"/>
<meta content="[\uff0c\u3002]+" name="lang:search.tokenizer"/>
<link href="../assets/images/favicon.png" rel="shortcut icon"/>
<meta content="mkdocs-1.0.4, mkdocs-material-4.4.0" name="generator"/>
<title>[Day 14] SHAP理論：解析SHAP解釋方法的核心 - 全民瘋AI系列 [探索可解釋人工智慧]</title>
<link href="../assets/stylesheets/application.0284f74d.css" rel="stylesheet"/>
<link href="../assets/stylesheets/application-palette.01803549.css" rel="stylesheet"/>
<meta content="#7e57c2" name="theme-color"/>
<script src="../assets/javascripts/modernizr.74668098.js"></script>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&amp;display=fallback" rel="stylesheet"/>
<style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
<link href="../assets/fonts/material-icons.css" rel="stylesheet"/>
<link href="../stylesheets/extra.css" rel="stylesheet"/>
</head>
<body data-md-color-accent="deep-purple" data-md-color-primary="deep-purple" dir="ltr">
<svg class="md-svg">
<defs>
<svg height="448" id="__github" viewbox="0 0 416 448" width="416" xmlns="http://www.w3.org/2000/svg"><path d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z" fill="currentColor"></path></svg>
</defs>
</svg>
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
<a class="md-skip" href="#day-14-shapshap" tabindex="1">
        跳轉到
      </a>
<header class="md-header" data-md-component="header">
<nav class="md-header-nav md-grid">
<div class="md-flex">
<div class="md-flex__cell md-flex__cell--shrink">
<a class="md-header-nav__button md-logo" href=".." title="全民瘋AI系列 [探索可解釋人工智慧]">
<i class="md-icon"></i>
</a>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
</div>
<div class="md-flex__cell md-flex__cell--stretch">
<div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
<span class="md-header-nav__topic">
              全民瘋AI系列 [探索可解釋人工智慧]
            </span>
<span class="md-header-nav__topic">
              
                [Day 14] SHAP理論：解析SHAP解釋方法的核心
              
            </span>
</div>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="query" data-md-state="active" name="query" placeholder="搜尋" spellcheck="false" type="text"/>
<label class="md-icon md-search__icon" for="__search"></label>
<button class="md-icon md-search__icon" data-md-component="reset" tabindex="-1" type="reset">
        
      </button>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="result">
<div class="md-search-result__meta">
            打字進行搜尋
          </div>
<ol class="md-search-result__list"></ol>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<div class="md-header-nav__source">
<a class="md-source" data-md-source="github" href="https://github.com/andy6804tw/crazyai-xai" title="前往倉庫">
<div class="md-source__icon">
<svg height="24" viewbox="0 0 24 24" width="24">
<use height="24" width="24" xlink:href="#__github"></use>
</svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
</div>
</div>
</nav>
</header>
<div class="md-container">
<main class="md-main">
<div class="md-main__inner md-grid" data-md-component="container">
<div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav class="md-nav md-nav--primary" data-md-level="0">
<label class="md-nav__title md-nav__title--site" for="__drawer">
<a class="md-nav__button md-logo" href=".." title="全民瘋AI系列 [探索可解釋人工智慧]">
<i class="md-icon"></i>
</a>
    全民瘋AI系列 [探索可解釋人工智慧]
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-source="github" href="https://github.com/andy6804tw/crazyai-xai" title="前往倉庫">
<div class="md-source__icon">
<svg height="24" viewbox="0 0 24 24" width="24">
<use height="24" width="24" xlink:href="#__github"></use>
</svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" id="nav-1" type="checkbox"/>
<label class="md-nav__link" for="nav-1">
      1.XAI基礎與概念介紹
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-1">
        1.XAI基礎與概念介紹
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../1.揭開模型的神秘面紗:為何XAI對機器學習如此重要/" title="[Day 1] 揭開模型的神秘面紗：為何XAI對機器學習如此重要？">
      [Day 1] 揭開模型的神秘面紗：為何XAI對機器學習如此重要？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2.從黑盒到透明化:XAI技術的發展之路/" title="[Day 2] 從黑盒到透明化：XAI技術的發展之路">
      [Day 2] 從黑盒到透明化：XAI技術的發展之路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../3.機器學習中的可解釋性指標/" title="[Day 3] 機器學習中的可解釋性指標">
      [Day 3] 機器學習中的可解釋性指標
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../4.LIME vs SHAP:哪種XAI解釋方法更適合你/" title="[Day 4] LIME vs. SHAP：哪種XAI解釋方法更適合你？">
      [Day 4] LIME vs. SHAP：哪種XAI解釋方法更適合你？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../5.淺談XAI與傳統機器學習的區別/" title="[Day 5] 淺談XAI與傳統機器學習的區別">
      [Day 5] 淺談XAI與傳統機器學習的區別
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" id="nav-2" type="checkbox"/>
<label class="md-nav__link" for="nav-2">
      2.XAI在傳統機器學習中的應用
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-2">
        2.XAI在傳統機器學習中的應用
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../6.非監督學習也能做到可解釋性-探索XAI在非監督學習中的應用/" title="[Day 6] 非監督學習也能做到可解釋性？探索XAI在非監督學習中的應用">
      [Day 6] 非監督學習也能做到可解釋性？探索XAI在非監督學習中的應用
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../7.KNN與XAI:從鄰居中找出模型的決策邏輯/" title="[Day 7] KNN與XAI：從鄰居中找出模型的決策邏輯">
      [Day 7] KNN與XAI：從鄰居中找出模型的決策邏輯
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../8.解釋線性模型:探索線性迴歸和邏輯迴歸的可解釋性/" title="[Day 8] 解釋線性模型：探索線性迴歸和邏輯迴歸的可解釋性">
      [Day 8] 解釋線性模型：探索線性迴歸和邏輯迴歸的可解釋性
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../9.基於樹狀結構的XAI方法:決策樹的可解釋性/" title="[Day 9] 基於樹狀結構的XAI方法：決策樹的可解釋性">
      [Day 9] 基於樹狀結構的XAI方法：決策樹的可解釋性
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../10.Permutation Importance:從特徵重要性角度解釋整個模型行為/" title="[Day 10] Permutation Importance：從特徵重要性角度解釋整個模型行為">
      [Day 10] Permutation Importance：從特徵重要性角度解釋整個模型行為
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../11.Partial Dependence Plot:探索特徵對預測值的影響/" title="[Day 11] Partial Dependence Plot：探索特徵對預測值的影響">
      [Day 11] Partial Dependence Plot：探索特徵對預測值的影響
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-toggle md-nav__toggle" data-md-toggle="nav-3" id="nav-3" type="checkbox"/>
<label class="md-nav__link" for="nav-3">
      3.XAI常用工具介紹
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-3">
        3.XAI常用工具介紹
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../12.LIME理論:如何用局部線性近似解釋黑箱模型/" title="[Day 12] LIME理論：如何用局部線性近似解釋黑箱模型">
      [Day 12] LIME理論：如何用局部線性近似解釋黑箱模型
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../13.LIME實作:實戰演練LIME解釋方法/" title="[Day 13] LIME實作：實戰演練LIME解釋方法">
      [Day 13] LIME實作：實戰演練LIME解釋方法
    </a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-toggle md-nav__toggle" data-md-toggle="toc" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
        [Day 14] SHAP理論：解析SHAP解釋方法的核心
      </label>
<a class="md-nav__link md-nav__link--active" href="./" title="[Day 14] SHAP理論：解析SHAP解釋方法的核心">
      [Day 14] SHAP理論：解析SHAP解釋方法的核心
    </a>
<nav class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">本頁目錄</label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#shapley-values" title="Shapley values 簡介">
    Shapley values 簡介
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#shapley-values_1" title="簡單例子解釋 Shapley values">
    簡單例子解釋 Shapley values
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#shap-shapley-additive-explanations" title="SHAP (SHapley Additive exPlanations)">
    SHAP (SHapley Additive exPlanations)
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#kernelexplainer" title="解析 KernelExplainer 背後原理">
    解析 KernelExplainer 背後原理
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#reference" title="Reference">
    Reference
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../15.SHAP實作:實戰演練SHAP解釋方法/" title="[Day 15] SHAP實作：實戰演練SHAP解釋方法">
      [Day 15] SHAP實作：實戰演練SHAP解釋方法
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" id="nav-4" type="checkbox"/>
<label class="md-nav__link" for="nav-4">
      4.XAI在深度學習中的可解釋性
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-4">
        4.XAI在深度學習中的可解釋性
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../16.神經網路的可解釋性:如何理解深度學習中的黑箱模型/" title="[Day 16] 神經網路的可解釋性：如何理解深度學習中的黑箱模型？">
      [Day 16] 神經網路的可解釋性：如何理解深度學習中的黑箱模型？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../17.解析深度神經網路:使用Deep SHAP進行模型解釋/" title="[Day 17] 解析深度神經網路：使用Deep SHAP進行模型解釋">
      [Day 17] 解析深度神經網路：使用Deep SHAP進行模型解釋
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../18.CNN卷積深度神經網路的解釋方法/" title="[Day 18] CNN：卷積深度神經網路的解釋方法">
      [Day 18] CNN：卷積深度神經網路的解釋方法
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../19.Perturbation Based如何用擾動方法解釋神經網路/" title="[Day 19] Perturbation-Based：如何用擾動方法解釋神經網路">
      [Day 19] Perturbation-Based：如何用擾動方法解釋神經網路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../20.Gradient Based利用梯度訊息解釋神經網路/" title="[Day 20] Gradient-Based：利用梯度訊息解釋神經網路">
      [Day 20] Gradient-Based：利用梯度訊息解釋神經網路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../21.Propagation Based探索反向傳播法的可解釋性/" title="[Day 21] Propagation-Based：探索反向傳播法的可解釋性">
      [Day 21] Propagation-Based：探索反向傳播法的可解釋性
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../22.CAM Based如何解釋卷積神經網路/" title="[Day 22] CAM-Based：如何解釋卷積神經網路">
      [Day 22] CAM-Based：如何解釋卷積神經網路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../23.Attention Based使用注意力機制解釋CNN模型/" title="[Day 23] Attention-Based：使用注意力機制解釋CNN模型">
      [Day 23] Attention-Based：使用注意力機制解釋CNN模型
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" id="nav-5" type="checkbox"/>
<label class="md-nav__link" for="nav-5">
      5.XAI在現實生活中的應用案例
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-5">
        5.XAI在現實生活中的應用案例
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../24.LSTM的可解釋性:解析步態分類中的時序資料/" title="[Day 24] LSTM的可解釋性：從時序資料解析人體姿態預測">
      [Day 24] LSTM的可解釋性：從時序資料解析人體姿態預測
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../25.XAI在影像處理中的瑕疵檢測:解釋卷積神經網路的運作/" title="[Day 25] XAI在影像處理中的瑕疵檢測：解釋卷積神經網路的運作">
      [Day 25] XAI在影像處理中的瑕疵檢測：解釋卷積神經網路的運作
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../26.智慧工廠製程中的鋼材缺陷檢測:運用XAI解析數值型感測器數據/" title="[Day 26] XAI在表格型資料的應用：解析智慧工廠中的鋼材缺陷">
      [Day 26] XAI在表格型資料的應用：解析智慧工廠中的鋼材缺陷
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../27.XAI在NLP中的應用:以情感分析解釋語言模型/" title="[Day 27] XAI在NLP中的應用：以情感分析解釋語言模型">
      [Day 27] XAI在NLP中的應用：以情感分析解釋語言模型
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" id="nav-6" type="checkbox"/>
<label class="md-nav__link" for="nav-6">
      6.XAI的挑戰與未來
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-6">
        6.XAI的挑戰與未來
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../28.誤差分析和對抗樣本:如何利用XAI檢測模型的弱點/" title="[Day 28] 對抗樣本的挑戰：如何利用XAI檢測模型的弱點？">
      [Day 28] 對抗樣本的挑戰：如何利用XAI檢測模型的弱點？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../29.XAI如何影響人類對技術的信任和接受程度/" title="[Day 29] XAI如何影響人類對技術的信任和接受程度？">
      [Day 29] XAI如何影響人類對技術的信任和接受程度？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../30.XAI未來發展方向:向更可靠的機器學習模型邁進/" title="[Day30] XAI未來發展方向：向更可靠的機器學習模型邁進">
      [Day30] XAI未來發展方向：向更可靠的機器學習模型邁進
    </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">本頁目錄</label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#shapley-values" title="Shapley values 簡介">
    Shapley values 簡介
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#shapley-values_1" title="簡單例子解釋 Shapley values">
    簡單例子解釋 Shapley values
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#shap-shapley-additive-explanations" title="SHAP (SHapley Additive exPlanations)">
    SHAP (SHapley Additive exPlanations)
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#kernelexplainer" title="解析 KernelExplainer 背後原理">
    解析 KernelExplainer 背後原理
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#reference" title="Reference">
    Reference
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content">
<article class="md-content__inner md-typeset"><a class="md-content__icon pdf-download-btn" download href="../pdf/全民瘋AI系列_探索可解釋人工智慧_v1.1.pdf" title="Download"><i class="fa fas fa-download"></i><small> PDF</small></a>
<h1 id="day-14-shapshap">[Day 14] SHAP理論：解析SHAP解釋方法的核心</h1>
<h2 id="shapley-values">Shapley values 簡介</h2>
<p>Shapley values 最早是由經濟學家 Lloyd Shapley 所提出，用於評估參與合作博弈的每個玩家對於勝利的貢獻價值。在機器學習中，我們可以將這個概念應用到輸入特徵 X 對於輸出的影響上，透過 Shapley values 可以計算每個特徵對於輸出的貢獻。簡單來說，Shapley values 計算的是在各種情況下，如果某個特徵被加入到模型中，它會帶來多少額外的貢獻。最後我們將所有特徵的額外貢獻的期望值加總，就得到了所謂的 Shapley values。透過這種方法可以幫助我們理解模型中每個特徵對於輸出的影響程度，進而提高模型的可解釋性和可信度。</p>
<h2 id="shapley-values_1">簡單例子解釋 Shapley values</h2>
<p>假設團隊有三個人共同接了一個案子，根據每個人的貢獻程度將酬勞按比例分配。透過計算 Shapley values，我們能夠評估每個成員在完成任務時的貢獻大小，以實現更公平的酬勞分配。以下是三個成員的性格特質及在互相合作和獨立作業時所能達成的貢獻分數。其分數範圍在0到100之間，代表他們參與完成案子的能力與效率。</p>
<ul>
<li>A(工程師) 喜歡獨立作業，能力強，是團隊中的核心人物。</li>
<li>B(工程師) 謹慎按部就班，能確保任務進行順利且無差錯。</li>
<li>C(專案經理) 無產出能力，但擅於溝通並管理整個團隊的工作。</li>
</ul>
<p>從下表中可以依據三位在團隊中加入的順序進行排列組合，其中 𝜙 代表團隊都沒有人的情況下產出當然為 0，接著可以得知 A、B、C 三人獨立工作的分數分別為 90, 60, 0。至於合作的部分 A+B 共同工作的產出為 80，從這組合當中可以發現 B 的加入使得共同產出下降了 10(A就是典型的單打獨鬥，有人插手反而拖累進度)。其餘的 A+C 和 B+C 的工作產出分別為 70 和 80。最後 A+B+C 三人各自發揮專長，且有了 C 的溝同協調才使得工作順利完成使分數得到滿分 100。</p>
<p><img alt="" src="../image/img14-1.png"/></p>
<p>有了上表產出分數後，我們就可以去計算每個人在團隊的貢獻值。其計算方式根據所有組隊成員加入的所有順序，再去計算在各種順序下每個人額外的貢獻個是多少。首先計算 A 的貢獻程度，三個人總共有六種加入的組合順序，如下表所示：</p>
<p><img alt="" src="../image/img14-2.png"/></p>
<ul>
<li>首先第一個加入順序為 A,B,C， A 所扮演的角色為第一個因此是 90。</li>
<li>第二個組合 A,C,B 跟第一個案例一樣由於 A 加入時還是空的因此還是由 A 自己出力貢獻為 90。</li>
<li>若 B,A,C 的順序由 B 先做然後 A 再加入，此時 A 有加入或沒加入的差別就是 A 和 B 一起組隊，或是 B 自己。因此 A 在這一組合中所帶來額外的貢獻為 (A+B)-B=20。</li>
<li>若 B,C,A 的話 A 所帶來的額外貢獻為，(A+B+C)-(B+C)=30</li>
<li>若 C,A,B 的話 A 所帶來的額外貢獻為，(A+C)-(C)=70</li>
<li>若 C,B,A 的話 A 所帶來的額外貢獻為，(A+B+C)-(B+C)=30</li>
</ul>
<p>到目前為止已經計算完在所有的加入組合順序中 A 所帶來的額外貢獻，因此 A 的 Shapley values 就是將所有的組合的貢獻分數做一個平均得到 55。</p>
<p><img alt="" src="../image/img14-3.png"/></p>
<p>上面步驟依此類推在六種組隊可能的順序中為每個人分別計算帶來的額外貢獻分數，平均就可以得到在這一個任務中每個人的貢獻程度了。最後我們可以分別計算出 A、B 和 C 的 Shapley values，如下表所示，最後得到 A 為 55， B 為 40，C 為 5，可以發現這三個值相加其實就等於 100。</p>
<p><img alt="" src="../image/img14-4.png"/></p>
<h2 id="shap-shapley-additive-explanations">SHAP (SHapley Additive exPlanations)</h2>
<p>以上述的例子每個人就等同於機器學習中的 X 特徵，而 y 就是輸出。我們要觀察每個特徵 X 對於計算 y 的貢獻程度有多少，因此我們必須去計算所有特徵的 Shapley values 各是多少。但是當 X 的特徵數量太多的時候，假設有 d 個特徵的時候我們就相當於要計算 2的d次方-1種可能性，這也意味著要個別訓練這麼多模型。假設有兩個特徵，則要計算 Shapley values 就必須訓練三個模型：</p>
<ul>
<li>第一個模型：f(x1)</li>
<li>第二個模型：f(x2)</li>
<li>第三個模型：f(x1, x2)</li>
</ul>
<p>若特徵數量太多的時候訓練大量的模型代價是很高的，因此可以透過 SHAP (SHapley Additive exPlanations) 來計算特徵的重要性，進而解釋模型的預測結果，而不需要訓練大量的模型。本篇的主角 SHAP 是一種解釋性技術，它就是使用 Shapley values 的概念來評估每個特徵對於模型預測的貢獻。SHAP 提供了以下幾種 kernel 來快速估計 Shapley values：</p>
<ul>
<li>TreeExplainer</li>
<li>DeepExplainer</li>
<li>GradientExplainer</li>
<li>LinearExplainer</li>
<li>KernelExplainer </li>
</ul>
<p>每一個 kernel 的簡單介紹可以參考本系列<a href="">[Day 4] LIME vs. SHAP：哪種XAI解釋方法更適合你？</a>，而在今日的文章中我們將重點放在通用的 KernelExplainer，它主要透過生成新的擾動資料來近似計算 SHAP，且適用於各種不同類型的模型。</p>
<h2 id="kernelexplainer">解析 KernelExplainer 背後原理</h2>
<p>以下解釋採用 kernel shap 的方式來估計 Shapley values。假設第 i 筆資料 d 個特徵長像下面這樣子。我們要另外建立一個長度為 d 的 z 向量，這裡的 z 就好比每個特徵是否要被考慮因此不是1(出現)就是0(忽略)。</p>
<p><img alt="" src="../image/img14-5.png"/></p>
<p>h(z) 就是將一組特徵透過 z 來決定要觀察哪些特徵，假設 x=[1,2,3,4]、z=[1,0,1,0] 就是要保留第一跟第三個特徵。因此 h(z)=[1, 隨機, 3, 隨機]，所謂的忽略就是隨機的從訓練資料集中取一筆資料出來將第二和四個特徵放入取代隨機。因此 xk 就是隨機從訓練資料集抽取的一筆資料。</p>
<p><img alt="" src="../image/img14-6.png"/></p>
<p>所以 h(z) 其實就是一個 one-to-many 的映射，由於會隨機的抽取資料取代0位置的數值。如果我們用這種方式產生很多組 z 的話會產生 2 的d次方的可能性。</p>
<p><img alt="" src="../image/img14-7.png"/></p>
<p>還記得我們在 Day4 解釋 SHAP 運作原理的例子嗎？假設有輸入四個特徵，年齡、性別、血壓、BMI作為輸入要預測一個人罹癌的機率。𝜙0 就是基準點 base rate 這裡為 0.1，表示每個人都有 0.1 的機率罹癌。𝜙1～𝜙4 代表四個特徵對罹癌的貢獻值，全部相加起來就是那個人離癌的幾率了。因此 SHAP 就是要訓練一個模型 g() 要學習每個 𝜙。</p>
<ul>
<li>g(z): 為被簡化的可解釋的模型</li>
<li>z: 表示每個特徵是否要被考慮，1(出現)、0(忽略)</li>
<li>d: 輸入特徵的個數</li>
<li>𝜙0: 代表基準值</li>
<li>𝜙j: 代表每個特徵的Shapley values</li>
</ul>
<p><img alt="" src="../image/img14-8.png"/></p>
<p>g() 是 SHAP 自行定義的模型，其目標是希望 g(z) 能夠接近於 f(h(z))。換句話說，如果對於第 i 筆資料樣本 x=[1,2,3,4] 以及 z=[1,0,1,0]，只觀察第一和第三個特徵時，f(h(z)) 的預測結果將會趨近於 g(z) 也就是 𝜙0+𝜙1+𝜙3。</p>
<p><img alt="" src="../image/img14-9.png"/></p>
<p>請各位回想一下之前在做 LIME 的時候需要從資料抽一些樣本要與被觀察的那筆資料計算距離，越近就代表越重要。因此 kernel shape 的方法中也是要給予權重的概念，但方法不同。差別在於它的 loss function 後面多了 π(z) 也就是所謂的權重，這個權重的決定取決於 z 有多少個1。</p>
<p><img alt="" src="../image/img14-10.png"/></p>
<p>延續剛剛的例子假設我們要觀察第一和第三個特徵時，損失函數中最後一項 π(z) 的計算方式直接套入上面式子。代表這筆資料猜對的重要程度，其中 c(4,2) 代表排列組合中的 C4 取 2。表示在有 4 個元素的集合中，選取 2 個元素的組合數量。</p>
<p><img alt="" src="../image/img14-11.png"/></p>
<p>在 Kernel SHAP 中，對於特徵子集的抽樣是通過進行 Monto Carlo 抽樣的方式進行的。預設情況下，當特徵小於等於11個特徵時，SHAP 演算法會抽取 nsamples 數量為 <code>2**M - 2</code> 筆資料。而特徵數量大於11個時，會抽取 nsamples = <code>2*M + 2048</code> 個特徵子集作為近似計算的樣本，其中 M 是特徵的數量。會有這樣的機制是因為當特徵數量增加時，為了保持計算效率，Kernel SHAP 會進行抽樣，只包含部分特徵子集，但仍然能夠提供合理的解釋整個模型。</p>
<ul>
<li>當M&lt;=11個特徵以下： nsamples = 2**M-2</li>
<li>當M&gt;11個以上： nsamples = 2*M + 2048</li>
</ul>
<blockquote>
<p>詳細資訊可以直接參考 Kernel SHAP 的原始<a href="https://github.com/shap/shap/blob/master/shap/explainers/_kernel.py#L311">程式碼</a>。</p>
</blockquote>
<p>簡單來說 SHAP 的套件實現會根據特徵數量和計算成本採取適當的抽樣策略，以提供近似的 Shapley 值計算結果。對於小特徵集，它會包含所有可能的特徵組合，對於大型特徵集，則透過抽樣方式來有效估計 Shapley 值。</p>
<blockquote>
<p>由於 Kernel SHAP 對模型類型沒有假設，它的速度比其他特定於模型類型的算法慢例如像是 Tree SHAP。</p>
</blockquote>
<h2 id="reference">Reference</h2>
<ul>
<li>
<p>Scott Lundberg, et al. "<a href="https://arxiv.org/abs/1705.07874">A Unified Approach to Interpreting Model Predictions</a>." Arxiv, 2017.</p>
</li>
<li>
<p>Kjersti Aas, et al. "<a href="https://arxiv.org/abs/1903.10464">Explaining individual predictions when features are dependent: More accurate approximations to Shapley values</a>." Arxiv, 2019.</p>
</li>
</ul>
</article>
</div>
</div>
</main>
<footer class="md-footer">
<div class="md-footer-nav">
<nav class="md-footer-nav__inner md-grid">
<a class="md-flex md-footer-nav__link md-footer-nav__link--prev" href="../13.LIME實作:實戰演練LIME解釋方法/" rel="prev" title="[Day 13] LIME實作：實戰演練LIME解釋方法">
<div class="md-flex__cell md-flex__cell--shrink">
<i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
</div>
<div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
<span class="md-flex__ellipsis">
<span class="md-footer-nav__direction">
                  上一頁
                </span>
                [Day 13] LIME實作：實戰演練LIME解釋方法
              </span>
</div>
</a>
<a class="md-flex md-footer-nav__link md-footer-nav__link--next" href="../15.SHAP實作:實戰演練SHAP解釋方法/" rel="next" title="[Day 15] SHAP實作：實戰演練SHAP解釋方法">
<div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
<span class="md-flex__ellipsis">
<span class="md-footer-nav__direction">
                  下一頁
                </span>
                [Day 15] SHAP實作：實戰演練SHAP解釋方法
              </span>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
</div>
</a>
</nav>
</div>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-footer-copyright">
<div class="md-footer-copyright__highlight">
            Copyright © 2023 - 2024 10程式中
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
</div>
</div>
</div>
</footer>
</div>
<script src="../assets/javascripts/application.245445c6.js"></script>
<script src="../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
<script src="../assets/javascripts/lunr/tinyseg.js"></script>
<script src="../assets/javascripts/lunr/lunr.ja.js"></script>
<script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
<script src="../javascripts/extra.js"></script>
<script src="../javascripts/analytics.js"></script>
</body>
</html>