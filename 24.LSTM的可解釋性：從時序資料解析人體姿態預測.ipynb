{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mobile Health Human Behavior Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 設定亂數種子數值\n",
    "seed_value= 4\n",
    "# 1. 設定 Python 環境變數亂數種子\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "# 2. 設定 Python 內建亂數生成器亂數種子\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "# 3. 設定 Numpy 亂數種子\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "# 4. 設定 TensorFlow 亂數種子\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Colab 進行matplotlib繪圖時顯示繁體中文\n",
    "# 下載台北思源黑體並命名taipei_sans_tc_beta.ttf，移至指定路徑\n",
    "!gdown 1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.font_manager import fontManager\n",
    "\n",
    "fontManager.addfont('TaipeiSansTCBeta-Regular.ttf')\n",
    "mpl.rc('font', family='Taipei Sans TC Beta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入資料集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AhU9zQG2Tet"
   },
   "source": [
    "- L1: Standing still (1 min)\n",
    "- L2: Sitting and relaxing (1 min)\n",
    "- L3: Lying down (1 min)\n",
    "- L4: Walking (1 min)\n",
    "- L5: Climbing stairs (1 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_data =  pd.read_csv('https://github.com/andy6804tw/2023-15th-ironman/raw/main/dataset/mHealth_subject1.csv')\n",
    "x_feature_names = ['acc_l_ankle_x','acc_l_ankle_y','acc_l_ankle_z','gyro_l_ankle_x','gyro_l_ankle_y','gyro_l_ankle_z']\n",
    "y_feature_name = ['label']\n",
    "y_label_names = ['站立', '靜坐', '平躺', '走路', '上樓']\n",
    "df_data = df_data[x_feature_names + y_feature_name]\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "依 label 將資料切割，資料取樣率為50Hz，每種動作分別搜集約一分鐘的訊號，因此每筆資料大小約 3072 rows x 4 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xcbUWroj1CqQ",
    "outputId": "476ba975-7c83-488f-c371-72bdb6ca2647",
    "tags": []
   },
   "outputs": [],
   "source": [
    "L1 = df_data.loc[ df_data.label == 1] #L1: 站立 (1 min) \n",
    "L2 = df_data.loc[ df_data.label == 2] #L2: 靜坐 (1 min)\n",
    "L3 = df_data.loc[ df_data.label == 3] #L3: 平躺 (1 min)\n",
    "L4 = df_data.loc[ df_data.label == 4] #L4: 走路 (1 min)\n",
    "L5 = df_data.loc[ df_data.label == 5] #L5: 上樓 (1 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料視覺化\n",
    "顯示前500筆(10秒)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0-o-ttSZp9C",
    "outputId": "f1519fa1-a871-4bd2-c0f7-1bc462af916c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_data_10s(data, title, normalize=True):\n",
    "    data_10s = data.loc[ : ,\"acc_l_ankle_x\":\"gyro_l_ankle_z\"]\n",
    "    data_10s = data_10s[ :500]\n",
    "    data_10s = data_10s.reset_index(drop=True)\n",
    "    if(normalize):\n",
    "        # 經過標準化 sqrt(變異數) = 標準差\n",
    "        mean = data_10s.mean(axis=0)\n",
    "        std = data_10s.std(axis=0)\n",
    "        data_10s -= mean\n",
    "        data_10s /= std\n",
    "    chart = data_10s.plot( #kind='bar',  #圖表類型\n",
    "            title=title,\n",
    "            legend=True,  # 是否顯示圖例\n",
    "            figsize=(10, 5))  # 圖表大小\n",
    "    if(normalize):\n",
    "        plt.ylim((-5,5))\n",
    "    else:\n",
    "        plt.ylim((-30,30))\n",
    "    # plt.savefig(f'{title}.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "AejART0IQf1a",
    "outputId": "2f06020a-60f5-4259-a623-9882b052e1f5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 繪製站立10秒訊號(原始數據)\n",
    "plot_data_10s(L1, title='站立', normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 繪製靜坐10秒訊號(原始數據)\n",
    "plot_data_10s(L2, title='靜坐', normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 繪製平躺10秒訊號(原始數據)\n",
    "plot_data_10s(L3, title='平躺', normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 繪製走路10秒訊號(原始數據)\n",
    "plot_data_10s(L4, title='走路', normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 繪製上樓10秒訊號(原始數據)\n",
    "plot_data_10s(L5, title='上樓', normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4D_KVyd2byR"
   },
   "source": [
    "# 資料預處理\n",
    "這裡的意思是1分鐘3072筆的資料取視窗大小100點資料，接著移動50點再另外收集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 抓取window_size的資料作為觀察資料(x), 預測下一時間點步態(y)\n",
    "def window_data(data, window_size, shift):\n",
    "    X = []\n",
    "    y = []\n",
    "    i = 0\n",
    "    while (i + window_size) <= len(data) - 1:\n",
    "        # 將連續的window_size時間段內的資料（去除最後一個特徵label）作為觀察資料x\n",
    "        X.append(data[i:i+window_size, :-1])\n",
    "        # 將接下來的一個時間點的第6個特徵（標籤）作為預測資料y\n",
    "        y.append(data[i+window_size, 6])\n",
    "        i += shift  # 移動索引，以繼續抓取下一筆資料\n",
    "    X = np.array(X)\n",
    "    y = np.array(y).reshape(-1)\n",
    "    assert len(X) == len(y)  # 確保觀察資料和預測資料的數量一致\n",
    "    return X, y  # 返回處理後的時序資料和預測資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 蒐集六個訊號100個時間點(window_size)，每筆資料採樣移動20個資料點\n",
    "X_L1, y_L1 = window_data(L1.values, window_size=100, shift=20)\n",
    "X_L2, y_L2 = window_data(L2.values, window_size=100, shift=20)\n",
    "X_L3, y_L3 = window_data(L3.values, window_size=100, shift=20)\n",
    "X_L4, y_L4 = window_data(L4.values, window_size=100, shift=20)\n",
    "X_L5, y_L5 = window_data(L5.values, window_size=100, shift=20)\n",
    "\n",
    "X = np.concatenate([X_L1, X_L2, X_L3, X_L4, X_L5])\n",
    "y = np.concatenate([y_L1, y_L2, y_L3, y_L4, y_L5])-1 # 標籤要從0開始故全部減一\n",
    "print(\"X shape: \",X.shape)\n",
    "print(\"y shape: \",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 切割資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4OHU7MCcdOk",
    "outputId": "d27ed5ff-32c4-47c8-db16-095adb82da40",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=42, stratify=y)\n",
    "print(\"X_train shape = \",X_train.shape)\n",
    "print(\"X_test shape = \",X_test.shape)\n",
    "print(\"y_train shape = \",y_train.shape)\n",
    "print(\"y_test shape = \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moQKmaVFJEwm"
   },
   "source": [
    "## 模型建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-OQIxyzJZxe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.compat.v1.keras.backend import get_session\n",
    "tf.compat.v1.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1DCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_sensor = 6\n",
    "window_size = 100\n",
    "\n",
    "def build_1dcnn_model():\n",
    "    model_input = layers.Input(shape=(window_size, num_sensor))\n",
    "    \n",
    "    # Flatten the input\n",
    "    flattened_input = layers.Flatten()(model_input)\n",
    "    \n",
    "    # Normalization layer\n",
    "    normalization_layer = tf.keras.layers.Normalization(axis=1)\n",
    "    normalization_layer.adapt(x_train.reshape(-1, window_size * num_sensor))\n",
    "    normalized_input = normalization_layer(flattened_input)\n",
    "    \n",
    "    # Reshape back to original shape\n",
    "    reshaped_input = layers.Reshape((window_size, x_train.shape[-1]))(normalized_input)\n",
    "    \n",
    "    # Rest of the model\n",
    "    x = layers.Conv1D(4, 2, activation='relu')(reshaped_input)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    # x = layers.Dense(32, activation='relu')(x)\n",
    "    model_output = layers.Dense(5, activation='softmax')(x)\n",
    "    \n",
    "    return Model(model_input, model_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_sensor = 6\n",
    "window_size = 100\n",
    "def build_model():\n",
    "    model_input = layers.Input(shape=(window_size, num_sensor))\n",
    "    # 輸出層\n",
    "    x = layers.LSTM(2, activation='relu', return_sequences=True, return_state=False)(model_input)\n",
    "    x = layers.Flatten()(x)\n",
    "    # 輸出層\n",
    "    model_output = layers.Dense(5, activation='softmax')(x)\n",
    "    return Model(model_input, model_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GH6tG5FAuxJt"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jy3d_IhTuvnG",
    "outputId": "c5c2b204-c6d3-4dba-d323-030c08d3ccd1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 編譯模型\n",
    "model.compile(\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      optimizer='adam',\n",
    "      metrics=['acc'])\n",
    "# 訓練模型\n",
    "history = model.fit( X_train, y_train, \n",
    "                    validation_split=0.1,\n",
    "                    batch_size=4,\n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "wscb6FHEWa-J",
    "outputId": "7b1138a6-4196-4ba5-9b3a-c82f5b67f5ab",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "3BMy4ocCWmV8",
    "outputId": "1ea0f7c8-6784-4370-c5a3-2203928d635a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4EkYARh5WroM",
    "outputId": "18e5f01f-d21e-4b73-f103-39e904907397",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on test set\n",
    "test_result = model.evaluate(x = X_test, y = y_test, batch_size = X_test.shape[0])\n",
    "# Print test loss and test accuracy\n",
    "print(\"Loss on testing set: %f\" % test_result[0])\n",
    "print(\"Accuracy on testing set: %f\" % test_result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = model.predict(np.array([X_test[0]])).argmax(axis=1)[0]\n",
    "print(f'Predict: {pred}, Ground True: {y_test[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "pred_valid = model.predict(X_test).argmax(axis=1)\n",
    "print(classification_report(y_test, pred_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "# 使用 Deep SHAP 解釋模型\n",
    "explainer = shap.DeepExplainer(model=model, data=X_train)\n",
    "# 估計 Shapely values\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5個類別, 75筆測試資料, 100個時間點, 6個特徵\n",
    "np.array(shap_values).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Summary Plot (全局解釋)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_array(arr):\n",
    "    # 計算陣列中所有元素的總和\n",
    "    total = sum(arr)\n",
    "    # 正規化每個元素\n",
    "    normalized_arr = [x / total for x in arr]\n",
    "    return normalized_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 獲得在某標籤下每個特徵對於整體平均貢獻的值\n",
    "# 0:站立、1:靜坐、2:平躺、3:走路、4:上樓\n",
    "label=4\n",
    "shap_value = np.array(shap_values)\n",
    "shap_value = np.absolute(shap_value[label])\n",
    "shap_value = np.sum(shap_value, axis=1)\n",
    "SHAP_list = [np.sum(shap_value[:, 0]), np.sum(shap_value[:, 1]), np.sum(shap_value[:, 2]), np.sum(shap_value[:, 3]), np.sum(shap_value[:, 4]), np.sum(shap_value[:, 5])]\n",
    "plt.barh(x_feature_names, normalize_array(SHAP_list), label=y_label_names[label], color='#028bfb')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "plt.savefig('plot.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to get the shape values or each feature\n",
    "shap_df = pd.DataFrame(list(dict(zip(x_feature_names, normalize_array(SHAP_list))).items()),\n",
    "             columns=['features','shapvals']).sort_values(by='shapvals', ascending=False)\n",
    "shap_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP Force plot (單筆資料解釋)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "# 觀察測試集中第一筆資料的重要程度\n",
    "index=0\n",
    "pred_class = model.predict(X_test[[index]]).argmax()\n",
    "pred_proba = model.predict(X_test[[index]])[0][pred_class]\n",
    "print(f'測試集第 {index+1} 筆模型預測結果: {pred_class} 機率值: {pred_proba}')\n",
    "print(f'真實答案: {int(y_test[index])} ({y_label_names[pred_class]})')\n",
    "shap_value = shap_values[pred_class][index]\n",
    "shap_value = shap_value.sum(axis=0)\n",
    "shap.force_plot(explainer.expected_value[pred_class], shap_value, feature_names=x_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 把(100,6)所有數值加總+基準值\n",
    "shap_values[pred_class][index].sum()+explainer.expected_value[pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 把六個特徵shap_value加總+基準值\n",
    "shap_value.sum()+explainer.expected_value[pred_class]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP waterfall plot (單筆資料解釋)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_class = model.predict(X_test[[index]]).argmax()\n",
    "pred_proba = model.predict(X_test[[index]])[0][pred_class]\n",
    "shap_value = np.array(shap_values)\n",
    "shap_value = np.expand_dims((shap_value[pred_class])[index], axis=0)\n",
    "shap_value = np.sum(shap_value, axis=1)[0]\n",
    "shap.waterfall_plot(shap.Explanation(values=shap_value, \n",
    "                                    base_values=explainer.expected_value[pred_class],  \n",
    "                                    feature_names=x_feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(0, shap_values[pred_class][index], feature_names=x_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- [[forecast][LSTM+SHAP]Applied SHAP on the polynomial equation case with LSTM algorithm](https://medium.com/@sakamoto2000.kim/applied-shap-on-the-polynomial-equation-case-with-lstm-algorithm-7c140d15736b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "24. LSTM的可解釋性：從時序資料解析人體姿態預測.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
