
<!DOCTYPE html>

<html class="no-js" lang="zh-Hant">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="ie=edge" http-equiv="x-ua-compatible"/>
<meta content="10程式中" name="author"/>
<meta content="複製" name="lang:clipboard.copy"/>
<meta content="已複製" name="lang:clipboard.copied"/>
<meta content="ja" name="lang:search.language"/>
<meta content="True" name="lang:search.pipeline.stopwords"/>
<meta content="True" name="lang:search.pipeline.trimmer"/>
<meta content="沒有符合的項目" name="lang:search.result.none"/>
<meta content="找到 1 個符合的項目" name="lang:search.result.one"/>
<meta content="找到 # 個符合的項目" name="lang:search.result.other"/>
<meta content="[\uff0c\u3002]+" name="lang:search.tokenizer"/>
<link href="../assets/images/favicon.png" rel="shortcut icon"/>
<meta content="mkdocs-1.0.4, mkdocs-material-4.4.0" name="generator"/>
<title>[Day 29] XAI如何影響人類對技術的信任和接受程度？ - 全民瘋AI系列 [探索可解釋人工智慧]</title>
<link href="../assets/stylesheets/application.0284f74d.css" rel="stylesheet"/>
<link href="../assets/stylesheets/application-palette.01803549.css" rel="stylesheet"/>
<meta content="#7e57c2" name="theme-color"/>
<script src="../assets/javascripts/modernizr.74668098.js"></script>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&amp;display=fallback" rel="stylesheet"/>
<style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
<link href="../assets/fonts/material-icons.css" rel="stylesheet"/>
<link href="../stylesheets/extra.css" rel="stylesheet"/>
</head>
<body data-md-color-accent="deep-purple" data-md-color-primary="deep-purple" dir="ltr">
<svg class="md-svg">
<defs>
<svg height="448" id="__github" viewbox="0 0 416 448" width="416" xmlns="http://www.w3.org/2000/svg"><path d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z" fill="currentColor"></path></svg>
</defs>
</svg>
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
<a class="md-skip" href="#day-29-xai" tabindex="1">
        跳轉到
      </a>
<header class="md-header" data-md-component="header">
<nav class="md-header-nav md-grid">
<div class="md-flex">
<div class="md-flex__cell md-flex__cell--shrink">
<a class="md-header-nav__button md-logo" href=".." title="全民瘋AI系列 [探索可解釋人工智慧]">
<i class="md-icon"></i>
</a>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
</div>
<div class="md-flex__cell md-flex__cell--stretch">
<div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
<span class="md-header-nav__topic">
              全民瘋AI系列 [探索可解釋人工智慧]
            </span>
<span class="md-header-nav__topic">
              
                [Day 29] XAI如何影響人類對技術的信任和接受程度？
              
            </span>
</div>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="query" data-md-state="active" name="query" placeholder="搜尋" spellcheck="false" type="text"/>
<label class="md-icon md-search__icon" for="__search"></label>
<button class="md-icon md-search__icon" data-md-component="reset" tabindex="-1" type="reset">
        
      </button>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="result">
<div class="md-search-result__meta">
            打字進行搜尋
          </div>
<ol class="md-search-result__list"></ol>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<div class="md-header-nav__source">
<a class="md-source" data-md-source="github" href="https://github.com/andy6804tw/crazyai-xai" title="前往倉庫">
<div class="md-source__icon">
<svg height="24" viewbox="0 0 24 24" width="24">
<use height="24" width="24" xlink:href="#__github"></use>
</svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
</div>
</div>
</nav>
</header>
<div class="md-container">
<main class="md-main">
<div class="md-main__inner md-grid" data-md-component="container">
<div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav class="md-nav md-nav--primary" data-md-level="0">
<label class="md-nav__title md-nav__title--site" for="__drawer">
<a class="md-nav__button md-logo" href=".." title="全民瘋AI系列 [探索可解釋人工智慧]">
<i class="md-icon"></i>
</a>
    全民瘋AI系列 [探索可解釋人工智慧]
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-source="github" href="https://github.com/andy6804tw/crazyai-xai" title="前往倉庫">
<div class="md-source__icon">
<svg height="24" viewbox="0 0 24 24" width="24">
<use height="24" width="24" xlink:href="#__github"></use>
</svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" id="nav-1" type="checkbox"/>
<label class="md-nav__link" for="nav-1">
      1.XAI基礎與概念介紹
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-1">
        1.XAI基礎與概念介紹
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../1.揭開模型的神秘面紗:為何XAI對機器學習如此重要/" title="[Day 1] 揭開模型的神秘面紗：為何XAI對機器學習如此重要？">
      [Day 1] 揭開模型的神秘面紗：為何XAI對機器學習如此重要？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2.從黑盒到透明化:XAI技術的發展之路/" title="[Day 2] 從黑盒到透明化：XAI技術的發展之路">
      [Day 2] 從黑盒到透明化：XAI技術的發展之路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../3.機器學習中的可解釋性指標/" title="[Day 3] 機器學習中的可解釋性指標">
      [Day 3] 機器學習中的可解釋性指標
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../4.LIME vs SHAP:哪種XAI解釋方法更適合你/" title="[Day 4] LIME vs. SHAP：哪種XAI解釋方法更適合你？">
      [Day 4] LIME vs. SHAP：哪種XAI解釋方法更適合你？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../5.淺談XAI與傳統機器學習的區別/" title="[Day 5] 淺談XAI與傳統機器學習的區別">
      [Day 5] 淺談XAI與傳統機器學習的區別
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" id="nav-2" type="checkbox"/>
<label class="md-nav__link" for="nav-2">
      2.XAI在傳統機器學習中的應用
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-2">
        2.XAI在傳統機器學習中的應用
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../6.非監督學習也能做到可解釋性-探索XAI在非監督學習中的應用/" title="[Day 6] 非監督學習也能做到可解釋性？探索XAI在非監督學習中的應用">
      [Day 6] 非監督學習也能做到可解釋性？探索XAI在非監督學習中的應用
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../7.KNN與XAI:從鄰居中找出模型的決策邏輯/" title="[Day 7] KNN與XAI：從鄰居中找出模型的決策邏輯">
      [Day 7] KNN與XAI：從鄰居中找出模型的決策邏輯
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../8.解釋線性模型:探索線性迴歸和邏輯迴歸的可解釋性/" title="[Day 8] 解釋線性模型：探索線性迴歸和邏輯迴歸的可解釋性">
      [Day 8] 解釋線性模型：探索線性迴歸和邏輯迴歸的可解釋性
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../9.基於樹狀結構的XAI方法:決策樹的可解釋性/" title="[Day 9] 基於樹狀結構的XAI方法：決策樹的可解釋性">
      [Day 9] 基於樹狀結構的XAI方法：決策樹的可解釋性
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../10.Permutation Importance:從特徵重要性角度解釋整個模型行為/" title="[Day 10] Permutation Importance：從特徵重要性角度解釋整個模型行為">
      [Day 10] Permutation Importance：從特徵重要性角度解釋整個模型行為
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../11.Partial Dependence Plot:探索特徵對預測值的影響/" title="[Day 11] Partial Dependence Plot：探索特徵對預測值的影響">
      [Day 11] Partial Dependence Plot：探索特徵對預測值的影響
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" id="nav-3" type="checkbox"/>
<label class="md-nav__link" for="nav-3">
      3.XAI常用工具介紹
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-3">
        3.XAI常用工具介紹
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../12.LIME理論:如何用局部線性近似解釋黑箱模型/" title="[Day 12] LIME理論：如何用局部線性近似解釋黑箱模型">
      [Day 12] LIME理論：如何用局部線性近似解釋黑箱模型
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../13.LIME實作:實戰演練LIME解釋方法/" title="[Day 13] LIME實作：實戰演練LIME解釋方法">
      [Day 13] LIME實作：實戰演練LIME解釋方法
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../14.SHAP理論:解析SHAP解釋方法的核心/" title="[Day 14] SHAP理論：解析SHAP解釋方法的核心">
      [Day 14] SHAP理論：解析SHAP解釋方法的核心
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../15.SHAP實作:實戰演練SHAP解釋方法/" title="[Day 15] SHAP實作：實戰演練SHAP解釋方法">
      [Day 15] SHAP實作：實戰演練SHAP解釋方法
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" id="nav-4" type="checkbox"/>
<label class="md-nav__link" for="nav-4">
      4.XAI在深度學習中的可解釋性
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-4">
        4.XAI在深度學習中的可解釋性
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../16.神經網路的可解釋性:如何理解深度學習中的黑箱模型/" title="[Day 16] 神經網路的可解釋性：如何理解深度學習中的黑箱模型？">
      [Day 16] 神經網路的可解釋性：如何理解深度學習中的黑箱模型？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../17.解析深度神經網路:使用Deep SHAP進行模型解釋/" title="[Day 17] 解析深度神經網路：使用Deep SHAP進行模型解釋">
      [Day 17] 解析深度神經網路：使用Deep SHAP進行模型解釋
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../18.CNN卷積深度神經網路的解釋方法/" title="[Day 18] CNN：卷積深度神經網路的解釋方法">
      [Day 18] CNN：卷積深度神經網路的解釋方法
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../19.Perturbation Based如何用擾動方法解釋神經網路/" title="[Day 19] Perturbation-Based：如何用擾動方法解釋神經網路">
      [Day 19] Perturbation-Based：如何用擾動方法解釋神經網路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../20.Gradient Based利用梯度訊息解釋神經網路/" title="[Day 20] Gradient-Based：利用梯度訊息解釋神經網路">
      [Day 20] Gradient-Based：利用梯度訊息解釋神經網路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../21.Propagation Based探索反向傳播法的可解釋性/" title="[Day 21] Propagation-Based：探索反向傳播法的可解釋性">
      [Day 21] Propagation-Based：探索反向傳播法的可解釋性
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../22.CAM Based如何解釋卷積神經網路/" title="[Day 22] CAM-Based：如何解釋卷積神經網路">
      [Day 22] CAM-Based：如何解釋卷積神經網路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../23.Attention Based使用注意力機制解釋CNN模型/" title="[Day 23] Attention-Based：使用注意力機制解釋CNN模型">
      [Day 23] Attention-Based：使用注意力機制解釋CNN模型
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" id="nav-5" type="checkbox"/>
<label class="md-nav__link" for="nav-5">
      5.XAI在現實生活中的應用案例
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-5">
        5.XAI在現實生活中的應用案例
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../24.LSTM的可解釋性:解析步態分類中的時序資料/" title="[Day 24] LSTM的可解釋性：從時序資料解析人體姿態預測">
      [Day 24] LSTM的可解釋性：從時序資料解析人體姿態預測
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../25.XAI在影像處理中的瑕疵檢測:解釋卷積神經網路的運作/" title="[Day 25] XAI在影像處理中的瑕疵檢測：解釋卷積神經網路的運作">
      [Day 25] XAI在影像處理中的瑕疵檢測：解釋卷積神經網路的運作
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../26.智慧工廠製程中的鋼材缺陷檢測:運用XAI解析數值型感測器數據/" title="[Day 26] XAI在表格型資料的應用：解析智慧工廠中的鋼材缺陷">
      [Day 26] XAI在表格型資料的應用：解析智慧工廠中的鋼材缺陷
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../27.XAI在NLP中的應用:以情感分析解釋語言模型/" title="[Day 27] XAI在NLP中的應用：以情感分析解釋語言模型">
      [Day 27] XAI在NLP中的應用：以情感分析解釋語言模型
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-toggle md-nav__toggle" data-md-toggle="nav-6" id="nav-6" type="checkbox"/>
<label class="md-nav__link" for="nav-6">
      6.XAI的挑戰與未來
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-6">
        6.XAI的挑戰與未來
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../28.誤差分析和對抗樣本:如何利用XAI檢測模型的弱點/" title="[Day 28] 對抗樣本的挑戰：如何利用XAI檢測模型的弱點？">
      [Day 28] 對抗樣本的挑戰：如何利用XAI檢測模型的弱點？
    </a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-toggle md-nav__toggle" data-md-toggle="toc" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
        [Day 29] XAI如何影響人類對技術的信任和接受程度？
      </label>
<a class="md-nav__link md-nav__link--active" href="./" title="[Day 29] XAI如何影響人類對技術的信任和接受程度？">
      [Day 29] XAI如何影響人類對技術的信任和接受程度？
    </a>
<nav class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">本頁目錄</label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#ai" title="AI的倫理道德">
    AI的倫理道德
  </a>
<nav class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#gpt" title="[案例一] GPT偵測器具備語文上的偏見與歧視">
    [案例一] GPT偵測器具備語文上的偏見與歧視
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#google" title="[案例二] Google相簿出包誤將黑人標成大猩猩">
    [案例二] Google相簿出包誤將黑人標成大猩猩
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ai_1" title="[案例三] 鐵面無私包青天？小心AI的內建歧視">
    [案例三] 鐵面無私包青天？小心AI的內建歧視
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ai_2" title="[案例四] AI攝影機誤把裁判的光頭當足球跟拍轉播">
    [案例四] AI攝影機誤把裁判的光頭當足球跟拍轉播
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ai_3" title="建立對AI的信任">
    建立對AI的信任
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ai_4" title="AI的信任和技術接受">
    AI的信任和技術接受
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#reference" title="Reference">
    Reference
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../30.XAI未來發展方向:向更可靠的機器學習模型邁進/" title="[Day30] XAI未來發展方向：向更可靠的機器學習模型邁進">
      [Day30] XAI未來發展方向：向更可靠的機器學習模型邁進
    </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">本頁目錄</label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#ai" title="AI的倫理道德">
    AI的倫理道德
  </a>
<nav class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#gpt" title="[案例一] GPT偵測器具備語文上的偏見與歧視">
    [案例一] GPT偵測器具備語文上的偏見與歧視
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#google" title="[案例二] Google相簿出包誤將黑人標成大猩猩">
    [案例二] Google相簿出包誤將黑人標成大猩猩
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ai_1" title="[案例三] 鐵面無私包青天？小心AI的內建歧視">
    [案例三] 鐵面無私包青天？小心AI的內建歧視
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ai_2" title="[案例四] AI攝影機誤把裁判的光頭當足球跟拍轉播">
    [案例四] AI攝影機誤把裁判的光頭當足球跟拍轉播
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ai_3" title="建立對AI的信任">
    建立對AI的信任
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#ai_4" title="AI的信任和技術接受">
    AI的信任和技術接受
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#reference" title="Reference">
    Reference
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content">
<article class="md-content__inner md-typeset"><a class="md-content__icon pdf-download-btn" download href="../pdf/全民瘋AI系列_探索可解釋人工智慧_v1.1.pdf" title="Download"><i class="fa fas fa-download"></i><small> PDF</small></a>
<h1 id="day-29-xai">[Day 29] XAI如何影響人類對技術的信任和接受程度？</h1>
<p>在科技迅速進步的時代，人工智慧已經深深地融入了我們的生活，從<code>智慧製造</code>、<code>智慧醫療</code>、<code>智慧服務</code>到<code>智慧交通</code>，無所不在。然而這種深度的整合也伴隨著對於技術的信任和接受程度的關切。如今 XAI 已成為解決這些問題的關鍵，它不僅協助我們提高對技術的信任與對技術的接受程度。當一般大眾能夠理解 AI 如何達到特定的結果時，他們更有可能接受並使用這些技術。</p>
<ul>
<li>透明：人工智慧系統應該易於理解。</li>
<li>可靠：人工智慧系統應確保運行可靠和安全。</li>
<li>公平：人工智慧系统應該公平對待所有人。</li>
<li>隱私：人工智慧系統應該保障並尊重隱私。</li>
<li>包容：人工智慧系統應確保每個人都能夠參與和受益。</li>
<li>負責：人工智慧系統應該建立監督標準。</li>
</ul>
<p><img alt="" src="../image/img28-1.png"/></p>
<p>一個負責任的人工智慧除了以上六項原則之外，另外 XAI 也引發了對 AI 倫理和道德的更多關注。想必這也是每個企業主和使用者所擔憂的議題，隨著對技術的信任增加，同時我們更關心 AI 的倫理道德和風險。</p>
<h2 id="ai">AI的倫理道德</h2>
<p>AI 的倫理道德一直是引起廣泛關注的議題，而機器學習作為 AI 的重要分支，其倫理問題更是引人深思。在今日的文章中，我們將深入探討機器學習中常見的道德問題，並借鏡一些真實例子來闡述這些議題的重要性。</p>
<h4 id="gpt">[案例一] GPT偵測器具備語文上的偏見與歧視</h4>
<p>在近期的一項研究中，使用這些生成式預訓練模型（GPT）偵測器來判斷英文文章是否來自 AI ，母語非英文的使用者在撰寫英文文章時，有超過一半的情況被誤認為是 AI 生成的文章。這引發了對 GPT 偵測器存在語文上的偏見和歧視的擔憂。在訓練 GPT 偵測器的過程中，研究人員使用了7款熱門的偵測器來檢查91篇源自中國論壇的托福寫作文章，以及88篇由美國8年級生所撰寫的英文作文。從實驗結果顯示，這些偵測器能較正確地分辨出由美國學生所撰寫的文章，但對於中國學生所撰寫的托福文章的識別率卻顯著下降，並誤判為是 AI 所生成的文章。</p>
<p><img alt="" src="../image/img28-2.png"/></p>
<p>這一問題的根本在於訓練數據的不平衡和偏向性。當訓練數據不夠多樣化或存在偏向性時，模型就容易產生誤判和歧視性行為。因此為了建立更公正、無偏見的 AI 系統，需要謹慎挑選和處理訓練數據，並定期檢查和調整模型以減少偏見。這也反映了 AI 技術應該受到倫理和多元性的審視，以確保其應用不會對不同文化和語言的使用者產生不公平的影響。</p>
<ul>
<li>相關報導：<a href="https://www.ithome.com.tw/news/157743?fbclid=IwAR1K6xShDCoDOIR-i_bzt3PrBvMQBdiC_O0hRnocJYA_oPqOTsWiH4x5aig">非英語母語者寫的英文文章，有一半被GPT偵測器標記為AI生成</a></li>
</ul>
<h4 id="google">[案例二] Google相簿出包誤將黑人標成大猩猩</h4>
<p>在這個案例中，Google 相簿使用了機器學習技術來自動辨識照片中的物體和人物，但不幸的是，該系統在辨識中出現了一個重大錯誤。這個錯誤導致該系統將一位用戶以及他的黑人朋友的照片誤標為大猩猩，這引起了公眾的廣泛討論，並帶出了有關人工智慧的資訊倫理議題。</p>
<p><img alt="" src="../image/img28-3.png"/></p>
<ul>
<li>相關報導：<a href="https://www.ithome.com.tw/news/97131">相片辨識出包誤將黑人標成大猩猩，Google火速道歉</a></li>
</ul>
<h4 id="ai_1">[案例三] 鐵面無私包青天？小心AI的內建歧視</h4>
<p>近年來，美國法院廣泛使用名為「COMPAS」的 AI 系統，這是由商業公司開發的，用來協助法官評估被告的再犯風險，並作為判決的參考依據。然而許多<a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">研究</a>已經明確指出，這套 AI 系統存在潛在的種族歧視問題，即有色人種更容易被預測為高再犯風險，這引發了廣泛的爭議和討論。</p>
<p><img alt="" src="../image/img28-4.png"/></p>
<p>從案例二和案例三中我們可以看到，影像辨識技術在某些情況下存在未知的不確定性，並且容易受到種族歧視等問題的影響。這突顯了 AI 的一個關鍵限制：AI 缺乏真正的思考能力和判斷能力，而是依賴於訓練數據來做出決策。</p>
<ul>
<li>相關報導：<a href="https://dq.yam.com/post/13034">AI 當法官，會是正義女神的化身嗎？</a></li>
</ul>
<h4 id="ai_2">[案例四] AI攝影機誤把裁判的光頭當足球跟拍轉播</h4>
<p>最後一個來點輕鬆的，在這個案例中，一家蘇格蘭足球俱樂部引入了一套AI攝影機系統，目的要自動追蹤足球比賽中球的蹤跡，以進行轉播。然而在比賽進行一段時間後，這套 AI 系統卻突然停止追蹤足球，而是將鏡頭對準了場邊的裁判光頭。這個事件凸顯出 AI 系統的不確定性和可信度問題。AI 攝影機系統的設計初衷是為了提供更好的比賽轉播體驗，但卻因為意外的失誤，導致了轉播的笑話。</p>
<p><img alt="" src="https://i.imgur.com/8U0UUkk.gif"/></p>
<p>這個案例強調了影像視覺可解釋性的重要性。如果 AI 攝影機系統能夠清晰地解釋其決策過程，或者提供有關為何選擇對準裁判光頭的合理解釋，可能有助於減輕事件的影響。</p>
<ul>
<li>相關報導：<a href="https://buzzorange.com/techorange/2020/11/02/ai-soccer-follow-bald-lineman/">蘇格蘭AI攝影機誤把裁判的光頭當足球跟拍轉播</a></li>
<li>影像來源：<a href="https://www.zhihu.com/zvideo/1306220010348875776">AI錯把光頭認足球</a></li>
</ul>
<h2 id="ai_3">建立對AI的信任</h2>
<p>在建立對 AI 的信任方面，深度學習模型的可解釋性一直是一個關鍵的課題。深度學習模型的強大性能是不可否認的，但模型的高度抽象性也帶來了對其運作方式的不透明性。因此我們必須關注模型的解釋能力，以確保大眾能夠理解和信任模型的決策。</p>
<p>以金融業為例，我們可以看到深度學習模型在信用評分等領域的應用。在這樣的情境下，我們希望能夠回答一系列問題，以確保模型的信任度：</p>
<ul>
<li>我們應該如何解釋模型中每個連接的權重，以理解它們在預測中的具體作用和含義？</li>
<li>哪些權重在最終預測中扮演了關鍵的角色，影響著最終結果？</li>
<li>權重的大小是否能提供有關輸入變數的相對重要性的訊息？</li>
</ul>
<p>這些問題的答案對於金融機構以及任何其他使用 AI 的領域都非常重要。模型解釋性不僅有助於追蹤和理解模型的決策過程，還可以幫助檢測模型的偏見和錯誤。同時透明的模型解釋也可以提高使用者對AI系統的信任度，並推動更廣泛的技術應用。</p>
<p>例如一些金融機構如國泰金控已經開始使用 SHAP 演算法來解釋其 AI 模型的決策。他們還積極採用自建的公平性和反歧視模型驗證方法，以確保模型不會因種族、性別或其他因素而偏見。此外，他們引入了聯邦學習技術，以保護敏感數據並提高模型的安全性。同時，透過引入人類回饋，他們實踐了強化學習，不斷改進 AI 模型的性能，以符合 AI 治理原則的要求。</p>
<blockquote>
<p>相關報導：<a href="https://www.ithome.com.tw/news/158850?fbclid=IwAR1uzScM5f_DQ9hobImf4Wxo-6p400LKNqHLv15s_U4DNAHTnuP91NrA1KQ">實踐AI治理原則國泰金控聚焦四大技術</a></p>
</blockquote>
<h2 id="ai_4">AI的信任和技術接受</h2>
<p>XAI 對於提高人類對技術的信任和接受程度具有巨大的潛力。它為我們提供了一個機會，可以建立更加透明和可信賴的人機互動，並確保 AI 技術在未來的應用中取得成功。隨著 XAI 領域的不斷發展，我們可以期待看到更多創新和改進，這將進一步推動技術的進步和社會的發展。除了今天所提到的案例外，我們可以看到 XAI 是如何改變這些領域的技術接受程度和社會影響：</p>
<ul>
<li>金融風險管理：如何利用可解釋的方法預測市場趨勢？</li>
<li>網路安全：如何利用可解釋性的方法檢測和防止攻擊？</li>
<li>社會公正：如何確保機器學習模型不歧視特定族群？</li>
<li>醫學診斷：用可解釋的方法解釋醫學圖像和診斷結果</li>
<li>生物醫學：從基因組學到蛋白質折疊的解釋性分析</li>
<li>法律：如何利用可解釋的方法幫助判決和解釋法律條文？</li>
<li>認知心理學：如何理解人類的決策和行為？</li>
<li>教育：如何利用可解釋的方法評估學生學習成效？</li>
</ul>
<h2 id="reference">Reference</h2>
<ul>
<li>
<p><a href="https://fullstackdeeplearning.com/course/2022/lecture-9-ethics/">Full Stack Deep Learning 2022: Lecture 9: Ethics</a></p>
</li>
<li>
<p><a href="https://ek21.com/news/tech/191675/">五張圖詳解企業如何建立可信任的AI</a></p>
</li>
<li><a href="https://kknews.cc/zh-tw/code/n9lyk23.html">如何將DeepSHAP應用於神經網絡</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/68987264">人工智慧也有歧視和偏見</a></li>
</ul>
</article>
</div>
</div>
</main>
<footer class="md-footer">
<div class="md-footer-nav">
<nav class="md-footer-nav__inner md-grid">
<a class="md-flex md-footer-nav__link md-footer-nav__link--prev" href="../28.誤差分析和對抗樣本:如何利用XAI檢測模型的弱點/" rel="prev" title="[Day 28] 對抗樣本的挑戰：如何利用XAI檢測模型的弱點？">
<div class="md-flex__cell md-flex__cell--shrink">
<i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
</div>
<div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
<span class="md-flex__ellipsis">
<span class="md-footer-nav__direction">
                  上一頁
                </span>
                [Day 28] 對抗樣本的挑戰：如何利用XAI檢測模型的弱點？
              </span>
</div>
</a>
<a class="md-flex md-footer-nav__link md-footer-nav__link--next" href="../30.XAI未來發展方向:向更可靠的機器學習模型邁進/" rel="next" title="[Day30] XAI未來發展方向：向更可靠的機器學習模型邁進">
<div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
<span class="md-flex__ellipsis">
<span class="md-footer-nav__direction">
                  下一頁
                </span>
                [Day30] XAI未來發展方向：向更可靠的機器學習模型邁進
              </span>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
</div>
</a>
</nav>
</div>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-footer-copyright">
<div class="md-footer-copyright__highlight">
            Copyright © 2023 - 2024 10程式中
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
</div>
</div>
</div>
</footer>
</div>
<script src="../assets/javascripts/application.245445c6.js"></script>
<script src="../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
<script src="../assets/javascripts/lunr/tinyseg.js"></script>
<script src="../assets/javascripts/lunr/lunr.ja.js"></script>
<script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
<script src="../javascripts/extra.js"></script>
<script src="../javascripts/analytics.js"></script>
</body>
</html>