
<!DOCTYPE html>

<html class="no-js" lang="zh-Hant">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="ie=edge" http-equiv="x-ua-compatible"/>
<meta content="10程式中" name="author"/>
<meta content="複製" name="lang:clipboard.copy"/>
<meta content="已複製" name="lang:clipboard.copied"/>
<meta content="ja" name="lang:search.language"/>
<meta content="True" name="lang:search.pipeline.stopwords"/>
<meta content="True" name="lang:search.pipeline.trimmer"/>
<meta content="沒有符合的項目" name="lang:search.result.none"/>
<meta content="找到 1 個符合的項目" name="lang:search.result.one"/>
<meta content="找到 # 個符合的項目" name="lang:search.result.other"/>
<meta content="[\uff0c\u3002]+" name="lang:search.tokenizer"/>
<link href="../assets/images/favicon.png" rel="shortcut icon"/>
<meta content="mkdocs-1.0.4, mkdocs-material-4.4.0" name="generator"/>
<title>[Day 8] 解釋線性模型：探索線性迴歸和邏輯迴歸的可解釋性 - 全民瘋AI系列 [探索可解釋人工智慧]</title>
<link href="../assets/stylesheets/application.0284f74d.css" rel="stylesheet"/>
<link href="../assets/stylesheets/application-palette.01803549.css" rel="stylesheet"/>
<meta content="#7e57c2" name="theme-color"/>
<script src="../assets/javascripts/modernizr.74668098.js"></script>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&amp;display=fallback" rel="stylesheet"/>
<style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
<link href="../assets/fonts/material-icons.css" rel="stylesheet"/>
<link href="../stylesheets/extra.css" rel="stylesheet"/>
</head>
<body data-md-color-accent="deep-purple" data-md-color-primary="deep-purple" dir="ltr">
<svg class="md-svg">
<defs>
<svg height="448" id="__github" viewbox="0 0 416 448" width="416" xmlns="http://www.w3.org/2000/svg"><path d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z" fill="currentColor"></path></svg>
</defs>
</svg>
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
<a class="md-skip" href="#day-8" tabindex="1">
        跳轉到
      </a>
<header class="md-header" data-md-component="header">
<nav class="md-header-nav md-grid">
<div class="md-flex">
<div class="md-flex__cell md-flex__cell--shrink">
<a class="md-header-nav__button md-logo" href=".." title="全民瘋AI系列 [探索可解釋人工智慧]">
<i class="md-icon"></i>
</a>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
</div>
<div class="md-flex__cell md-flex__cell--stretch">
<div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
<span class="md-header-nav__topic">
              全民瘋AI系列 [探索可解釋人工智慧]
            </span>
<span class="md-header-nav__topic">
              
                [Day 8] 解釋線性模型：探索線性迴歸和邏輯迴歸的可解釋性
              
            </span>
</div>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="query" data-md-state="active" name="query" placeholder="搜尋" spellcheck="false" type="text"/>
<label class="md-icon md-search__icon" for="__search"></label>
<button class="md-icon md-search__icon" data-md-component="reset" tabindex="-1" type="reset">
        
      </button>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="result">
<div class="md-search-result__meta">
            打字進行搜尋
          </div>
<ol class="md-search-result__list"></ol>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<div class="md-header-nav__source">
<a class="md-source" data-md-source="github" href="https://github.com/andy6804tw/crazyai-xai" title="前往倉庫">
<div class="md-source__icon">
<svg height="24" viewbox="0 0 24 24" width="24">
<use height="24" width="24" xlink:href="#__github"></use>
</svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
</div>
</div>
</nav>
</header>
<div class="md-container">
<main class="md-main">
<div class="md-main__inner md-grid" data-md-component="container">
<div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav class="md-nav md-nav--primary" data-md-level="0">
<label class="md-nav__title md-nav__title--site" for="__drawer">
<a class="md-nav__button md-logo" href=".." title="全民瘋AI系列 [探索可解釋人工智慧]">
<i class="md-icon"></i>
</a>
    全民瘋AI系列 [探索可解釋人工智慧]
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-source="github" href="https://github.com/andy6804tw/crazyai-xai" title="前往倉庫">
<div class="md-source__icon">
<svg height="24" viewbox="0 0 24 24" width="24">
<use height="24" width="24" xlink:href="#__github"></use>
</svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" id="nav-1" type="checkbox"/>
<label class="md-nav__link" for="nav-1">
      1.XAI基礎與概念介紹
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-1">
        1.XAI基礎與概念介紹
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../1.揭開模型的神秘面紗:為何XAI對機器學習如此重要/" title="[Day 1] 揭開模型的神秘面紗：為何XAI對機器學習如此重要？">
      [Day 1] 揭開模型的神秘面紗：為何XAI對機器學習如此重要？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2.從黑盒到透明化:XAI技術的發展之路/" title="[Day 2] 從黑盒到透明化：XAI技術的發展之路">
      [Day 2] 從黑盒到透明化：XAI技術的發展之路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../3.機器學習中的可解釋性指標/" title="[Day 3] 機器學習中的可解釋性指標">
      [Day 3] 機器學習中的可解釋性指標
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../4.LIME vs SHAP:哪種XAI解釋方法更適合你/" title="[Day 4] LIME vs. SHAP：哪種XAI解釋方法更適合你？">
      [Day 4] LIME vs. SHAP：哪種XAI解釋方法更適合你？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../5.淺談XAI與傳統機器學習的區別/" title="[Day 5] 淺談XAI與傳統機器學習的區別">
      [Day 5] 淺談XAI與傳統機器學習的區別
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-toggle md-nav__toggle" data-md-toggle="nav-2" id="nav-2" type="checkbox"/>
<label class="md-nav__link" for="nav-2">
      2.XAI在傳統機器學習中的應用
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-2">
        2.XAI在傳統機器學習中的應用
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../6.非監督學習也能做到可解釋性-探索XAI在非監督學習中的應用/" title="[Day 6] 非監督學習也能做到可解釋性？探索XAI在非監督學習中的應用">
      [Day 6] 非監督學習也能做到可解釋性？探索XAI在非監督學習中的應用
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../7.KNN與XAI:從鄰居中找出模型的決策邏輯/" title="[Day 7] KNN與XAI：從鄰居中找出模型的決策邏輯">
      [Day 7] KNN與XAI：從鄰居中找出模型的決策邏輯
    </a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-toggle md-nav__toggle" data-md-toggle="toc" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
        [Day 8] 解釋線性模型：探索線性迴歸和邏輯迴歸的可解釋性
      </label>
<a class="md-nav__link md-nav__link--active" href="./" title="[Day 8] 解釋線性模型：探索線性迴歸和邏輯迴歸的可解釋性">
      [Day 8] 解釋線性模型：探索線性迴歸和邏輯迴歸的可解釋性
    </a>
<nav class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">本頁目錄</label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#_1" title="線性迴歸模型">
    線性迴歸模型
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_2" title="解釋線性迴歸模型的方法（係數解釋、截距解釋）">
    解釋線性迴歸模型的方法（係數解釋、截距解釋）
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_3" title="[實作] 線性迴歸：糖尿病預測">
    [實作] 線性迴歸：糖尿病預測
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_4" title="邏輯迴歸模型">
    邏輯迴歸模型
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#odds-ratio" title="解釋邏輯迴歸模型的方法 (odds ratio)">
    解釋邏輯迴歸模型的方法 (odds ratio)
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_5" title="小結">
    小結
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../9.基於樹狀結構的XAI方法:決策樹的可解釋性/" title="[Day 9] 基於樹狀結構的XAI方法：決策樹的可解釋性">
      [Day 9] 基於樹狀結構的XAI方法：決策樹的可解釋性
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../10.Permutation Importance:從特徵重要性角度解釋整個模型行為/" title="[Day 10] Permutation Importance：從特徵重要性角度解釋整個模型行為">
      [Day 10] Permutation Importance：從特徵重要性角度解釋整個模型行為
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../11.Partial Dependence Plot:探索特徵對預測值的影響/" title="[Day 11] Partial Dependence Plot：探索特徵對預測值的影響">
      [Day 11] Partial Dependence Plot：探索特徵對預測值的影響
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" id="nav-3" type="checkbox"/>
<label class="md-nav__link" for="nav-3">
      3.XAI常用工具介紹
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-3">
        3.XAI常用工具介紹
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../12.LIME理論:如何用局部線性近似解釋黑箱模型/" title="[Day 12] LIME理論：如何用局部線性近似解釋黑箱模型">
      [Day 12] LIME理論：如何用局部線性近似解釋黑箱模型
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../13.LIME實作:實戰演練LIME解釋方法/" title="[Day 13] LIME實作：實戰演練LIME解釋方法">
      [Day 13] LIME實作：實戰演練LIME解釋方法
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../14.SHAP理論:解析SHAP解釋方法的核心/" title="[Day 14] SHAP理論：解析SHAP解釋方法的核心">
      [Day 14] SHAP理論：解析SHAP解釋方法的核心
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../15.SHAP實作:實戰演練SHAP解釋方法/" title="[Day 15] SHAP實作：實戰演練SHAP解釋方法">
      [Day 15] SHAP實作：實戰演練SHAP解釋方法
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" id="nav-4" type="checkbox"/>
<label class="md-nav__link" for="nav-4">
      4.XAI在深度學習中的可解釋性
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-4">
        4.XAI在深度學習中的可解釋性
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../16.神經網路的可解釋性:如何理解深度學習中的黑箱模型/" title="[Day 16] 神經網路的可解釋性：如何理解深度學習中的黑箱模型？">
      [Day 16] 神經網路的可解釋性：如何理解深度學習中的黑箱模型？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../17.解析深度神經網路:使用Deep SHAP進行模型解釋/" title="[Day 17] 解析深度神經網路：使用Deep SHAP進行模型解釋">
      [Day 17] 解析深度神經網路：使用Deep SHAP進行模型解釋
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../18.CNN卷積深度神經網路的解釋方法/" title="[Day 18] CNN：卷積深度神經網路的解釋方法">
      [Day 18] CNN：卷積深度神經網路的解釋方法
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../19.Perturbation Based如何用擾動方法解釋神經網路/" title="[Day 19] Perturbation-Based：如何用擾動方法解釋神經網路">
      [Day 19] Perturbation-Based：如何用擾動方法解釋神經網路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../20.Gradient Based利用梯度訊息解釋神經網路/" title="[Day 20] Gradient-Based：利用梯度訊息解釋神經網路">
      [Day 20] Gradient-Based：利用梯度訊息解釋神經網路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../21.Propagation Based探索反向傳播法的可解釋性/" title="[Day 21] Propagation-Based：探索反向傳播法的可解釋性">
      [Day 21] Propagation-Based：探索反向傳播法的可解釋性
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../22.CAM Based如何解釋卷積神經網路/" title="[Day 22] CAM-Based：如何解釋卷積神經網路">
      [Day 22] CAM-Based：如何解釋卷積神經網路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../23.Attention Based使用注意力機制解釋CNN模型/" title="[Day 23] Attention-Based：使用注意力機制解釋CNN模型">
      [Day 23] Attention-Based：使用注意力機制解釋CNN模型
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" id="nav-5" type="checkbox"/>
<label class="md-nav__link" for="nav-5">
      5.XAI在現實生活中的應用案例
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-5">
        5.XAI在現實生活中的應用案例
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../24.LSTM的可解釋性:解析步態分類中的時序資料/" title="[Day 24] LSTM的可解釋性：從時序資料解析人體姿態預測">
      [Day 24] LSTM的可解釋性：從時序資料解析人體姿態預測
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../25.XAI在影像處理中的瑕疵檢測:解釋卷積神經網路的運作/" title="[Day 25] XAI在影像處理中的瑕疵檢測：解釋卷積神經網路的運作">
      [Day 25] XAI在影像處理中的瑕疵檢測：解釋卷積神經網路的運作
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../26.智慧工廠製程中的鋼材缺陷檢測:運用XAI解析數值型感測器數據/" title="[Day 26] XAI在表格型資料的應用：解析智慧工廠中的鋼材缺陷">
      [Day 26] XAI在表格型資料的應用：解析智慧工廠中的鋼材缺陷
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../27.XAI在NLP中的應用:以情感分析解釋語言模型/" title="[Day 27] XAI在NLP中的應用：以情感分析解釋語言模型">
      [Day 27] XAI在NLP中的應用：以情感分析解釋語言模型
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" id="nav-6" type="checkbox"/>
<label class="md-nav__link" for="nav-6">
      6.XAI的挑戰與未來
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-6">
        6.XAI的挑戰與未來
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../28.誤差分析和對抗樣本:如何利用XAI檢測模型的弱點/" title="[Day 28] 對抗樣本的挑戰：如何利用XAI檢測模型的弱點？">
      [Day 28] 對抗樣本的挑戰：如何利用XAI檢測模型的弱點？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../29.XAI如何影響人類對技術的信任和接受程度/" title="[Day 29] XAI如何影響人類對技術的信任和接受程度？">
      [Day 29] XAI如何影響人類對技術的信任和接受程度？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../30.XAI未來發展方向:向更可靠的機器學習模型邁進/" title="[Day30] XAI未來發展方向：向更可靠的機器學習模型邁進">
      [Day30] XAI未來發展方向：向更可靠的機器學習模型邁進
    </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">本頁目錄</label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#_1" title="線性迴歸模型">
    線性迴歸模型
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_2" title="解釋線性迴歸模型的方法（係數解釋、截距解釋）">
    解釋線性迴歸模型的方法（係數解釋、截距解釋）
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_3" title="[實作] 線性迴歸：糖尿病預測">
    [實作] 線性迴歸：糖尿病預測
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_4" title="邏輯迴歸模型">
    邏輯迴歸模型
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#odds-ratio" title="解釋邏輯迴歸模型的方法 (odds ratio)">
    解釋邏輯迴歸模型的方法 (odds ratio)
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_5" title="小結">
    小結
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content">
<article class="md-content__inner md-typeset"><a class="md-content__icon pdf-download-btn" download href="../pdf/全民瘋AI系列_探索可解釋人工智慧_v1.1.pdf" title="Download"><i class="fa fas fa-download"></i><small> PDF</small></a>
<h1 id="day-8">[Day 8] 解釋線性模型：探索線性迴歸和邏輯迴歸的可解釋性</h1>
<p>範例程式：<a href="https://colab.research.google.com/github/andy6804tw/crazyai-xai/blob/main/code/08.解釋線性模型：探索線性迴歸和邏輯迴歸的可解釋性.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p>
<h2 id="_1">線性迴歸模型</h2>
<p>線性迴歸是一種統計學方法，用於建立自變數(x)和應變數(y)之間的線性關係模型。線性迴歸假設應變數是由一個或多個自變數線性組合而成的，且自變數之間不存在多重共線性，誤差項是獨立同分佈的，且呈現常態分佈。</p>
<p><img alt="" src="https://i.imgur.com/SRRdlKp.png"/></p>
<blockquote>
<p>圖片來源：<a href="http://reliawiki.org/index.php/Simple_Linear_Regression_Analysis">reliawiki</a></p>
</blockquote>
<p>在線性迴歸中，我們假設應變數和自變數之間存在一種線性關係，並使用最小平方法或梯度下降法來找到最佳擬合直線。整個線性迴歸的目標就是最小化我們的損失函數，因此最後可以用這條直線預測新數據點的值。</p>
<p><img alt="" src="../image/img8-1.png"/></p>
<blockquote>
<p>理論知識可以參考全民瘋AI系列2.0<a href="https://ithelp.ithome.com.tw/articles/10268453">線性迴歸 (Linear Regression)</a></p>
</blockquote>
<h2 id="_2">解釋線性迴歸模型的方法（係數解釋、截距解釋）</h2>
<p>接著我們來探討解釋線性迴歸模型的方法，一種常見的解釋線性迴歸模型的方法是係數解釋。這種方法通過分析迴歸模型的係數，來解釋自變數對應變數的影響。在簡單線性迴歸模型中，自變數的係數可以直接解釋為自變數對應變數的影響程度，例如當自變數增加1個單位時，應變數會增加多少個單位。在多元線性迴歸模型中，則需要考慮多個自變數的影響，通常可以通過控制其他變數的影響，來分析某一個自變數對應變數的影響。</p>
<p>另一種解釋線性迴歸模型的方法是截距解釋。截距在線性迴歸模型中表示當所有自變數均為0時，應變數的期望值，通常被稱為模型的基準值。截距的解釋可以幫助我們理解當自變數均為0時，應變數的期望值是多少。例如，在一個簡單線性迴歸模型中，截距可以解釋為當自變數等於0時，應變數的期望值是多少。在多元線性迴歸模型中，截距的解釋可以幫助我們理解當所有自變數均為0時，應變數的期望值是多少，這對於理解模型的基準值和比較不同模型的表現非常重要。</p>
<h2 id="_3">[實作] 線性迴歸：糖尿病預測</h2>
<p>diabetes 資料集是由美國糖尿病資料集中選取的442名病患的生物醫學數據集合。這些數據由10個生理特徵和1個預測目標（糖尿病患者在一年後的疾病進展情況）組成。每個特徵的意義如下：</p>
<ul>
<li>Age：年齡</li>
<li>Sex：性別（1表示男性，0表示女性）</li>
<li>Body mass index (BMI)：身體質量指數</li>
<li>Average blood pressure (BP)：平均血壓</li>
<li>S1：總膽固醇</li>
<li>S2：低密度脂蛋白</li>
<li>S3：高密度脂蛋白</li>
<li>S4：總膽固醇/高密度脂蛋白</li>
<li>S5：血清甘油三酯水平的對數</li>
<li>S6：血糖水平</li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># 載入Sklearn糖尿病預測資料集10個輸入特徵1個輸出</span>
<span class="n">diabetes</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">diabetes</span><span class="o">.</span><span class="n">data</span> <span class="c1"># 輸入特徵</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">diabetes</span><span class="o">.</span><span class="n">target</span> <span class="c1"># 輸出</span>
<span class="c1"># 切分訓練集測試集</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
<p>使用 Sklearn 建立線性迴歸模型。</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="c1"># 訓練模型</span>
<span class="n">linearModel</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">linearModel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
<p>模型訓練好以後，就可以觀察線性模型的特徵係數以及截距。</p>
<div class="codehilite"><pre><span></span><span class="c1"># 取得10個特徵係數</span>
<span class="nb">print</span><span class="p">(</span><span class="n">linearModel</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="c1"># 取得截距</span>
<span class="nb">print</span><span class="p">(</span><span class="n">linearModel</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
</pre></div>
<p>在本例子中輸入有十個特徵，因此線性迴歸式中每個特徵項都會對應一個係數。假設我們從測試集中提取一筆資料預測。由於輸入特徵已經過標準化，因此我們可以很快地觀察各項係數的大小來辦定特徵重要程度。可以發現在什麼都不輸入時會有個基底值(截距)151.346。</p>
<p><img alt="" src="../image/img8-2.png"/></p>
<h2 id="_4">邏輯迴歸模型</h2>
<p>線性迴歸和邏輯迴歸差別在於線性迴歸的目標是預測連續數值型的因變量。它基於線性關係建立模型，並且假設因變量和自變量之間存在線性關係。而邏輯迴歸也建立在一個線性模型的基礎上，但是它將線性模型的輸出通過一個稱為 S 形曲線（sigmoid 函數）的轉換，將線性模型的輸出映射到0和1之間，這樣預測結果就變成了二元類別。</p>
<p><img alt="" src="../image/img8-3.png"/></p>
<p>因此我們可以理解這個邏輯迴歸的輸出就相當於，模型根據輸入的特徵判斷結果是1的機率有多高。</p>
<p><img alt="" src="../image/img8-4.png"/></p>
<blockquote>
<p>理論知識可以參考全民瘋AI系列2.0<a href="https://ithelp.ithome.com.tw/articles/10269006">邏輯迴歸 (Logistic Regression)</a></p>
</blockquote>
<h2 id="odds-ratio">解釋邏輯迴歸模型的方法 (odds ratio)</h2>
<p>那麼邏輯迴歸該如何解釋呢？首先我們可以說預測出來的 ŷ 相當於是 y(i) 等於1的機率有多高(依據上面的公式)。另外還可以發現一件事情就是我們如果吧 <code>P(y(i)=1)</code> 除以 <code>P(y(i)=0)</code> 再取 log 之後其實是一個線性的關係。</p>
<p><img alt="" src="../image/img8-5.png"/></p>
<p><code>P(y(i)=1)</code> 除以 <code>P(y(i)=0)</code> 在統計上有個名詞稱之為勝算（odds），也就是「Y=1的機率」與「Y=0的機率」的比率。如果事件發生的機率是 p，那麼其不發生的機率就是 1-p，那麼此事件的勝算比就是 p/(1-p)。</p>
<p><img alt="" src="../image/img8-6.png"/></p>
<p>以銅板的例子來說，假設我們想要預測一個公平的銅板翻轉出現正面的機率，由於正反面出現的機率相等，因此 p=1/2。根據上述公式，其勝算比就是 p/(1-p) = (1/2) / (1/2) = 1，也就是說翻轉公平銅板出現正面的勝算比是1。</p>
<p>接著再以一個不公平的銅板為例，假設這個銅板正面朝上的機率是3/5，因此 p=3/5。根據上述公式，其勝算比就是 p/(1-p) = (3/5) / (2/5) = 3/2，也就是說翻轉這個不公平的銅板出現正面的勝算比是 3/2。</p>
<p>基於上述例子我們可以得出以下結論：
- 當 odds 大於1時，表示事件的發生機率較高，此時因變數 y 為1的機率較大。
- 當 odds 介於0和1之間時，表示事件的發生機率較低，此時因變數 y 為0的機率較大。</p>
<p>假設對數勝算（log odds）是一個線性函數，我們把 log 搬移到右邊變成取 exp 變成以下式子：</p>
<p><img alt="" src="../image/img8-7.png"/></p>
<p>所以我們可以在邏輯迴歸模型中，利用 odds ratio（勝算比）來解釋變數對於反應變數的影響。odds ratio 是指當一個自變數 X 的值增加 1 單位時，對應的勝算會乘上一個倍數，這個倍數即為 odds ratio。</p>
<p>具體來說，如果一個變數 X 的 odds ratio 為 2，表示當 X 增加 1 單位時，Y=1 的機率相對於 Y=0 的機率將會增加 2 倍。而如果 odds ratio 為 0.5，則表示當 X 增加 1 單位時，Y=1 的機率相對於 Y=0 的機率將會減少一半。</p>
<ul>
<li>如果 odds ratio 越大，表示該自變數對於反應變數的影響越大</li>
<li>如果 odds ratio 為 1，表示該自變數對於反應變數沒有影響</li>
<li>如果 odds ratio 小於 1，表示該自變數與反應變數呈現反向關係。</li>
</ul>
<p>然而在邏輯迴歸模型中，每個自變量都會有一個 odds ratio 值，可以通過比較 odds ratio 值的大小來判斷哪些自變量對事件發生的機率有較大的影響。在 sklearn 中，可以使用 LogisticRegression 模型的 coef_ 屬性獲取特徵的係數，並將其指數化以得到 odds ratio。以下是一個簡單的範例 code：</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># 載入自己的資料集</span>
<span class="n">X</span> <span class="o">=</span> <span class="o">...</span><span class="n">略</span>
<span class="n">y</span> <span class="o">=</span> <span class="o">...</span><span class="n">略</span>

<span class="c1"># 建立 Logistic Regression 模型並訓練</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># 獲取係數</span>
<span class="n">coef</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span>

<span class="c1"># 將係數指數化得到 odds ratio</span>
<span class="n">odds_ratio</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">coef</span><span class="p">)</span>
</pre></div>
<p>在這個範例中，X 是訓練資料，y 是每筆資料對應的標籤。獲取 coef_ 屬性之後，可以使用 np.exp() 函數將係數指數化。這樣可以得到所有特徵的 odds ratio 值，近一步的分析當 X 的值增加 1 單位時，所對應的勝算來觀察特徵重要性。</p>
<h2 id="_5">小結</h2>
<p>線性迴歸用於預測一個連續的數值，例如預測股票的價格或房屋的價格等。它假設自變數和因變數之間有線性關係，也就是說，當自變數的值增加一個單位時，因變數的值也會按比例增加或減少。</p>
<p>邏輯迴歸用於預測二元變數，例如預測某人是否患有某種疾病、電子郵件是否為垃圾郵件等。邏輯迴歸使用 sigmoid 函數將輸出限制在0到1之間，表示因變數屬於某個類別的機率。如果機率大於0.5，那麼我們就預測為1，否則預測為0。</p>
<p>線性迴歸的基本概念和假設是建立在數學統計學理論上，理解和掌握這些概念和假設可以幫助我們更好地應用線性迴歸模型進行實際問題的解決。綜上所述，線性迴歸模型的係數和截距是解釋自變數對應變數的影響和模型基準值的重要因素，透過對這些因素的分析，可以幫助我們更好地理解線性迴歸模型的行為。</p>
</article>
</div>
</div>
</main>
<footer class="md-footer">
<div class="md-footer-nav">
<nav class="md-footer-nav__inner md-grid">
<a class="md-flex md-footer-nav__link md-footer-nav__link--prev" href="../7.KNN與XAI:從鄰居中找出模型的決策邏輯/" rel="prev" title="[Day 7] KNN與XAI：從鄰居中找出模型的決策邏輯">
<div class="md-flex__cell md-flex__cell--shrink">
<i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
</div>
<div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
<span class="md-flex__ellipsis">
<span class="md-footer-nav__direction">
                  上一頁
                </span>
                [Day 7] KNN與XAI：從鄰居中找出模型的決策邏輯
              </span>
</div>
</a>
<a class="md-flex md-footer-nav__link md-footer-nav__link--next" href="../9.基於樹狀結構的XAI方法:決策樹的可解釋性/" rel="next" title="[Day 9] 基於樹狀結構的XAI方法：決策樹的可解釋性">
<div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
<span class="md-flex__ellipsis">
<span class="md-footer-nav__direction">
                  下一頁
                </span>
                [Day 9] 基於樹狀結構的XAI方法：決策樹的可解釋性
              </span>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
</div>
</a>
</nav>
</div>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-footer-copyright">
<div class="md-footer-copyright__highlight">
            Copyright © 2023 - 2024 10程式中
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
</div>
</div>
</div>
</footer>
</div>
<script src="../assets/javascripts/application.245445c6.js"></script>
<script src="../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
<script src="../assets/javascripts/lunr/tinyseg.js"></script>
<script src="../assets/javascripts/lunr/lunr.ja.js"></script>
<script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
<script src="../javascripts/extra.js"></script>
<script src="../javascripts/analytics.js"></script>
</body>
</html>