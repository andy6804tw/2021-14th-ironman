
<!DOCTYPE html>

<html class="no-js" lang="zh-Hant">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="ie=edge" http-equiv="x-ua-compatible"/>
<meta content="10程式中" name="author"/>
<meta content="複製" name="lang:clipboard.copy"/>
<meta content="已複製" name="lang:clipboard.copied"/>
<meta content="ja" name="lang:search.language"/>
<meta content="True" name="lang:search.pipeline.stopwords"/>
<meta content="True" name="lang:search.pipeline.trimmer"/>
<meta content="沒有符合的項目" name="lang:search.result.none"/>
<meta content="找到 1 個符合的項目" name="lang:search.result.one"/>
<meta content="找到 # 個符合的項目" name="lang:search.result.other"/>
<meta content="[\uff0c\u3002]+" name="lang:search.tokenizer"/>
<link href="assets/images/favicon.png" rel="shortcut icon"/>
<meta content="mkdocs-1.0.4, mkdocs-material-4.4.0" name="generator"/>
<title>[Day 22] CAM-Based:如何解釋卷積神經網路 - 全民瘋AI系列 [探索可解釋人工智慧]</title>
<link href="assets/stylesheets/application.0284f74d.css" rel="stylesheet"/>
<link href="assets/stylesheets/application-palette.01803549.css" rel="stylesheet"/>
<meta content="#7e57c2" name="theme-color"/>
<script src="assets/javascripts/modernizr.74668098.js"></script>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&amp;display=fallback" rel="stylesheet"/>
<style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
<link href="assets/fonts/material-icons.css" rel="stylesheet"/>
<link href="stylesheets/extra.css" rel="stylesheet"/>
</head>
<body data-md-color-accent="deep-purple" data-md-color-primary="deep-purple" dir="ltr">
<svg class="md-svg">
<defs>
<svg height="448" id="__github" viewbox="0 0 416 448" width="416" xmlns="http://www.w3.org/2000/svg"><path d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z" fill="currentColor"></path></svg>
</defs>
</svg>
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
<a class="md-skip" href="#day-22-cam-based" tabindex="1">
        跳轉到
      </a>
<header class="md-header" data-md-component="header">
<nav class="md-header-nav md-grid">
<div class="md-flex">
<div class="md-flex__cell md-flex__cell--shrink">
<a class="md-header-nav__button md-logo" href="." title="全民瘋AI系列 [探索可解釋人工智慧]">
<i class="md-icon"></i>
</a>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
</div>
<div class="md-flex__cell md-flex__cell--stretch">
<div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
<span class="md-header-nav__topic">
              全民瘋AI系列 [探索可解釋人工智慧]
            </span>
<span class="md-header-nav__topic">
              
                [Day 22] CAM-Based:如何解釋卷積神經網路
              
            </span>
</div>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="query" data-md-state="active" name="query" placeholder="搜尋" spellcheck="false" type="text"/>
<label class="md-icon md-search__icon" for="__search"></label>
<button class="md-icon md-search__icon" data-md-component="reset" tabindex="-1" type="reset">
        
      </button>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="result">
<div class="md-search-result__meta">
            打字進行搜尋
          </div>
<ol class="md-search-result__list"></ol>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<div class="md-header-nav__source">
<a class="md-source" data-md-source="github" href="https://github.com/andy6804tw/2020-12th-ironman" title="前往倉庫">
<div class="md-source__icon">
<svg height="24" viewbox="0 0 24 24" width="24">
<use height="24" width="24" xlink:href="#__github"></use>
</svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
</div>
</div>
</nav>
</header>
<div class="md-container">
<main class="md-main">
<div class="md-main__inner md-grid" data-md-component="container">
<div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav class="md-nav md-nav--primary" data-md-level="0">
<label class="md-nav__title md-nav__title--site" for="__drawer">
<a class="md-nav__button md-logo" href="." title="全民瘋AI系列 [探索可解釋人工智慧]">
<i class="md-icon"></i>
</a>
    全民瘋AI系列 [探索可解釋人工智慧]
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-source="github" href="https://github.com/andy6804tw/2020-12th-ironman" title="前往倉庫">
<div class="md-source__icon">
<svg height="24" viewbox="0 0 24 24" width="24">
<use height="24" width="24" xlink:href="#__github"></use>
</svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" id="nav-1" type="checkbox"/>
<label class="md-nav__link" for="nav-1">
      1. XAI 基礎與概念介紹
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-1">
        1. XAI 基礎與概念介紹
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="1. 揭開模型的神秘面紗:為何XAI對機器學習如此重要.html" title="[Day 1] 揭開模型的神秘面紗:為何XAI對機器學習如此重要?">
      [Day 1] 揭開模型的神秘面紗:為何XAI對機器學習如此重要?
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="2. 從黑盒到透明化:XAI技術的發展之路.html" title="[Day 2] 從黑盒到透明化:XAI技術的發展之路">
      [Day 2] 從黑盒到透明化:XAI技術的發展之路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="3. 機器學習中的可解釋性指標.html" title="[Day 3] 機器學習中的可解釋性指標">
      [Day 3] 機器學習中的可解釋性指標
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="4. LIME vs SHAP:哪種XAI解釋方法更適合你.html" title="[Day 4] LIME vs. SHAP:哪種XAI解釋方法更適合你?">
      [Day 4] LIME vs. SHAP:哪種XAI解釋方法更適合你?
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="5. 淺談XAI與傳統機器學習的區別.html" title="[Day 5] 淺談XAI與傳統機器學習的區別">
      [Day 5] 淺談XAI與傳統機器學習的區別
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" id="nav-2" type="checkbox"/>
<label class="md-nav__link" for="nav-2">
      2. XAI 在傳統機器學習中的應用
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-2">
        2. XAI 在傳統機器學習中的應用
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="6. 非監督學習也能做到可解釋性-探索XAI在非監督學習中的應用.html" title="[Day 6] 非監督學習也能做到可解釋性?探索XAI在非監督學習中的應用">
      [Day 6] 非監督學習也能做到可解釋性?探索XAI在非監督學習中的應用
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="7. KNN與XAI:從鄰居中找出模型的決策邏輯.html" title="[Day 7] KNN與XAI:從鄰居中找出模型的決策邏輯">
      [Day 7] KNN與XAI:從鄰居中找出模型的決策邏輯
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="8. 解釋線性模型:探索線性迴歸和邏輯迴歸的可解釋性.html" title="[Day 8] 解釋線性模型:探索線性迴歸和邏輯迴歸的可解釋性">
      [Day 8] 解釋線性模型:探索線性迴歸和邏輯迴歸的可解釋性
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="9. 基於樹狀結構的XAI方法:決策樹的可解釋性.html" title="[Day 9] 基於樹狀結構的XAI方法:決策樹的可解釋性">
      [Day 9] 基於樹狀結構的XAI方法:決策樹的可解釋性
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="10. Permutation Importance:從特徵重要性角度解釋整個模型行為.html" title="[Day 10] Permutation Importance:從特徵重要性角度解釋整個模型行為">
      [Day 10] Permutation Importance:從特徵重要性角度解釋整個模型行為
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="11. Partial Dependence Plot:探索特徵對預測值的影響.html" title="[Day 11] Partial Dependence Plot:探索特徵對預測值的影響">
      [Day 11] Partial Dependence Plot:探索特徵對預測值的影響
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" id="nav-3" type="checkbox"/>
<label class="md-nav__link" for="nav-3">
      3. XAI 常用工具介紹
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-3">
        3. XAI 常用工具介紹
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="12. LIME理論:如何用局部線性近似解釋黑箱模型.html" title="[Day 12] LIME理論:如何用局部線性近似解釋黑箱模型">
      [Day 12] LIME理論:如何用局部線性近似解釋黑箱模型
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="13. LIME實作:實戰演練LIME解釋方法.html" title="[Day 13] LIME實作:實戰演練LIME解釋方法">
      [Day 13] LIME實作:實戰演練LIME解釋方法
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="14. SHAP理論:解析SHAP解釋方法的核心.html" title="[Day 14] SHAP理論:解析SHAP解釋方法的核心">
      [Day 14] SHAP理論:解析SHAP解釋方法的核心
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="15. SHAP實作:實戰演練SHAP解釋方法.html" title="[Day 15] SHAP實作:實戰演練SHAP解釋方法">
      [Day 15] SHAP實作:實戰演練SHAP解釋方法
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-toggle md-nav__toggle" data-md-toggle="nav-4" id="nav-4" type="checkbox"/>
<label class="md-nav__link" for="nav-4">
      4. XAI 在深度學習中的可解釋性
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-4">
        4. XAI 在深度學習中的可解釋性
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="16. 神經網路的可解釋性:如何理解深度學習中的黑箱模型.html" title="[Day 16] 神經網路的可解釋性:如何理解深度學習中的黑箱模型?">
      [Day 16] 神經網路的可解釋性:如何理解深度學習中的黑箱模型?
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="17.  解析深度神經網路:使用Deep SHAP進行模型解釋.html" title="[Day 17] 解析深度神經網路:使用Deep SHAP進行模型解釋">
      [Day 17] 解析深度神經網路:使用Deep SHAP進行模型解釋
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="18. CNN:卷積深度神經網路的解釋方法.html" title="[Day 18] CNN:卷積深度神經網路的解釋方法">
      [Day 18] CNN:卷積深度神經網路的解釋方法
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="19. Perturbation-Based:如何用擾動方法解釋神經網路.html" title="[Day 19] Perturbation-Based:如何用擾動方法解釋神經網路">
      [Day 19] Perturbation-Based:如何用擾動方法解釋神經網路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="20. Gradient-Based:利用梯度訊息解釋神經網路.html" title="[Day 20] Gradient-Based:利用梯度訊息解釋神經網路">
      [Day 20] Gradient-Based:利用梯度訊息解釋神經網路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="21. Propagation-Based:探索反向傳播法的可解釋性.html" title="[Day 21] Propagation-Based:探索反向傳播法的可解釋性">
      [Day 21] Propagation-Based:探索反向傳播法的可解釋性
    </a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-toggle md-nav__toggle" data-md-toggle="toc" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
        [Day 22] CAM-Based:如何解釋卷積神經網路
      </label>
<a class="md-nav__link md-nav__link--active" href="22. CAM-Based:如何解釋卷積神經網路.html" title="[Day 22] CAM-Based:如何解釋卷積神經網路">
      [Day 22] CAM-Based:如何解釋卷積神經網路
    </a>
<nav class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">本頁目錄</label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#cam" title="CAM">
    CAM
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#grad-cam" title="Grad-CAM">
    Grad-CAM
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#cam-based-grad-cam" title="CAM-Based 方法實作 (Grad-CAM)">
    CAM-Based 方法實作 (Grad-CAM)
  </a>
<nav class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#xception" title="載入預訓練模型(Xception)">
    載入預訓練模型(Xception)
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#grad-cam_1" title="Grad-CAM 實作">
    Grad-CAM 實作
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#reference" title="Reference">
    Reference
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="23. Attention-Based:使用注意力機制解釋CNN模型.html" title="[Day 23] Attention-Based:使用注意力機制解釋CNN模型">
      [Day 23] Attention-Based:使用注意力機制解釋CNN模型
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" id="nav-5" type="checkbox"/>
<label class="md-nav__link" for="nav-5">
      5. XAI 在現實生活中的應用案例
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-5">
        5. XAI 在現實生活中的應用案例
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="24. LSTM的可解釋性:解析步態分類中的時序資料.html" title="[Day 24] LSTM的可解釋性:從時序資料解析人體姿態預測">
      [Day 24] LSTM的可解釋性:從時序資料解析人體姿態預測
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="25. XAI在影像處理中的瑕疵檢測:解釋卷積神經網路的運作.html" title="[Day 25] XAI在影像處理中的瑕疵檢測:解釋卷積神經網路的運作">
      [Day 25] XAI在影像處理中的瑕疵檢測:解釋卷積神經網路的運作
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="26. 智慧工廠製程中的鋼材缺陷檢測:運用XAI解析數值型感測器數據.html" title="[Day 26] XAI在表格型資料的應用:解析智慧工廠中的鋼材缺陷">
      [Day 26] XAI在表格型資料的應用:解析智慧工廠中的鋼材缺陷
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="27. XAI在NLP中的應用:以情感分析解釋語言模型.html" title="[Day 27] XAI在NLP中的應用:以情感分析解釋語言模型">
      [Day 27] XAI在NLP中的應用:以情感分析解釋語言模型
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" id="nav-6" type="checkbox"/>
<label class="md-nav__link" for="nav-6">
      6. XAI 的挑戰與未來
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-6">
        6. XAI 的挑戰與未來
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="28. 誤差分析和對抗樣本:如何利用XAI檢測模型的弱點.html" title="[Day 28] XAI如何影響人類對技術的信任和接受程度?">
      [Day 28] XAI如何影響人類對技術的信任和接受程度?
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="29. XAI如何影響人類對技術的信任和接受程度.html" title="[Day 29] 對抗樣本的挑戰:如何利用XAI檢測模型的弱點?">
      [Day 29] 對抗樣本的挑戰:如何利用XAI檢測模型的弱點?
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="30. XAI未來發展方向:向更可靠的機器學習模型邁進.html" title="[Day 30] XAI未來發展方向:向更可靠的機器學習模型邁進">
      [Day 30] XAI未來發展方向:向更可靠的機器學習模型邁進
    </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">本頁目錄</label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#cam" title="CAM">
    CAM
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#grad-cam" title="Grad-CAM">
    Grad-CAM
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#cam-based-grad-cam" title="CAM-Based 方法實作 (Grad-CAM)">
    CAM-Based 方法實作 (Grad-CAM)
  </a>
<nav class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#xception" title="載入預訓練模型(Xception)">
    載入預訓練模型(Xception)
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#grad-cam_1" title="Grad-CAM 實作">
    Grad-CAM 實作
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#reference" title="Reference">
    Reference
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content">
<article class="md-content__inner md-typeset"><a class="md-content__icon pdf-download-btn" download href="pdf/全民瘋AI系列_探索可解釋人工智慧_v1.1.pdf" title="Download"><i class="fa fas fa-download"></i><small> PDF</small></a>
<h1 id="day-22-cam-based">[Day 22] CAM-Based：如何解釋卷積神經網路</h1>
<p>CAM（Class Activation Mapping）是一種用於解釋卷積神經網路（CNN）模型在圖像分類任務中的預測的技術。它的目的是生成一個視覺化的熱圖，以顯示模型在圖像中關注的區域，以及這些區域對於模型預測某一類別的貢獻。以下是近年來與 CAM 相關的變形方法的整理：</p>
<ul>
<li><a href="https://arxiv.org/abs/1512.04150">CAM (Class Activation Mapping)</a> (Zhou et al. 2015):
基本的CAM方法是用來解釋CNN模型的預測，通過將卷積層的特徵圖與全連接層的權重相結合，生成類別特定的熱圖，以顯示模型對於不同類別的注意力分佈。</li>
<li><a href="https://arxiv.org/abs/1610.02391">Grad-CAM (Gradient-weighted Class Activation Mapping)</a> (Ancona et al. 2016):
Grad-CAM建立在CAM的基礎上，使用梯度訊息來更準確地計算特徵圖上的權重。它通過將卷積層的梯度值與特徵圖相乘，生成熱圖，以視覺化模型對於不同類別的關注點。</li>
<li><a href="https://arxiv.org/abs/1710.11063">Grad-CAM++</a> (Chattopadhyay et al. 2017):
Grad-CAM++是Grad-CAM的進一步改進版本，它引入了多尺度特徵圖的概念，以提高對於細微細節的解釋能力。它使用多個卷積層的特徵圖來生成更具細節的熱圖。</li>
<li><a href="https://arxiv.org/abs/1910.01279">Score-CAM</a> (Haofan et al. 2020):
Score-CAM是一種用於解釋模型預測的方法，它通過將通道的分數（score）和特徵圖相乘，生成類別特定的熱圖。它旨在提高CAM方法的性能，並減少噪聲。</li>
</ul>
<p>在今天的內容中，將介紹 CAM 和 Grad-CAM 的差別，最後使用 TensorFlow 來示範如何運用 Grad-CAM 方法來解釋 CNN 模型。</p>
<h2 id="cam">CAM</h2>
<p>CAM 在 2015 年被提出，論文名稱為 <a href="https://arxiv.org/abs/1512.04150">Learning Deep Features for Discriminative Localization</a>，它的主要概念是將 CNN 的最後一個卷積層的特徵圖之後接上全局平均池化層(Global Average Pooling Layer)與全連接層的權重相結合。首先計算每個類別的權重，這些權重是全連接層的權重與卷積層的特徵圖相乘後的總和。接著將這些權重應用到卷積層的特徵圖上，生成一個類別特定的熱圖。這個熱圖顯示了對於某一特定類別，圖像的不同區域的相對重要性。最後熱圖經過適當的正規化處理，以確保它可以被視覺化並與原始圖像尺寸對應。</p>
<p><img alt="" src="image/img22-1.png"/></p>
<p>全局平均池化（Global Average Pooling）是一種用於卷積神經網路（CNN）中的特徵映射的操作。它通常用於卷積神經網路的最後一層，以幫助縮減特徵圖的維度並生成一個固定大小的輸出，以供後續的分類或回歸任務使用。全局平均池化的過程非常簡單，以下用一張特徵圖為例，假設 pool size 4*4 也就是對整張圖做平均得到 24 這就是一個通道(一張特徵圖) GAP 後的結果。</p>
<p><img alt="" src="image/img22-2.png"/></p>
<p>簡單來說全局平均池化做法屬於空間維度的一種特徵壓縮，因為這個實數是根據所有特徵值計算出來的，所以在某種程度上具有平均感受野，最後保持通道數不變，所以最後輸出大小為 1x1xC：</p>
<p><img alt="" src="image/img22-3.png"/></p>
<p>經過全局平均池化（GAP）後，我們得到了一個包含權重 w 的像素陣列。這些權重 w 反映了每張特徵圖對於最終預測某個類別的重要性。更大的權重值表示相應特徵圖對於該分類的貢獻更大。</p>
<p><img alt="" src="image/img22-4.png"/></p>
<p>為了更好地理解這些權重，我們可以將它們應用於整張特徵圖上的每個像素點，然後進行疊加。這樣做的好處是我們可以根據每張特徵圖的重要性來集中關注不同的區域。如果某特定分類的權重 w 很大，那麼該分類所對應的特徵圖將在進行疊加時具有更大的影響。相反，權重接近於0的特徵圖對於最終的關注度較低，因此它們被視為不太重要的部分。</p>
<p><img alt="" src="image/img22-5.png"/></p>
<p>此方法確實為解釋 CNN 模型的預測提供了重要的基礎，但它存在一個明顯的限制，即受到了網路架構的限制。因為如果要使用 CAM 解釋，在 CNN 架構當中最後一層一定要接上 GAP 層。隨後的方法，如Grad-CAM和其變種，試圖克服這些限制，使解釋性方法更具通用性，適用於各種深度學習模型。</p>
<h2 id="grad-cam">Grad-CAM</h2>
<p>從 CAM 的介紹中，我們了解到實現 CAM 所需的一個關鍵條件是必須加入全局平均池化（GAP）層。然而這種要求在某種程度上限制了網路架構的自由度，因為模型必須包含 GAP 層才能使用 CAM。更重要的是，如果我們堅持要求模型的最後一層必須是GAP層，這可能會影響模型的準確性。因此 Grad-CAM 在這方面解除了這種限制，它出自於這邊論文 <a href="https://arxiv.org/abs/1610.02391">Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization </a>。使用 Grad-CAM 我們可以對一般的 CNN 架構進行解釋，而不需要強制要求模型的最後一層必須是 GAP 層。這意味著我們可以更靈活地應用 Grad-CAM 來獲得 CNN 對輸入圖片的關注區域，而無需對模型進行大幅度的修改，同時不會明顯影響模型的準確性。</p>
<p>從下圖中可以清楚地看到，不論是全連接層、RNN、LSTM，或者更複雜的網路模型，都可以透過 Grad-CAM 取得神經網絡的分類關注區域熱力圖。</p>
<p><img alt="" src="image/img22-6.png"/></p>
<p>簡單來說 Grad-CAM 的關鍵在於能夠透過反向傳播計算用於 CAM 的權重 𝑤。我們可以針對每個特徵圖進行反向傳播，計算梯度的平均值，以獲得相對應的權重。最後，將這些權重（𝑊₁, 𝑊₂, …, 𝑊𝑛）與特徵圖相乘，然後進行總和，就可以觀察到不同位置對輸出的影響。</p>
<p><img alt="" src="image/img22-7.png"/></p>
<h2 id="cam-based-grad-cam">CAM-Based 方法實作 (Grad-CAM)</h2>
<p>今天的範例將使用 Xception 預訓練模型來示範如何透過 Grad-CAM 解釋模型推論結果。Xception 的名稱是由 <code>Extreme Inception</code> 衍生而來，因為它基於 Inception v3 架構的概念，並對一些地方進行了極端擴展和改進。</p>
<blockquote>
<p>Xception 論文：<a href="https://arxiv.org/abs/1610.02357">Xception: Deep Learning with Depthwise Separable Convolutions</a></p>
</blockquote>
<h3 id="xception">載入預訓練模型(Xception)</h3>
<p>首先使用 TensorFlow 載入 Xception 模型，將輸入張量(tensor)連接到預訓練的神經網路層，<code>imagenet</code> 表示使用在 ImageNet 資料集上預訓練的權重。<code>include_top=True</code> 表示輸出包括模型的最後分類層(全連接層)，此模型通常用於影像分類任務。</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.applications.xception</span> <span class="kn">import</span> <span class="n">Xception</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Input</span>

<span class="c1"># 建立一個輸入張量，指定圖像大小為224x224（RGB色彩通道）</span>
<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="c1"># 建立 Xception 模型</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Xception</span><span class="p">(</span><span class="n">input_tensor</span><span class="o">=</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">'imagenet'</span><span class="p">,</span> <span class="n">include_top</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
<p>接著載入一張圖像，對其進行預處理。其中 <code>np.expand_dims()</code> 的目的是將圖像轉換為模型可接受的維度，這裡將圖像包裝在一個批次(batch)中，通常是一個批次只有一張圖像。最後使用 Xception 模型的預處理函數 <code>preprocess_input()</code> 來處理圖像，以確保圖像的數值範圍和格式符合模型的要求。</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.applications.xception</span> <span class="kn">import</span> <span class="n">preprocess_input</span>

<span class="c1"># 載入圖像</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">load_img</span><span class="p">(</span><span class="s1">'./dataset/cat_dog.jpg'</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="c1"># 將載入的圖像轉換為數組形式</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># 將圖像轉換為模型可接受的維度</span>
<span class="c1"># 預處理圖像</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">preprocess_input</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
<p>確認輸入影像都完成處理過後，就可以使用已建立的 Xception 模型進行圖像分類預測，返回分類機率。最後再使用 <code>decode_predictions()</code> 解析取得預測結果，並取得類別名稱和相對應的預測機率。</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.applications.xception</span> <span class="kn">import</span> <span class="n">decode_predictions</span>

<span class="c1"># 進行圖像分類預測</span>
<span class="n">pred_proba</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 返回分類機率</span>
<span class="c1"># 解析預測結果</span>
<span class="n">pred_class</span> <span class="o">=</span> <span class="n">decode_predictions</span><span class="p">(</span><span class="n">pred_proba</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># 解析取得預測結果</span>
</pre></div>
<p>我們先來看看模型預測的結果。雖然這張影像同時有一隻貓和狗，但模型在神經網路中先抓取到狗的重要特徵(例如：鼻子、嘴巴)，因此最終模型預測 <code>bull_mastiff</code>(鬥牛獒)，該類別的機率值有 48%。</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'uint8'</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>
<span class="n">predicted_class_name</span> <span class="o">=</span> <span class="n">pred_class</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Prediction: </span><span class="si">{</span><span class="n">predicted_class_name</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">pred_class</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<p><img alt="" src="image/img22-8.png"/></p>
<h3 id="grad-cam_1">Grad-CAM 實作</h3>
<p>這段函式主要用於生成Grad-CAM熱圖，以視覺化深度學習模型對於輸入圖像的預測結果的解釋性。首先建立一個新的模型 grad_model，該模型接受相同的輸入圖像，但同時輸出最後一個卷積層的輸出和整個模型的預測結果。這是為了能夠計算特定類別對於最後一個卷積層的梯度。接下來，使用 TensorFlow 的 GradientTape 來記錄計算梯度。它計算了模型對於輸入圖像的預測，同時記錄了對應於特定類別的分類神經元相對於最後一個卷積層輸出的梯度。然後計算這些梯度的平均強度 pooled_grads，並取得一個向量做為權重，每個元素對應於最後一個卷積層的特徵圖通道。接著將最後一個卷積層的輸出與 pooled_grads 做點積，這個操作強調了對於特定類別預測重要的特徵圖區域。得到的結果是一個熱圖，其中每個像素值表示相應位置對於該類別預測的重要性。最後為了視覺化，將熱圖的值正規化為介於0和1之間，以便更容易理解和視覺化。</p>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">make_gradcam_heatmap</span><span class="p">(</span><span class="n">img_array</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">last_conv_layer_name</span><span class="p">,</span> <span class="n">pred_index</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># 建立一個模型，同時輸出最後一個卷積層和整個模型的預測結果</span>
    <span class="n">grad_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span>
        <span class="n">model</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="n">last_conv_layer_name</span><span class="p">)</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">output</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="c1"># 計算對於輸入圖像的預測類別，相對於最後一個卷積層的梯度</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">last_conv_layer_output</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">grad_model</span><span class="p">(</span><span class="n">img_array</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">pred_index</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pred_index</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">preds</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">class_channel</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[:,</span> <span class="n">pred_index</span><span class="p">]</span>

    <span class="c1"># 輸出分類神經元相對於最後一個卷積層的輸出特徵圖的梯度</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">class_channel</span><span class="p">,</span> <span class="n">last_conv_layer_output</span><span class="p">)</span>

    <span class="c1"># 這是一個向量，其中每個數字都是特定特徵圖通道上的梯度的平均強度</span>
    <span class="n">pooled_grads</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

    <span class="c1"># 將特徵圖乘以權重，等於該特徵圖中的某些區域對於該分類的重要性</span>
    <span class="n">last_conv_layer_output</span> <span class="o">=</span> <span class="n">last_conv_layer_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">heatmap</span> <span class="o">=</span> <span class="n">last_conv_layer_output</span> <span class="o">@</span> <span class="n">pooled_grads</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
    <span class="n">heatmap</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">heatmap</span><span class="p">)</span> <span class="c1"># 然後將所有通道相加以獲得熱圖</span>

    <span class="c1"># 為了視覺化，將熱圖正規化0~1之間</span>
    <span class="n">heatmap</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">heatmap</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">heatmap</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">heatmap</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
<p>接下來我們實際將影像、模型以及最後一層卷積的名稱餵入我們剛剛建立的函式，然後繪製出一張熱圖。在這篇文章中，我們使用的是 Xception 模型架構，其最後一層卷積層的名稱為 <code>block14_sepconv2_act</code>。如果不知道最後一層的名稱是什麼，可以透過 <code>model.summary()</code> 來查看模型的結構，然後尋找最後一個 Conv2D 層的名稱。</p>
<p><img alt="" src="image/img22-9.png"/></p>
<div class="codehilite"><pre><span></span><span class="c1"># 產生 class activation heatmap</span>
<span class="n">last_conv_layer_name</span> <span class="o">=</span> <span class="s2">"block14_sepconv2_act"</span>
<span class="n">heatmap</span> <span class="o">=</span> <span class="n">make_gradcam_heatmap</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">last_conv_layer_name</span><span class="p">)</span>

<span class="c1"># 顯示 heatmap</span>
<span class="n">plt</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">heatmap</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
<p>由於最後一層的卷積特徵圖大小為 <code>(None, 7, 7, 2048)</code>，因此最後計算出來的熱圖大小為一張將過正規化的 <code>7*7</code> 像素大小的熱圖。</p>
<p><img alt="" src="image/img22-10.png"/></p>
<p>最後這段程式是將剛剛得到的熱圖與原始影像進行疊合視覺化結果。此函式接受四個主要的輸入參數：</p>
<ul>
<li>img_path: 輸入圖像的路徑，這是要解釋的圖像。</li>
<li>heatmap: Grad-CAM 熱圖，表示模型對圖像中不同區域的關注程度。</li>
<li>cam_path: 輸出的熱圖圖像檔案的路徑。</li>
<li>alpha: 控制疊加熱圖和原始圖像的透明度。</li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.cm</span> <span class="k">as</span> <span class="nn">cm</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">display</span>

<span class="k">def</span> <span class="nf">save_and_display_gradcam</span><span class="p">(</span><span class="n">img_path</span><span class="p">,</span> <span class="n">heatmap</span><span class="p">,</span> <span class="n">cam_path</span><span class="o">=</span><span class="s2">"cam.jpg"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">):</span>
    <span class="c1"># 載入原始圖像</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">load_img</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

    <span class="c1"># 將熱圖重新縮放到0-255的範圍</span>
    <span class="n">heatmap</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">(</span><span class="mi">255</span> <span class="o">*</span> <span class="n">heatmap</span><span class="p">)</span>

    <span class="c1"># 使用Jet色彩映射將熱圖上色</span>
    <span class="n">jet</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s2">"jet"</span><span class="p">)</span>

    <span class="c1"># 使用Jet色彩映射的RGB值</span>
    <span class="n">jet_colors</span> <span class="o">=</span> <span class="n">jet</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">256</span><span class="p">))[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">]</span>
    <span class="n">jet_heatmap</span> <span class="o">=</span> <span class="n">jet_colors</span><span class="p">[</span><span class="n">heatmap</span><span class="p">]</span>

    <span class="c1"># 創建帶有RGB色彩的熱圖圖像</span>
    <span class="n">jet_heatmap</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">array_to_img</span><span class="p">(</span><span class="n">jet_heatmap</span><span class="p">)</span>
    <span class="n">jet_heatmap</span> <span class="o">=</span> <span class="n">jet_heatmap</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">jet_heatmap</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">jet_heatmap</span><span class="p">)</span>

    <span class="c1"># 在原始圖像上疊加熱圖</span>
    <span class="n">superimposed_img</span> <span class="o">=</span> <span class="n">jet_heatmap</span> <span class="o">*</span> <span class="n">alpha</span> <span class="o">+</span> <span class="n">img</span>
    <span class="n">superimposed_img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">array_to_img</span><span class="p">(</span><span class="n">superimposed_img</span><span class="p">)</span>

    <span class="c1"># 儲存疊加後的圖像</span>
    <span class="n">superimposed_img</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">cam_path</span><span class="p">)</span>

    <span class="c1"># 顯示Grad CAM</span>
    <span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="p">(</span><span class="n">cam_path</span><span class="p">))</span>
</pre></div>
<div class="codehilite"><pre><span></span><span class="n">save_and_display_gradcam</span><span class="p">(</span><span class="s1">'./dataset/cat_dog.jpg'</span><span class="p">,</span> <span class="n">heatmap</span><span class="p">)</span>
</pre></div>
<p>最後我們就能得到一張完整的 Grad-CAM 解釋圖了。從圖中可很明顯知道模型辨識一隻狗是關注影像中的哪一個特徵作為判斷依據。</p>
<p><img alt="" src="image/img22-11.png"/></p>
<p>如果想透過第三方套件進行 CNN 模型解釋也可以使用 <a href="https://github.com/sicara/tf-explain">tf_explain</a>，它是一個針對 TensorFlow 深度學習模型解釋的 Python 套件。內建提供了多種方法，並透過熱力圖可以用來觀察模型是否學到關鍵特徵。</p>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://keras.io/examples/vision/grad_cam/">Grad-CAM class activation visualization</a></li>
</ul>
</article>
</div>
</div>
</main>
<footer class="md-footer">
<div class="md-footer-nav">
<nav class="md-footer-nav__inner md-grid">
<a class="md-flex md-footer-nav__link md-footer-nav__link--prev" href="21. Propagation-Based:探索反向傳播法的可解釋性.html" rel="prev" title="[Day 21] Propagation-Based:探索反向傳播法的可解釋性">
<div class="md-flex__cell md-flex__cell--shrink">
<i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
</div>
<div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
<span class="md-flex__ellipsis">
<span class="md-footer-nav__direction">
                  上一頁
                </span>
                [Day 21] Propagation-Based:探索反向傳播法的可解釋性
              </span>
</div>
</a>
<a class="md-flex md-footer-nav__link md-footer-nav__link--next" href="23. Attention-Based:使用注意力機制解釋CNN模型.html" rel="next" title="[Day 23] Attention-Based:使用注意力機制解釋CNN模型">
<div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
<span class="md-flex__ellipsis">
<span class="md-footer-nav__direction">
                  下一頁
                </span>
                [Day 23] Attention-Based:使用注意力機制解釋CNN模型
              </span>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
</div>
</a>
</nav>
</div>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-footer-copyright">
<div class="md-footer-copyright__highlight">
            Copyright © 2023 - 2024 10程式中
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
</div>
</div>
</div>
</footer>
</div>
<script src="assets/javascripts/application.245445c6.js"></script>
<script src="assets/javascripts/lunr/lunr.stemmer.support.js"></script>
<script src="assets/javascripts/lunr/tinyseg.js"></script>
<script src="assets/javascripts/lunr/lunr.ja.js"></script>
<script>app.initialize({version:"1.0.4",url:{base:"."}})</script>
<script src="javascripts/extra.js"></script>
</body>
</html>