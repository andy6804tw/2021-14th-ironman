
<!DOCTYPE html>

<html class="no-js" lang="zh-Hant">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="ie=edge" http-equiv="x-ua-compatible"/>
<meta content="10程式中" name="author"/>
<meta content="複製" name="lang:clipboard.copy"/>
<meta content="已複製" name="lang:clipboard.copied"/>
<meta content="ja" name="lang:search.language"/>
<meta content="True" name="lang:search.pipeline.stopwords"/>
<meta content="True" name="lang:search.pipeline.trimmer"/>
<meta content="沒有符合的項目" name="lang:search.result.none"/>
<meta content="找到 1 個符合的項目" name="lang:search.result.one"/>
<meta content="找到 # 個符合的項目" name="lang:search.result.other"/>
<meta content="[\uff0c\u3002]+" name="lang:search.tokenizer"/>
<link href="../assets/images/favicon.png" rel="shortcut icon"/>
<meta content="mkdocs-1.0.4, mkdocs-material-4.4.0" name="generator"/>
<title>[Day 21] Propagation-Based：探索反向傳播法的可解釋性 - 全民瘋AI系列 [探索可解釋人工智慧]</title>
<link href="../assets/stylesheets/application.0284f74d.css" rel="stylesheet"/>
<link href="../assets/stylesheets/application-palette.01803549.css" rel="stylesheet"/>
<meta content="#7e57c2" name="theme-color"/>
<script src="../assets/javascripts/modernizr.74668098.js"></script>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&amp;display=fallback" rel="stylesheet"/>
<style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
<link href="../assets/fonts/material-icons.css" rel="stylesheet"/>
<link href="../stylesheets/extra.css" rel="stylesheet"/>
</head>
<body data-md-color-accent="deep-purple" data-md-color-primary="deep-purple" dir="ltr">
<svg class="md-svg">
<defs>
<svg height="448" id="__github" viewbox="0 0 416 448" width="416" xmlns="http://www.w3.org/2000/svg"><path d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z" fill="currentColor"></path></svg>
</defs>
</svg>
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
<a class="md-skip" href="#day-21-propagation-based" tabindex="1">
        跳轉到
      </a>
<header class="md-header" data-md-component="header">
<nav class="md-header-nav md-grid">
<div class="md-flex">
<div class="md-flex__cell md-flex__cell--shrink">
<a class="md-header-nav__button md-logo" href=".." title="全民瘋AI系列 [探索可解釋人工智慧]">
<i class="md-icon"></i>
</a>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
</div>
<div class="md-flex__cell md-flex__cell--stretch">
<div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
<span class="md-header-nav__topic">
              全民瘋AI系列 [探索可解釋人工智慧]
            </span>
<span class="md-header-nav__topic">
              
                [Day 21] Propagation-Based：探索反向傳播法的可解釋性
              
            </span>
</div>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="query" data-md-state="active" name="query" placeholder="搜尋" spellcheck="false" type="text"/>
<label class="md-icon md-search__icon" for="__search"></label>
<button class="md-icon md-search__icon" data-md-component="reset" tabindex="-1" type="reset">
        
      </button>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="result">
<div class="md-search-result__meta">
            打字進行搜尋
          </div>
<ol class="md-search-result__list"></ol>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<div class="md-header-nav__source">
<a class="md-source" data-md-source="github" href="https://github.com/andy6804tw/crazyai-xai" title="前往倉庫">
<div class="md-source__icon">
<svg height="24" viewbox="0 0 24 24" width="24">
<use height="24" width="24" xlink:href="#__github"></use>
</svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
</div>
</div>
</nav>
</header>
<div class="md-container">
<main class="md-main">
<div class="md-main__inner md-grid" data-md-component="container">
<div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav class="md-nav md-nav--primary" data-md-level="0">
<label class="md-nav__title md-nav__title--site" for="__drawer">
<a class="md-nav__button md-logo" href=".." title="全民瘋AI系列 [探索可解釋人工智慧]">
<i class="md-icon"></i>
</a>
    全民瘋AI系列 [探索可解釋人工智慧]
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-source="github" href="https://github.com/andy6804tw/crazyai-xai" title="前往倉庫">
<div class="md-source__icon">
<svg height="24" viewbox="0 0 24 24" width="24">
<use height="24" width="24" xlink:href="#__github"></use>
</svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" id="nav-1" type="checkbox"/>
<label class="md-nav__link" for="nav-1">
      1.XAI基礎與概念介紹
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-1">
        1.XAI基礎與概念介紹
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../1.揭開模型的神秘面紗:為何XAI對機器學習如此重要/" title="[Day 1] 揭開模型的神秘面紗：為何XAI對機器學習如此重要？">
      [Day 1] 揭開模型的神秘面紗：為何XAI對機器學習如此重要？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2.從黑盒到透明化:XAI技術的發展之路/" title="[Day 2] 從黑盒到透明化：XAI技術的發展之路">
      [Day 2] 從黑盒到透明化：XAI技術的發展之路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../3.機器學習中的可解釋性指標/" title="[Day 3] 機器學習中的可解釋性指標">
      [Day 3] 機器學習中的可解釋性指標
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../4.LIME vs SHAP:哪種XAI解釋方法更適合你/" title="[Day 4] LIME vs. SHAP：哪種XAI解釋方法更適合你？">
      [Day 4] LIME vs. SHAP：哪種XAI解釋方法更適合你？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../5.淺談XAI與傳統機器學習的區別/" title="[Day 5] 淺談XAI與傳統機器學習的區別">
      [Day 5] 淺談XAI與傳統機器學習的區別
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" id="nav-2" type="checkbox"/>
<label class="md-nav__link" for="nav-2">
      2.XAI在傳統機器學習中的應用
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-2">
        2.XAI在傳統機器學習中的應用
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../6.非監督學習也能做到可解釋性-探索XAI在非監督學習中的應用/" title="[Day 6] 非監督學習也能做到可解釋性？探索XAI在非監督學習中的應用">
      [Day 6] 非監督學習也能做到可解釋性？探索XAI在非監督學習中的應用
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../7.KNN與XAI:從鄰居中找出模型的決策邏輯/" title="[Day 7] KNN與XAI：從鄰居中找出模型的決策邏輯">
      [Day 7] KNN與XAI：從鄰居中找出模型的決策邏輯
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../8.解釋線性模型:探索線性迴歸和邏輯迴歸的可解釋性/" title="[Day 8] 解釋線性模型：探索線性迴歸和邏輯迴歸的可解釋性">
      [Day 8] 解釋線性模型：探索線性迴歸和邏輯迴歸的可解釋性
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../9.基於樹狀結構的XAI方法:決策樹的可解釋性/" title="[Day 9] 基於樹狀結構的XAI方法：決策樹的可解釋性">
      [Day 9] 基於樹狀結構的XAI方法：決策樹的可解釋性
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../10.Permutation Importance:從特徵重要性角度解釋整個模型行為/" title="[Day 10] Permutation Importance：從特徵重要性角度解釋整個模型行為">
      [Day 10] Permutation Importance：從特徵重要性角度解釋整個模型行為
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../11.Partial Dependence Plot:探索特徵對預測值的影響/" title="[Day 11] Partial Dependence Plot：探索特徵對預測值的影響">
      [Day 11] Partial Dependence Plot：探索特徵對預測值的影響
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" id="nav-3" type="checkbox"/>
<label class="md-nav__link" for="nav-3">
      3.XAI常用工具介紹
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-3">
        3.XAI常用工具介紹
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../12.LIME理論:如何用局部線性近似解釋黑箱模型/" title="[Day 12] LIME理論：如何用局部線性近似解釋黑箱模型">
      [Day 12] LIME理論：如何用局部線性近似解釋黑箱模型
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../13.LIME實作:實戰演練LIME解釋方法/" title="[Day 13] LIME實作：實戰演練LIME解釋方法">
      [Day 13] LIME實作：實戰演練LIME解釋方法
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../14.SHAP理論:解析SHAP解釋方法的核心/" title="[Day 14] SHAP理論：解析SHAP解釋方法的核心">
      [Day 14] SHAP理論：解析SHAP解釋方法的核心
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../15.SHAP實作:實戰演練SHAP解釋方法/" title="[Day 15] SHAP實作：實戰演練SHAP解釋方法">
      [Day 15] SHAP實作：實戰演練SHAP解釋方法
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-toggle md-nav__toggle" data-md-toggle="nav-4" id="nav-4" type="checkbox"/>
<label class="md-nav__link" for="nav-4">
      4.XAI在深度學習中的可解釋性
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-4">
        4.XAI在深度學習中的可解釋性
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../16.神經網路的可解釋性:如何理解深度學習中的黑箱模型/" title="[Day 16] 神經網路的可解釋性：如何理解深度學習中的黑箱模型？">
      [Day 16] 神經網路的可解釋性：如何理解深度學習中的黑箱模型？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../17.解析深度神經網路:使用Deep SHAP進行模型解釋/" title="[Day 17] 解析深度神經網路：使用Deep SHAP進行模型解釋">
      [Day 17] 解析深度神經網路：使用Deep SHAP進行模型解釋
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../18.CNN卷積深度神經網路的解釋方法/" title="[Day 18] CNN：卷積深度神經網路的解釋方法">
      [Day 18] CNN：卷積深度神經網路的解釋方法
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../19.Perturbation Based如何用擾動方法解釋神經網路/" title="[Day 19] Perturbation-Based：如何用擾動方法解釋神經網路">
      [Day 19] Perturbation-Based：如何用擾動方法解釋神經網路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../20.Gradient Based利用梯度訊息解釋神經網路/" title="[Day 20] Gradient-Based：利用梯度訊息解釋神經網路">
      [Day 20] Gradient-Based：利用梯度訊息解釋神經網路
    </a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-toggle md-nav__toggle" data-md-toggle="toc" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
        [Day 21] Propagation-Based：探索反向傳播法的可解釋性
      </label>
<a class="md-nav__link md-nav__link--active" href="./" title="[Day 21] Propagation-Based：探索反向傳播法的可解釋性">
      [Day 21] Propagation-Based：探索反向傳播法的可解釋性
    </a>
<nav class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">本頁目錄</label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#layer-wise-relevance-propagation" title="Layer-wise relevance propagation">
    Layer-wise relevance propagation
  </a>
<nav class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#1-basic-rule-lrp-0" title="1. Basic Rule (LRP-0):">
    1. Basic Rule (LRP-0):
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#2-epsilon-rule-lrp-" title="2. Epsilon Rule (LRP-ε):">
    2. Epsilon Rule (LRP-ε):
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#3-gamma-rule-lrp-" title="3. Gamma Rule (LRP-γ):">
    3. Gamma Rule (LRP-γ):
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_1" title="實驗結果">
    實驗結果
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#deeplift" title="DeepLIFT">
    DeepLIFT
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#reference" title="Reference">
    Reference
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../22.CAM Based如何解釋卷積神經網路/" title="[Day 22] CAM-Based：如何解釋卷積神經網路">
      [Day 22] CAM-Based：如何解釋卷積神經網路
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../23.Attention Based使用注意力機制解釋CNN模型/" title="[Day 23] Attention-Based：使用注意力機制解釋CNN模型">
      [Day 23] Attention-Based：使用注意力機制解釋CNN模型
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" id="nav-5" type="checkbox"/>
<label class="md-nav__link" for="nav-5">
      5.XAI在現實生活中的應用案例
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-5">
        5.XAI在現實生活中的應用案例
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../24.LSTM的可解釋性:解析步態分類中的時序資料/" title="[Day 24] LSTM的可解釋性：從時序資料解析人體姿態預測">
      [Day 24] LSTM的可解釋性：從時序資料解析人體姿態預測
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../25.XAI在影像處理中的瑕疵檢測:解釋卷積神經網路的運作/" title="[Day 25] XAI在影像處理中的瑕疵檢測：解釋卷積神經網路的運作">
      [Day 25] XAI在影像處理中的瑕疵檢測：解釋卷積神經網路的運作
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../26.智慧工廠製程中的鋼材缺陷檢測:運用XAI解析數值型感測器數據/" title="[Day 26] XAI在表格型資料的應用：解析智慧工廠中的鋼材缺陷">
      [Day 26] XAI在表格型資料的應用：解析智慧工廠中的鋼材缺陷
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../27.XAI在NLP中的應用:以情感分析解釋語言模型/" title="[Day 27] XAI在NLP中的應用：以情感分析解釋語言模型">
      [Day 27] XAI在NLP中的應用：以情感分析解釋語言模型
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" id="nav-6" type="checkbox"/>
<label class="md-nav__link" for="nav-6">
      6.XAI的挑戰與未來
    </label>
<nav class="md-nav" data-md-component="collapsible" data-md-level="1">
<label class="md-nav__title" for="nav-6">
        6.XAI的挑戰與未來
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../28.誤差分析和對抗樣本:如何利用XAI檢測模型的弱點/" title="[Day 28] 對抗樣本的挑戰：如何利用XAI檢測模型的弱點？">
      [Day 28] 對抗樣本的挑戰：如何利用XAI檢測模型的弱點？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../29.XAI如何影響人類對技術的信任和接受程度/" title="[Day 29] XAI如何影響人類對技術的信任和接受程度？">
      [Day 29] XAI如何影響人類對技術的信任和接受程度？
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../30.XAI未來發展方向:向更可靠的機器學習模型邁進/" title="[Day30] XAI未來發展方向：向更可靠的機器學習模型邁進">
      [Day30] XAI未來發展方向：向更可靠的機器學習模型邁進
    </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">本頁目錄</label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#layer-wise-relevance-propagation" title="Layer-wise relevance propagation">
    Layer-wise relevance propagation
  </a>
<nav class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#1-basic-rule-lrp-0" title="1. Basic Rule (LRP-0):">
    1. Basic Rule (LRP-0):
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#2-epsilon-rule-lrp-" title="2. Epsilon Rule (LRP-ε):">
    2. Epsilon Rule (LRP-ε):
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#3-gamma-rule-lrp-" title="3. Gamma Rule (LRP-γ):">
    3. Gamma Rule (LRP-γ):
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_1" title="實驗結果">
    實驗結果
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#deeplift" title="DeepLIFT">
    DeepLIFT
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#reference" title="Reference">
    Reference
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content">
<article class="md-content__inner md-typeset"><a class="md-content__icon pdf-download-btn" download href="../pdf/全民瘋AI系列_探索可解釋人工智慧_v1.1.pdf" title="Download"><i class="fa fas fa-download"></i><small> PDF</small></a>
<h1 id="day-21-propagation-based">[Day 21] Propagation-Based：探索反向傳播法的可解釋性</h1>
<p>今天所要談 Propagation-Based 方法在 CNN 中的作用是透過計算梯度、反向傳播或不同層的特徵來量化每個像素或特徵對預測結果的影響。</p>
<p>從昨天的 Gradient-based 方法我們了解到，可以使用梯度來估算每個輸入圖片的像素與最終分類結果之間的關係。換句話說，透過計算每個輸入圖片像素對於最終預測結果的影響，我們可以瞭解它們對於分類標籤的預測的貢獻程度。最終這些貢獻的總和等同於該圖像對於分類結果的預測。事實上這個概念可以在 CNN 的每一層都應用，即推斷每個特徵圖中的特徵與最終結果之間的相關性。這使得我們可以從最終輸出層開始回溯，而不僅僅針對輸入層計算梯度。以下為各位整理兩篇著名的 Propagation-Based 相關文獻：</p>
<ul>
<li><a href="https://link.springer.com/book/10.1007/978-3-030-28954-6">Layer-wise Relevance Propagation</a> (LRP) (Bach et al., 2015)：透過泰勒分解來反向傳遞神經網路，以達到識別重要像素的方法。 </li>
<li><a href="https://arxiv.org/abs/1704.02685">DeepLIFT</a>(Shrikumar et al., 2017)：是一種改進的反向傳播算法，用於生成熱圖以顯示神經網路的特徵重要性。SHAP 套件中的 Deep SHAP 就是基於 SHAP 和 DeepLIFT 算法。</li>
</ul>
<h2 id="layer-wise-relevance-propagation">Layer-wise relevance propagation</h2>
<p>Layer-wise relevance propagation 是一種 Propagation-Based 方法的實例，用於理解深度神經網路對輸入數據的預測是如何形成的，並將其分解成單個輸入維度的相關性分數。這可以幫助我們理解神經網路中哪些部分對最終預測貢獻最大，對於模型的解釋和可解釋性非常有用。該方法被擴展到處理卷積神經網路中的特殊非線性操作，以更好地理解這些網路的工作原理。</p>
<p><img alt="" src="../image/img21-1.png"/></p>
<p>從下圖可見，左側輸入一張圖片，經過網路中的一系列神經元計算後得到輸出結果 xf。這個輸出 xf 等同於 Rf，實際上是每一層的特徵經過相關性計算後總和的結果。因此右側的部分表示從輸出結果開始，透過層層傳遞，將重要訊息回饋到最初的輸入圖片中。</p>
<p><img alt="" src="../image/img21-2.png"/></p>
<ol>
<li>Input: 輸入是一張圖像，其中包含像素值 {xp}，這些像素值表示了圖像中的特徵。</li>
<li>Forward Propagation: 將像素值 {xp} 通過神經網路進行正向傳播。在神經網路中，經過多個層次的計算，獲得一個得分 f(x)，該得分指示了類別<code>貓</code>的存在。這個得分是由輸出神經元 xf 表示的，xf 的值編碼了圖像中是否包含貓的訊息。</li>
<li>Relevance Calculation: 接下來，計算輸出神經元 xf 的相對重要性（relevance），這個相對重要性記為 Rf，通常是 xf 的值本身。這表示輸出神經元對於類別<code>貓</code>的存在有多大的貢獻。</li>
<li>Backpropagation of Relevance: 從頂層開始，將相對重要性 Rf 進行反向傳播，傳播到較低的層次。這些相對重要性（Rp）被分配給了所有像素 {xp}，表示了它們對於最終類別分類的貢獻。</li>
<li>Relevance Redistribution: 最低隱藏層的最後一個神經元被認為對於更高層次的重要性較大，因此它將其分配的相對重要性重新分配到像素上。換句話說，這個神經元將影響圖像中某些特定區域的相對重要性。</li>
<li>Heatmap Generation: 通過以上步驟，得到了像素 {xp} 的相對重要性 heatmap，這個熱圖顯示了圖像中哪些區域對於最終類別分類更加重要。熱圖可用於可視化模型對圖像的關注點，以及在圖像中哪些區域包含了有關類別<code>貓</code>的訊息。</li>
</ol>
<p>我們可以發現 LRP 方法主要是從最終輸出層逐步追溯到輸入層，逐層理解前層重要的神經元是如何影響輸出的，以此來獲得解釋性。下面公式 Ri 就是第 i 層節點的 Relevance，要計算它就是 Rj 第 j 層所有節點的 Relevance 並乘上一個權重，這個權重就是 xi 節點經過計算往下一層傳遞的數值。</p>
<p><img alt="" src="../image/img21-3.png"/></p>
<p>以下這三種不同的 LRP 規則是用來調整相對重要性在不同神經網路層次之間的傳播方式。它們有助於解釋模型的預測，並提供了對模型中不同層次神經元貢獻的不同理解。根據神經元所在的層次，選擇適當的 LRP 規則可以更好地理解模型的工作原理。</p>
<h3 id="1-basic-rule-lrp-0">1. Basic Rule (LRP-0):</h3>
<p><img alt="" src="../image/img21-4.png"/>
應用層級: LRP-0 主要用於深層神經元，即神經網路中較高層次的神經元。</p>
<p>運作原理: 在 LRP-0 中，相對重要性（relevance）會傳遞到較低層的神經元，而且傳遞的方式是基於某種權重分佈的。這種權重分佈可以基於神經網路的結構和連接來計算，以確保相對重要性能夠合理地傳遞到較低層的神經元，間接提高了較高層次的貢獻。</p>
<h3 id="2-epsilon-rule-lrp-">2. Epsilon Rule (LRP-ε):</h3>
<p><img alt="" src="../image/img21-5.png"/>
應用層級: LRP-ε 通常應用於中層神經元，即神經網路中處於中間位置的神經元。</p>
<p>運作原理: 在 LRP-ε 中，相對重要性會以更平均的方式傳遞到較低層的神經元，不像 LRP-0 那麼專注於少數高度相對重要的神經元。這種方法有助於平衡訊息的傳遞，以更全面地考慮中間層次的貢獻。</p>
<h3 id="3-gamma-rule-lrp-">3. Gamma Rule (LRP-γ):</h3>
<p><img alt="" src="../image/img21-6.png"/>
應用層級: LRP-γ 通常應用於較淺層的神經元，即神經網路中較低層次的神經元。</p>
<p>運作原理: LRP-γ 會更強調相對重要性在較低層神經元之間的分佈，這意味著相對重要性會更加集中於較低層的特定神經元。這有助於解釋模型為什麼會對某些輸入特徵產生強烈的反應，並且能夠將模型的決策過程更清晰地關聯到較低層次的特徵。</p>
<h3 id="_1">實驗結果</h3>
<p>讓我們來觀察不同計算方法對最終解釋性的影響。在下圖中，紅色的點代表對辨識結果有正向幫助，而藍色的點則代表有負向的影響。我們也可以觀察到以下情況：當使用 LRP-0 時，產生了相當多的雜訊；LRP-ε 的效果看起來相對不錯，並且減少了雜訊點的出現；而最右邊的 LRP-γ 則沒有出現對辨識結果有負面影響的點，因此沒有藍色點。最後論文又提了一種方法是在神經網路中依據不同層使用不同的計算方法，其中在最後的全連階層使用 LRP-0，在深層取得比較多特徵的地方使用 LRP-ε，在淺層的地方使用 LRP-γ。最終的結果看起來遠比三個單獨使用效果顯著。</p>
<p><img alt="" src="../image/img21-7.png"/></p>
<p>各位可以試試看這個互動<a href="https://lrpserver.hhi.fraunhofer.de/image-classification">網站</a>，裡面實現了 LRP 方法，並可以調整參數控制解釋性。</p>
<p><img alt="" src="../image/img21-8.png"/></p>
<h2 id="deeplift">DeepLIFT</h2>
<p>DeepLIFT 是一種反向傳播的方法，類似於 LRP。每個單元 <code>i</code> 都被分配一個歸因值，表示該單元對於原始網路輸入 <code>x</code> 的激發相對於某個參考輸入 <code>x̄</code> 的相對效應。可以參考下方公式3：</p>
<p><img alt="" src="../image/img21-9.png"/></p>
<p>對於所有隱藏層單元，參考值 <code>z̄ji</code> 是通過對網路進行前向傳遞，使用基準輸入 <code>x̄</code>，並記錄每個單元的激發數值來確定的。與 LRP 一樣，基準通常選擇為零。相關性傳播過程可以通過下方公式4描述。</p>
<p><img alt="" src="../image/img21-10.png"/></p>
<p>簡單來說 DeepLIFT 理論的核心概念是將模型的輸入特徵歸因到每個特徵的貢獻度，以解釋模型的預測過程。如果要實作 DeepLIFT 可以參考原始論文在 GitHub 的開源套件 <a href="https://github.com/kundajelab/deeplift">DeepLIFT: Deep Learning Important FeaTures</a>。此外在 SHAP 套件提供的 DeepExplainer 解釋方法就是 DeepLIFT 和 Shapely values 的結合。詳細的實作內容可以參考 <a href="https://ithelp.ithome.com.tw/articles/10331443">[Day 17] 解析深度神經網路：使用Deep SHAP進行模型解釋</a>。</p>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://arxiv.org/abs/1512.02479">Explaining NonLinear Classification Decisions with Deep Taylor Decomposition</a></li>
<li><a href="https://arxiv.org/abs/1711.06104">Towards better understanding of gradient-based attribution methods for Deep Neural Networks</a></li>
<li><a href="https://medium.com/ai-academy-taiwan/%E5%8F%AF%E8%A7%A3%E9%87%8B-ai-xai-%E7%B3%BB%E5%88%97-03-%E5%9F%BA%E6%96%BC%E5%82%B3%E6%92%AD%E7%9A%84%E6%96%B9%E6%B3%95-propagation-based-layer-wise-relevance-propagation-1b79ce96042d">可解釋 AI (XAI) 系列 — 03 基於傳播的方法 (Propagation-Based): Layer-Wise Relevance Propagation</a></li>
</ul>
</article>
</div>
</div>
</main>
<footer class="md-footer">
<div class="md-footer-nav">
<nav class="md-footer-nav__inner md-grid">
<a class="md-flex md-footer-nav__link md-footer-nav__link--prev" href="../20.Gradient Based利用梯度訊息解釋神經網路/" rel="prev" title="[Day 20] Gradient-Based：利用梯度訊息解釋神經網路">
<div class="md-flex__cell md-flex__cell--shrink">
<i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
</div>
<div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
<span class="md-flex__ellipsis">
<span class="md-footer-nav__direction">
                  上一頁
                </span>
                [Day 20] Gradient-Based：利用梯度訊息解釋神經網路
              </span>
</div>
</a>
<a class="md-flex md-footer-nav__link md-footer-nav__link--next" href="../22.CAM Based如何解釋卷積神經網路/" rel="next" title="[Day 22] CAM-Based：如何解釋卷積神經網路">
<div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
<span class="md-flex__ellipsis">
<span class="md-footer-nav__direction">
                  下一頁
                </span>
                [Day 22] CAM-Based：如何解釋卷積神經網路
              </span>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
</div>
</a>
</nav>
</div>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-footer-copyright">
<div class="md-footer-copyright__highlight">
            Copyright © 2023 - 2024 10程式中
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
</div>
</div>
</div>
</footer>
</div>
<script src="../assets/javascripts/application.245445c6.js"></script>
<script src="../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
<script src="../assets/javascripts/lunr/tinyseg.js"></script>
<script src="../assets/javascripts/lunr/lunr.ja.js"></script>
<script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
<script src="../javascripts/extra.js"></script>
<script src="../javascripts/analytics.js"></script>
</body>
</html>